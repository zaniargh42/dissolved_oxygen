{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense  \n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 11) (492, 11)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Training set 2011-2015')\n",
    "train.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "test=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Testing set 2016-2019 ')\n",
    "test.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data(data):\n",
    "    X_train=data.drop(['dissolved_oxygen'],axis=1)\n",
    "    y_train=data.dissolved_oxygen\n",
    "    return X_train , y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_data(X_train,y_train):\n",
    "    X_scaler=StandardScaler()\n",
    "    X_train_scaled=X_scaler.fit_transform(X_train)\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_scaled=y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "    print(X_train_scaled.shape, y_train_scaled.shape)\n",
    "    return X_train_scaled,y_train_scaled , X_scaler , y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 10) (626, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=_prepare_data(train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(X_train, y_train,epochs=10,batch_size=8)\n",
    "\n",
    "KerasRegressor(model=model, epochs=100, batch_size=5, verbose=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have some missing values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 10) (605, 1)\n"
     ]
    }
   ],
   "source": [
    "nonul_train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "X_train,y_train=_prepare_data(nonul_train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonul_test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "X_test,y_test=_prepare_data(nonul_test)\n",
    "\n",
    "X_test=X_scaler.transform(X_test)\n",
    "y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create the model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train[0].shape[0], input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history , r2=_compile_model(X_train,y_train,X_test,y_test,80,32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size itrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.9799 - val_loss: 0.7359\n",
      "Epoch 2/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.9088 - val_loss: 0.6404\n",
      "Epoch 3/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.8070 - val_loss: 0.5552\n",
      "Epoch 4/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7539 - val_loss: 0.5241\n",
      "Epoch 5/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7305 - val_loss: 0.5132\n",
      "Epoch 6/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.5101\n",
      "Epoch 7/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7085 - val_loss: 0.5094\n",
      "Epoch 8/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7015 - val_loss: 0.5120\n",
      "Epoch 9/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6972 - val_loss: 0.5161\n",
      "Epoch 10/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6921 - val_loss: 0.5183\n",
      "Epoch 11/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6865 - val_loss: 0.5198\n",
      "Epoch 12/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.5228\n",
      "Epoch 13/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6811 - val_loss: 0.5293\n",
      "Epoch 14/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6774 - val_loss: 0.5236\n",
      "Epoch 15/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6711 - val_loss: 0.5423\n",
      "Epoch 16/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6710 - val_loss: 0.5474\n",
      "Epoch 17/80\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6664 - val_loss: 0.5505\n",
      "Epoch 18/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.5586\n",
      "Epoch 19/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6625 - val_loss: 0.5614\n",
      "Epoch 20/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6614 - val_loss: 0.5651\n",
      "Epoch 21/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6603 - val_loss: 0.5694\n",
      "Epoch 22/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6542 - val_loss: 0.5734\n",
      "Epoch 23/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.5748\n",
      "Epoch 24/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.5776\n",
      "Epoch 25/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6485 - val_loss: 0.5882\n",
      "Epoch 26/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6496 - val_loss: 0.5938\n",
      "Epoch 27/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6466 - val_loss: 0.5967\n",
      "Epoch 28/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6045\n",
      "Epoch 29/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6415 - val_loss: 0.6026\n",
      "Epoch 30/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6414 - val_loss: 0.6111\n",
      "Epoch 31/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6379 - val_loss: 0.6140\n",
      "Epoch 32/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6383 - val_loss: 0.6207\n",
      "Epoch 33/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6362 - val_loss: 0.6262\n",
      "Epoch 34/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6365 - val_loss: 0.6216\n",
      "Epoch 35/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.6184\n",
      "Epoch 36/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6298 - val_loss: 0.6329\n",
      "Epoch 37/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 0.6263\n",
      "Epoch 38/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6286 - val_loss: 0.6348\n",
      "Epoch 39/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 0.6279\n",
      "Epoch 40/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 0.6415\n",
      "Epoch 41/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 0.6441\n",
      "Epoch 42/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 0.6487\n",
      "Epoch 43/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.6534\n",
      "Epoch 44/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 0.6487\n",
      "Epoch 45/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.6561\n",
      "Epoch 46/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.6626\n",
      "Epoch 47/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6479\n",
      "Epoch 48/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 0.6680\n",
      "Epoch 49/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6758\n",
      "Epoch 50/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6759\n",
      "Epoch 51/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6100 - val_loss: 0.6767\n",
      "Epoch 52/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6789\n",
      "Epoch 53/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.6857\n",
      "Epoch 54/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 0.6832\n",
      "Epoch 55/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6081 - val_loss: 0.6872\n",
      "Epoch 56/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.7021\n",
      "Epoch 57/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6859\n",
      "Epoch 58/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6922\n",
      "Epoch 59/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6860\n",
      "Epoch 60/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6943\n",
      "Epoch 61/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5997 - val_loss: 0.6932\n",
      "Epoch 62/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6994\n",
      "Epoch 63/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.7113\n",
      "Epoch 64/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.7096\n",
      "Epoch 65/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 0.7101\n",
      "Epoch 66/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.7167\n",
      "Epoch 67/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 0.7133\n",
      "Epoch 68/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7084\n",
      "Epoch 69/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.7189\n",
      "Epoch 70/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 0.7183\n",
      "Epoch 71/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5965 - val_loss: 0.6940\n",
      "Epoch 72/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5948 - val_loss: 0.7194\n",
      "Epoch 73/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.7219\n",
      "Epoch 74/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 0.7274\n",
      "Epoch 75/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5946 - val_loss: 0.7025\n",
      "Epoch 76/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5920 - val_loss: 0.7325\n",
      "Epoch 77/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5931 - val_loss: 0.7333\n",
      "Epoch 78/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7332\n",
      "Epoch 79/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5917 - val_loss: 0.7364\n",
      "Epoch 80/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 0.7460\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:25<02:33, 25.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.9808 - val_loss: 0.7415\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 0.6931\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8759 - val_loss: 0.6326\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8170 - val_loss: 0.5860\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7784 - val_loss: 0.5577\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.5426\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7415 - val_loss: 0.5330\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7320 - val_loss: 0.5275\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7240 - val_loss: 0.5250\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7163 - val_loss: 0.5229\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7151 - val_loss: 0.5213\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7072 - val_loss: 0.5226\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7048 - val_loss: 0.5233\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7022 - val_loss: 0.5234\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6981 - val_loss: 0.5262\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6947 - val_loss: 0.5276\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6922 - val_loss: 0.5278\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6896 - val_loss: 0.5301\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6873 - val_loss: 0.5313\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6847 - val_loss: 0.5332\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6843 - val_loss: 0.5379\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6826 - val_loss: 0.5354\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6790 - val_loss: 0.5348\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6769 - val_loss: 0.5412\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6766 - val_loss: 0.5463\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6752 - val_loss: 0.5417\n",
      "Epoch 27/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6722 - val_loss: 0.5490\n",
      "Epoch 28/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6718 - val_loss: 0.5517\n",
      "Epoch 29/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6698 - val_loss: 0.5536\n",
      "Epoch 30/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6687 - val_loss: 0.5550\n",
      "Epoch 31/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6678 - val_loss: 0.5580\n",
      "Epoch 32/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6664 - val_loss: 0.5575\n",
      "Epoch 33/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6654 - val_loss: 0.5616\n",
      "Epoch 34/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6644 - val_loss: 0.5560\n",
      "Epoch 35/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.5646\n",
      "Epoch 36/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6601 - val_loss: 0.5640\n",
      "Epoch 37/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6578 - val_loss: 0.5692\n",
      "Epoch 38/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6570 - val_loss: 0.5688\n",
      "Epoch 39/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.5755\n",
      "Epoch 40/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.5732\n",
      "Epoch 41/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6542 - val_loss: 0.5770\n",
      "Epoch 42/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6509 - val_loss: 0.5771\n",
      "Epoch 43/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6493 - val_loss: 0.5864\n",
      "Epoch 44/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.5880\n",
      "Epoch 45/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6481 - val_loss: 0.5871\n",
      "Epoch 46/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6464 - val_loss: 0.5888\n",
      "Epoch 47/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6430 - val_loss: 0.5926\n",
      "Epoch 48/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6426 - val_loss: 0.5951\n",
      "Epoch 49/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6406 - val_loss: 0.5990\n",
      "Epoch 50/80\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.5928\n",
      "Epoch 51/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6400 - val_loss: 0.6079\n",
      "Epoch 52/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6393 - val_loss: 0.6064\n",
      "Epoch 53/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.6070\n",
      "Epoch 54/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6358 - val_loss: 0.6103\n",
      "Epoch 55/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6340 - val_loss: 0.6139\n",
      "Epoch 56/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6363 - val_loss: 0.6106\n",
      "Epoch 57/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6354 - val_loss: 0.6225\n",
      "Epoch 58/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6318 - val_loss: 0.6203\n",
      "Epoch 59/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6330 - val_loss: 0.6258\n",
      "Epoch 60/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6298 - val_loss: 0.6278\n",
      "Epoch 61/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6299 - val_loss: 0.6240\n",
      "Epoch 62/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6290 - val_loss: 0.6303\n",
      "Epoch 63/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 0.6337\n",
      "Epoch 64/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 0.6316\n",
      "Epoch 65/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 0.6348\n",
      "Epoch 66/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.6382\n",
      "Epoch 67/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6249 - val_loss: 0.6453\n",
      "Epoch 68/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 0.6260\n",
      "Epoch 69/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 0.6411\n",
      "Epoch 70/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6230 - val_loss: 0.6479\n",
      "Epoch 71/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6211 - val_loss: 0.6581\n",
      "Epoch 72/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6213 - val_loss: 0.6579\n",
      "Epoch 73/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6206 - val_loss: 0.6589\n",
      "Epoch 74/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6205 - val_loss: 0.6618\n",
      "Epoch 75/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6602\n",
      "Epoch 76/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6200 - val_loss: 0.6628\n",
      "Epoch 77/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6188 - val_loss: 0.6635\n",
      "Epoch 78/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6190 - val_loss: 0.6558\n",
      "Epoch 79/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.6669\n",
      "Epoch 80/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.6762\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:38<01:30, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 0.9905 - val_loss: 0.7545\n",
      "Epoch 2/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9711 - val_loss: 0.7318\n",
      "Epoch 3/80\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.9438 - val_loss: 0.7010\n",
      "Epoch 4/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9091 - val_loss: 0.6619\n",
      "Epoch 5/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8672 - val_loss: 0.6235\n",
      "Epoch 6/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8280 - val_loss: 0.5908\n",
      "Epoch 7/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7954 - val_loss: 0.5677\n",
      "Epoch 8/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7736 - val_loss: 0.5496\n",
      "Epoch 9/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7575 - val_loss: 0.5399\n",
      "Epoch 10/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.5300\n",
      "Epoch 11/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7398 - val_loss: 0.5238\n",
      "Epoch 12/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7320 - val_loss: 0.5205\n",
      "Epoch 13/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7265 - val_loss: 0.5165\n",
      "Epoch 14/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7224 - val_loss: 0.5140\n",
      "Epoch 15/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.5125\n",
      "Epoch 16/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 0.5108\n",
      "Epoch 17/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7112 - val_loss: 0.5099\n",
      "Epoch 18/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7081 - val_loss: 0.5105\n",
      "Epoch 19/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7053 - val_loss: 0.5086\n",
      "Epoch 20/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 0.5089\n",
      "Epoch 21/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7003 - val_loss: 0.5105\n",
      "Epoch 22/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6979 - val_loss: 0.5112\n",
      "Epoch 23/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6956 - val_loss: 0.5124\n",
      "Epoch 24/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6940 - val_loss: 0.5111\n",
      "Epoch 25/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.5129\n",
      "Epoch 26/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6915 - val_loss: 0.5110\n",
      "Epoch 27/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6891 - val_loss: 0.5159\n",
      "Epoch 28/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 0.5157\n",
      "Epoch 29/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.5196\n",
      "Epoch 30/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.5202\n",
      "Epoch 31/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6814 - val_loss: 0.5215\n",
      "Epoch 32/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.5220\n",
      "Epoch 33/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6784 - val_loss: 0.5236\n",
      "Epoch 34/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.5245\n",
      "Epoch 35/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6763 - val_loss: 0.5276\n",
      "Epoch 36/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.5298\n",
      "Epoch 37/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.5303\n",
      "Epoch 38/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.5318\n",
      "Epoch 39/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.5307\n",
      "Epoch 40/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6696 - val_loss: 0.5341\n",
      "Epoch 41/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6682 - val_loss: 0.5367\n",
      "Epoch 42/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6675 - val_loss: 0.5401\n",
      "Epoch 43/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6674 - val_loss: 0.5400\n",
      "Epoch 44/80\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6666 - val_loss: 0.5437\n",
      "Epoch 45/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.5474\n",
      "Epoch 46/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.5465\n",
      "Epoch 47/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6625 - val_loss: 0.5489\n",
      "Epoch 48/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.5504\n",
      "Epoch 49/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.5535\n",
      "Epoch 50/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.5511\n",
      "Epoch 51/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.5531\n",
      "Epoch 52/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.5564\n",
      "Epoch 53/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.5603\n",
      "Epoch 54/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.5582\n",
      "Epoch 55/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.5626\n",
      "Epoch 56/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.5638\n",
      "Epoch 57/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.5650\n",
      "Epoch 58/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.5648\n",
      "Epoch 59/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.5642\n",
      "Epoch 60/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.5716\n",
      "Epoch 61/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6452 - val_loss: 0.5711\n",
      "Epoch 62/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6439 - val_loss: 0.5715\n",
      "Epoch 63/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6429 - val_loss: 0.5771\n",
      "Epoch 64/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6424 - val_loss: 0.5773\n",
      "Epoch 65/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6418 - val_loss: 0.5761\n",
      "Epoch 66/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6417 - val_loss: 0.5788\n",
      "Epoch 67/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.5830\n",
      "Epoch 68/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6394 - val_loss: 0.5819\n",
      "Epoch 69/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6383 - val_loss: 0.5817\n",
      "Epoch 70/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6376 - val_loss: 0.5887\n",
      "Epoch 71/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.5929\n",
      "Epoch 72/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6354 - val_loss: 0.5918\n",
      "Epoch 73/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.5947\n",
      "Epoch 74/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.5961\n",
      "Epoch 75/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.5990\n",
      "Epoch 76/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.6000\n",
      "Epoch 77/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.5965\n",
      "Epoch 78/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6026\n",
      "Epoch 79/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6323 - val_loss: 0.5991\n",
      "Epoch 80/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.6062\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:47<00:55, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 0.9821 - val_loss: 0.7479\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9699 - val_loss: 0.7359\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9566 - val_loss: 0.7218\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9412 - val_loss: 0.7055\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9231 - val_loss: 0.6877\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9031 - val_loss: 0.6685\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8835 - val_loss: 0.6474\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8618 - val_loss: 0.6267\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8406 - val_loss: 0.6080\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8212 - val_loss: 0.5910\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8044 - val_loss: 0.5739\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7850 - val_loss: 0.5614\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7713 - val_loss: 0.5499\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7583 - val_loss: 0.5401\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.5328\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7374 - val_loss: 0.5270\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7299 - val_loss: 0.5231\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7257 - val_loss: 0.5206\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7192 - val_loss: 0.5185\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7174 - val_loss: 0.5185\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7120 - val_loss: 0.5181\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7091 - val_loss: 0.5182\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7057 - val_loss: 0.5174\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7031 - val_loss: 0.5177\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7007 - val_loss: 0.5180\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6988 - val_loss: 0.5195\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6958 - val_loss: 0.5196\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6941 - val_loss: 0.5208\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6919 - val_loss: 0.5219\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6902 - val_loss: 0.5245\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6888 - val_loss: 0.5269\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6865 - val_loss: 0.5266\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6847 - val_loss: 0.5282\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6834 - val_loss: 0.5302\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6821 - val_loss: 0.5316\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6802 - val_loss: 0.5328\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6799 - val_loss: 0.5401\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6767 - val_loss: 0.5428\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6748 - val_loss: 0.5429\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6730 - val_loss: 0.5436\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6721 - val_loss: 0.5459\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6704 - val_loss: 0.5466\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6693 - val_loss: 0.5482\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6682 - val_loss: 0.5485\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6675 - val_loss: 0.5491\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6664 - val_loss: 0.5506\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6655 - val_loss: 0.5524\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6638 - val_loss: 0.5612\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6626 - val_loss: 0.5653\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6633 - val_loss: 0.5696\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.5690\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6606 - val_loss: 0.5722\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6595 - val_loss: 0.5712\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6585 - val_loss: 0.5730\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6580 - val_loss: 0.5717\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6562 - val_loss: 0.5795\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6560 - val_loss: 0.5817\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6561 - val_loss: 0.5940\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6538 - val_loss: 0.5964\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6534 - val_loss: 0.5961\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6533 - val_loss: 0.5996\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6521 - val_loss: 0.5966\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6506 - val_loss: 0.5977\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6503 - val_loss: 0.5983\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6504 - val_loss: 0.6038\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6494 - val_loss: 0.6047\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6493 - val_loss: 0.5986\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6483 - val_loss: 0.6079\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6483 - val_loss: 0.6151\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6468 - val_loss: 0.6117\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6456 - val_loss: 0.6119\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6454 - val_loss: 0.6139\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6451 - val_loss: 0.6131\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6443 - val_loss: 0.6127\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6435 - val_loss: 0.6137\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6429 - val_loss: 0.6149\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6422 - val_loss: 0.6168\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6415 - val_loss: 0.6194\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6411 - val_loss: 0.6188\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6411 - val_loss: 0.6180\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:58<00:38, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 43ms/step - loss: 0.9982 - val_loss: 0.7683\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9938 - val_loss: 0.7645\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9896 - val_loss: 0.7601\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9847 - val_loss: 0.7551\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9794 - val_loss: 0.7492\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9729 - val_loss: 0.7424\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9653 - val_loss: 0.7346\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9561 - val_loss: 0.7258\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9464 - val_loss: 0.7157\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9351 - val_loss: 0.7046\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9231 - val_loss: 0.6926\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9097 - val_loss: 0.6799\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8961 - val_loss: 0.6665\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8806 - val_loss: 0.6532\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8667 - val_loss: 0.6395\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8505 - val_loss: 0.6267\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8372 - val_loss: 0.6140\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8235 - val_loss: 0.6022\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8092 - val_loss: 0.5918\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7988 - val_loss: 0.5820\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7867 - val_loss: 0.5736\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7784 - val_loss: 0.5658\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7706 - val_loss: 0.5592\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7622 - val_loss: 0.5534\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7564 - val_loss: 0.5486\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7499 - val_loss: 0.5442\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7448 - val_loss: 0.5404\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7399 - val_loss: 0.5368\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7363 - val_loss: 0.5335\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7322 - val_loss: 0.5305\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7286 - val_loss: 0.5282\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7255 - val_loss: 0.5262\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7226 - val_loss: 0.5243\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7192 - val_loss: 0.5226\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7166 - val_loss: 0.5214\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7147 - val_loss: 0.5200\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7119 - val_loss: 0.5187\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7102 - val_loss: 0.5181\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7076 - val_loss: 0.5177\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7054 - val_loss: 0.5172\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7033 - val_loss: 0.5166\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7019 - val_loss: 0.5163\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7009 - val_loss: 0.5164\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6988 - val_loss: 0.5164\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6969 - val_loss: 0.5165\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6961 - val_loss: 0.5169\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6945 - val_loss: 0.5167\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6936 - val_loss: 0.5172\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6925 - val_loss: 0.5174\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6913 - val_loss: 0.5180\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6905 - val_loss: 0.5183\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6890 - val_loss: 0.5185\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6881 - val_loss: 0.5186\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6872 - val_loss: 0.5194\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6870 - val_loss: 0.5205\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6855 - val_loss: 0.5208\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6848 - val_loss: 0.5221\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6839 - val_loss: 0.5229\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6832 - val_loss: 0.5240\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6821 - val_loss: 0.5242\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6811 - val_loss: 0.5255\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6805 - val_loss: 0.5270\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6795 - val_loss: 0.5278\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6793 - val_loss: 0.5299\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6780 - val_loss: 0.5309\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6773 - val_loss: 0.5315\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6765 - val_loss: 0.5323\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6763 - val_loss: 0.5332\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6758 - val_loss: 0.5350\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6747 - val_loss: 0.5356\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6741 - val_loss: 0.5369\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6734 - val_loss: 0.5379\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6725 - val_loss: 0.5378\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6724 - val_loss: 0.5398\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6715 - val_loss: 0.5411\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6705 - val_loss: 0.5417\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6699 - val_loss: 0.5418\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6690 - val_loss: 0.5428\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6681 - val_loss: 0.5434\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6680 - val_loss: 0.5454\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:03<00:20, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 0.9990 - val_loss: 0.7723\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9963 - val_loss: 0.7700\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9937 - val_loss: 0.7679\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9912 - val_loss: 0.7656\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9888 - val_loss: 0.7633\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9861 - val_loss: 0.7609\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9835 - val_loss: 0.7583\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9807 - val_loss: 0.7555\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9775 - val_loss: 0.7524\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9739 - val_loss: 0.7489\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9700 - val_loss: 0.7450\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9659 - val_loss: 0.7407\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9612 - val_loss: 0.7361\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9563 - val_loss: 0.7311\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9509 - val_loss: 0.7257\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9449 - val_loss: 0.7200\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.9388 - val_loss: 0.7139\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9319 - val_loss: 0.7075\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9251 - val_loss: 0.7007\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9175 - val_loss: 0.6935\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9096 - val_loss: 0.6862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9012 - val_loss: 0.6786\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8928 - val_loss: 0.6707\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8846 - val_loss: 0.6627\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8755 - val_loss: 0.6547\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8663 - val_loss: 0.6467\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8579 - val_loss: 0.6388\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8484 - val_loss: 0.6310\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8400 - val_loss: 0.6233\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8311 - val_loss: 0.6158\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8231 - val_loss: 0.6086\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8145 - val_loss: 0.6019\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8072 - val_loss: 0.5954\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7999 - val_loss: 0.5894\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7926 - val_loss: 0.5840\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7865 - val_loss: 0.5790\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7801 - val_loss: 0.5745\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7752 - val_loss: 0.5702\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7702 - val_loss: 0.5664\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7652 - val_loss: 0.5628\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7611 - val_loss: 0.5594\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7567 - val_loss: 0.5565\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7528 - val_loss: 0.5539\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7494 - val_loss: 0.5514\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7459 - val_loss: 0.5490\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7429 - val_loss: 0.5468\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7398 - val_loss: 0.5447\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7366 - val_loss: 0.5427\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7341 - val_loss: 0.5410\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7307 - val_loss: 0.5394\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7285 - val_loss: 0.5379\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7252 - val_loss: 0.5366\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7224 - val_loss: 0.5357\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7204 - val_loss: 0.5351\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7178 - val_loss: 0.5344\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7147 - val_loss: 0.5333\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7126 - val_loss: 0.5326\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7108 - val_loss: 0.5322\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7088 - val_loss: 0.5316\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7071 - val_loss: 0.5314\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7051 - val_loss: 0.5318\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7031 - val_loss: 0.5328\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7022 - val_loss: 0.5340\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6999 - val_loss: 0.5349\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6988 - val_loss: 0.5357\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6970 - val_loss: 0.5361\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6956 - val_loss: 0.5363\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6943 - val_loss: 0.5363\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6933 - val_loss: 0.5363\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6920 - val_loss: 0.5361\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6909 - val_loss: 0.5359\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6896 - val_loss: 0.5365\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6887 - val_loss: 0.5372\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6870 - val_loss: 0.5379\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6855 - val_loss: 0.5394\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6843 - val_loss: 0.5409\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6834 - val_loss: 0.5422\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6819 - val_loss: 0.5430\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6811 - val_loss: 0.5439\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6804 - val_loss: 0.5449\n",
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [01:10<00:09,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.9992 - val_loss: 0.7777\n",
      "Epoch 2/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9973 - val_loss: 0.7762\n",
      "Epoch 3/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9955 - val_loss: 0.7747\n",
      "Epoch 4/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9938 - val_loss: 0.7733\n",
      "Epoch 5/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9921 - val_loss: 0.7719\n",
      "Epoch 6/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9904 - val_loss: 0.7704\n",
      "Epoch 7/80\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.9886 - val_loss: 0.7689\n",
      "Epoch 8/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9868 - val_loss: 0.7674\n",
      "Epoch 9/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9849 - val_loss: 0.7658\n",
      "Epoch 10/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9829 - val_loss: 0.7641\n",
      "Epoch 11/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9807 - val_loss: 0.7623\n",
      "Epoch 12/80\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9784 - val_loss: 0.7603\n",
      "Epoch 13/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9760 - val_loss: 0.7581\n",
      "Epoch 14/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9734 - val_loss: 0.7558\n",
      "Epoch 15/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9706 - val_loss: 0.7533\n",
      "Epoch 16/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9678 - val_loss: 0.7506\n",
      "Epoch 17/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9646 - val_loss: 0.7478\n",
      "Epoch 18/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9614 - val_loss: 0.7448\n",
      "Epoch 19/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9580 - val_loss: 0.7416\n",
      "Epoch 20/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9543 - val_loss: 0.7382\n",
      "Epoch 21/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9505 - val_loss: 0.7347\n",
      "Epoch 22/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9465 - val_loss: 0.7309\n",
      "Epoch 23/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9424 - val_loss: 0.7270\n",
      "Epoch 24/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9380 - val_loss: 0.7229\n",
      "Epoch 25/80\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9335 - val_loss: 0.7188\n",
      "Epoch 26/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9288 - val_loss: 0.7144\n",
      "Epoch 27/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9240 - val_loss: 0.7099\n",
      "Epoch 28/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9193 - val_loss: 0.7053\n",
      "Epoch 29/80\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9142 - val_loss: 0.7006\n",
      "Epoch 30/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9091 - val_loss: 0.6957\n",
      "Epoch 31/80\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.9038 - val_loss: 0.6908\n",
      "Epoch 32/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8987 - val_loss: 0.6858\n",
      "Epoch 33/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8933 - val_loss: 0.6808\n",
      "Epoch 34/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8880 - val_loss: 0.6757\n",
      "Epoch 35/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8828 - val_loss: 0.6707\n",
      "Epoch 36/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8774 - val_loss: 0.6657\n",
      "Epoch 37/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8723 - val_loss: 0.6606\n",
      "Epoch 38/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8672 - val_loss: 0.6556\n",
      "Epoch 39/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8620 - val_loss: 0.6506\n",
      "Epoch 40/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8571 - val_loss: 0.6456\n",
      "Epoch 41/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8521 - val_loss: 0.6407\n",
      "Epoch 42/80\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8474 - val_loss: 0.6359\n",
      "Epoch 43/80\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8426 - val_loss: 0.6312\n",
      "Epoch 44/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8381 - val_loss: 0.6266\n",
      "Epoch 45/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8337 - val_loss: 0.6219\n",
      "Epoch 46/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8297 - val_loss: 0.6174\n",
      "Epoch 47/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8254 - val_loss: 0.6131\n",
      "Epoch 48/80\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.8213 - val_loss: 0.6090\n",
      "Epoch 49/80\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.8176 - val_loss: 0.6048\n",
      "Epoch 50/80\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.8137 - val_loss: 0.6008\n",
      "Epoch 51/80\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.8099 - val_loss: 0.5968\n",
      "Epoch 52/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8065 - val_loss: 0.5928\n",
      "Epoch 53/80\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8027 - val_loss: 0.5890\n",
      "Epoch 54/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7995 - val_loss: 0.5853\n",
      "Epoch 55/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7963 - val_loss: 0.5818\n",
      "Epoch 56/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7932 - val_loss: 0.5785\n",
      "Epoch 57/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7903 - val_loss: 0.5752\n",
      "Epoch 58/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7875 - val_loss: 0.5721\n",
      "Epoch 59/80\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7848 - val_loss: 0.5690\n",
      "Epoch 60/80\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7822 - val_loss: 0.5659\n",
      "Epoch 61/80\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7797 - val_loss: 0.5629\n",
      "Epoch 62/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7773 - val_loss: 0.5601\n",
      "Epoch 63/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7750 - val_loss: 0.5576\n",
      "Epoch 64/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7728 - val_loss: 0.5552\n",
      "Epoch 65/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7706 - val_loss: 0.5530\n",
      "Epoch 66/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7688 - val_loss: 0.5508\n",
      "Epoch 67/80\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7669 - val_loss: 0.5486\n",
      "Epoch 68/80\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7651 - val_loss: 0.5467\n",
      "Epoch 69/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7633 - val_loss: 0.5448\n",
      "Epoch 70/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7617 - val_loss: 0.5430\n",
      "Epoch 71/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7599 - val_loss: 0.5412\n",
      "Epoch 72/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7583 - val_loss: 0.5395\n",
      "Epoch 73/80\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7568 - val_loss: 0.5378\n",
      "Epoch 74/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7552 - val_loss: 0.5361\n",
      "Epoch 75/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7538 - val_loss: 0.5345\n",
      "Epoch 76/80\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.7523 - val_loss: 0.5331\n",
      "Epoch 77/80\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7508 - val_loss: 0.5317\n",
      "Epoch 78/80\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7497 - val_loss: 0.5303\n",
      "Epoch 79/80\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7482 - val_loss: 0.5290\n",
      "Epoch 80/80\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.7467 - val_loss: 0.5277\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:17<00:00, 11.02s/it]\n"
     ]
    }
   ],
   "source": [
    "r2_all=[]\n",
    "for item in tqdm([8,16,32,64,128,256,512]):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,80,item)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(7),r2_all)\n",
    "plt.xticks(range(7),[8,16,32,64,128,256,512])\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "76/76 [==============================] - 2s 10ms/step - loss: 0.9837 - val_loss: 0.7372\n",
      "Epoch 2/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 0.6397\n",
      "Epoch 3/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8040 - val_loss: 0.5580\n",
      "Epoch 4/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7648 - val_loss: 0.5265\n",
      "Epoch 5/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7454 - val_loss: 0.5178\n",
      "Epoch 6/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7327 - val_loss: 0.5125\n",
      "Epoch 7/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7259 - val_loss: 0.5091\n",
      "Epoch 8/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7218 - val_loss: 0.5103\n",
      "Epoch 9/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7142 - val_loss: 0.5089\n",
      "Epoch 10/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7095 - val_loss: 0.5105\n",
      "Epoch 11/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7060 - val_loss: 0.5116\n",
      "Epoch 12/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7024 - val_loss: 0.5125\n",
      "Epoch 13/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6997 - val_loss: 0.5144\n",
      "Epoch 14/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6959 - val_loss: 0.5179\n",
      "Epoch 15/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 0.5230\n",
      "Epoch 16/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6918 - val_loss: 0.5241\n",
      "Epoch 17/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6897 - val_loss: 0.5269\n",
      "Epoch 18/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.5244\n",
      "Epoch 19/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6843 - val_loss: 0.5326\n",
      "Epoch 20/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6852 - val_loss: 0.5356\n",
      "Epoch 21/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6815 - val_loss: 0.5336\n",
      "Epoch 22/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.5439\n",
      "Epoch 23/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6788 - val_loss: 0.5483\n",
      "Epoch 24/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6783 - val_loss: 0.5472\n",
      "Epoch 25/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6772 - val_loss: 0.5498\n",
      "Epoch 26/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6750 - val_loss: 0.5560\n",
      "Epoch 27/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6762 - val_loss: 0.5490\n",
      "Epoch 28/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 0.5596\n",
      "Epoch 29/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6687 - val_loss: 0.5676\n",
      "Epoch 30/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6677 - val_loss: 0.5717\n",
      "Epoch 31/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6644 - val_loss: 0.5713\n",
      "Epoch 32/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6633 - val_loss: 0.5744\n",
      "Epoch 33/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6626 - val_loss: 0.5778\n",
      "Epoch 34/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6589 - val_loss: 0.5786\n",
      "Epoch 35/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6575 - val_loss: 0.5842\n",
      "Epoch 36/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6559 - val_loss: 0.5880\n",
      "Epoch 37/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6544 - val_loss: 0.5909\n",
      "Epoch 38/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6516 - val_loss: 0.5922\n",
      "Epoch 39/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6519 - val_loss: 0.5981\n",
      "Epoch 40/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.5970\n",
      "Epoch 41/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6481 - val_loss: 0.5931\n",
      "Epoch 42/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6452 - val_loss: 0.6046\n",
      "Epoch 43/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6442 - val_loss: 0.6003\n",
      "Epoch 44/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6414 - val_loss: 0.6100\n",
      "Epoch 45/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 0.6183\n",
      "Epoch 46/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6402 - val_loss: 0.6152\n",
      "Epoch 47/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6384 - val_loss: 0.6172\n",
      "Epoch 48/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6382 - val_loss: 0.6189\n",
      "Epoch 49/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6376 - val_loss: 0.6236\n",
      "Epoch 50/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6360 - val_loss: 0.6145\n",
      "Epoch 51/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6327 - val_loss: 0.6321\n",
      "Epoch 52/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 0.6302\n",
      "Epoch 53/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6310 - val_loss: 0.6400\n",
      "Epoch 54/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6317 - val_loss: 0.6447\n",
      "Epoch 55/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6302 - val_loss: 0.6480\n",
      "Epoch 56/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6299 - val_loss: 0.6424\n",
      "Epoch 57/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 0.6440\n",
      "Epoch 58/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6281 - val_loss: 0.6436\n",
      "Epoch 59/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6285 - val_loss: 0.6487\n",
      "Epoch 60/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 0.6587\n",
      "Epoch 61/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 0.6545\n",
      "Epoch 62/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 0.6543\n",
      "Epoch 63/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 0.6553\n",
      "Epoch 64/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 0.6621\n",
      "Epoch 65/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 0.6466\n",
      "Epoch 66/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 0.6714\n",
      "Epoch 67/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 0.6660\n",
      "Epoch 68/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 0.6713\n",
      "Epoch 69/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 0.6803\n",
      "Epoch 70/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.6751\n",
      "Epoch 71/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 0.6853\n",
      "Epoch 72/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.6844\n",
      "Epoch 73/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.6787\n",
      "Epoch 74/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.6757\n",
      "Epoch 75/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.6592\n",
      "Epoch 76/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.6922\n",
      "Epoch 77/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6139 - val_loss: 0.6876\n",
      "Epoch 78/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.6710\n",
      "Epoch 79/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.7002\n",
      "Epoch 80/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 0.6996\n",
      "Epoch 81/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.6971\n",
      "Epoch 82/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6785\n",
      "Epoch 83/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.7068\n",
      "Epoch 84/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.6971\n",
      "Epoch 85/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6125 - val_loss: 0.7070\n",
      "Epoch 86/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.7138\n",
      "Epoch 87/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 0.7112\n",
      "Epoch 88/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 0.7096\n",
      "Epoch 89/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 0.7136\n",
      "Epoch 90/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 0.7165\n",
      "Epoch 91/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 0.7156\n",
      "Epoch 92/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.7170\n",
      "Epoch 93/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.7075\n",
      "Epoch 94/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.7252\n",
      "Epoch 95/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.7163\n",
      "Epoch 96/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.7252\n",
      "Epoch 97/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.7115\n",
      "Epoch 98/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.7133\n",
      "Epoch 99/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.7180\n",
      "Epoch 100/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.7209\n",
      "Epoch 101/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.7158\n",
      "Epoch 102/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.7189\n",
      "Epoch 103/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.7196\n",
      "Epoch 104/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.7252\n",
      "Epoch 105/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7300\n",
      "Epoch 106/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.7263\n",
      "Epoch 107/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.7243\n",
      "Epoch 108/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.7301\n",
      "Epoch 109/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.7350\n",
      "Epoch 110/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.7358\n",
      "Epoch 111/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.7255\n",
      "Epoch 112/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7434\n",
      "Epoch 113/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.7344\n",
      "Epoch 114/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.7336\n",
      "Epoch 115/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7272\n",
      "Epoch 116/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.7443\n",
      "Epoch 117/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6001 - val_loss: 0.7257\n",
      "Epoch 118/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.7300\n",
      "Epoch 119/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.7489\n",
      "Epoch 120/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5996 - val_loss: 0.7333\n",
      "Epoch 121/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.7404\n",
      "Epoch 122/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.7360\n",
      "Epoch 123/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.7243\n",
      "Epoch 124/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.7450\n",
      "Epoch 125/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5964 - val_loss: 0.7351\n",
      "Epoch 126/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.7407\n",
      "Epoch 127/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 0.7421\n",
      "Epoch 128/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 0.7497\n",
      "Epoch 129/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.7388\n",
      "Epoch 130/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 0.7463\n",
      "Epoch 131/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 0.7423\n",
      "Epoch 132/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 0.7514\n",
      "Epoch 133/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5956 - val_loss: 0.7476\n",
      "Epoch 134/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.7438\n",
      "Epoch 135/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.7347\n",
      "Epoch 136/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 0.7511\n",
      "Epoch 137/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 0.7530\n",
      "Epoch 138/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.7514\n",
      "Epoch 139/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.7677\n",
      "Epoch 140/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5964 - val_loss: 0.7565\n",
      "Epoch 141/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7559\n",
      "Epoch 142/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.7590\n",
      "Epoch 143/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5916 - val_loss: 0.7478\n",
      "Epoch 144/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7574\n",
      "Epoch 145/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 0.7578\n",
      "Epoch 146/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 0.7664\n",
      "Epoch 147/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 0.7511\n",
      "Epoch 148/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5950 - val_loss: 0.7717\n",
      "Epoch 149/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5912 - val_loss: 0.7517\n",
      "Epoch 150/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5939 - val_loss: 0.7650\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:39<02:39, 39.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "76/76 [==============================] - 1s 5ms/step - loss: 0.9687 - val_loss: 0.7145\n",
      "Epoch 2/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8932 - val_loss: 0.6228\n",
      "Epoch 3/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8119 - val_loss: 0.5546\n",
      "Epoch 4/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7557 - val_loss: 0.5183\n",
      "Epoch 5/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7308 - val_loss: 0.5040\n",
      "Epoch 6/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7170 - val_loss: 0.5032\n",
      "Epoch 7/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7091 - val_loss: 0.5033\n",
      "Epoch 8/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7029 - val_loss: 0.5075\n",
      "Epoch 9/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6974 - val_loss: 0.5114\n",
      "Epoch 10/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6938 - val_loss: 0.5145\n",
      "Epoch 11/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6887 - val_loss: 0.5167\n",
      "Epoch 12/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 0.5238\n",
      "Epoch 13/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6833 - val_loss: 0.5286\n",
      "Epoch 14/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6785 - val_loss: 0.5296\n",
      "Epoch 15/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6756 - val_loss: 0.5372\n",
      "Epoch 16/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6721 - val_loss: 0.5395\n",
      "Epoch 17/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6666 - val_loss: 0.5434\n",
      "Epoch 18/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6652 - val_loss: 0.5521\n",
      "Epoch 19/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.5475\n",
      "Epoch 20/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6582 - val_loss: 0.5555\n",
      "Epoch 21/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6580 - val_loss: 0.5645\n",
      "Epoch 22/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6541 - val_loss: 0.5640\n",
      "Epoch 23/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.5697\n",
      "Epoch 24/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6474 - val_loss: 0.5738\n",
      "Epoch 25/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6482 - val_loss: 0.5819\n",
      "Epoch 26/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6444 - val_loss: 0.5810\n",
      "Epoch 27/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 0.5894\n",
      "Epoch 28/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6394 - val_loss: 0.5849\n",
      "Epoch 29/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6394 - val_loss: 0.5978\n",
      "Epoch 30/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6379 - val_loss: 0.5971\n",
      "Epoch 31/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6361 - val_loss: 0.6079\n",
      "Epoch 32/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6350 - val_loss: 0.6089\n",
      "Epoch 33/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6340 - val_loss: 0.6186\n",
      "Epoch 34/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6349 - val_loss: 0.6010\n",
      "Epoch 35/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6326 - val_loss: 0.6362\n",
      "Epoch 36/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6337 - val_loss: 0.6265\n",
      "Epoch 37/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6314 - val_loss: 0.6254\n",
      "Epoch 38/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6298 - val_loss: 0.6231\n",
      "Epoch 39/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6281 - val_loss: 0.6412\n",
      "Epoch 40/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 0.6387\n",
      "Epoch 41/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6280 - val_loss: 0.6493\n",
      "Epoch 42/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6254 - val_loss: 0.6448\n",
      "Epoch 43/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 0.6471\n",
      "Epoch 44/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 0.6503\n",
      "Epoch 45/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.6491\n",
      "Epoch 46/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6229 - val_loss: 0.6582\n",
      "Epoch 47/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.6612\n",
      "Epoch 48/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6592\n",
      "Epoch 49/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 0.6570\n",
      "Epoch 50/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 0.6685\n",
      "Epoch 51/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 0.6667\n",
      "Epoch 52/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 0.6749\n",
      "Epoch 53/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6194 - val_loss: 0.6785\n",
      "Epoch 54/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 0.6801\n",
      "Epoch 55/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.6797\n",
      "Epoch 56/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 0.6825\n",
      "Epoch 57/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 0.6746\n",
      "Epoch 58/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.6778\n",
      "Epoch 59/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.6829\n",
      "Epoch 60/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 0.6629\n",
      "Epoch 61/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6150 - val_loss: 0.6851\n",
      "Epoch 62/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6796\n",
      "Epoch 63/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.6847\n",
      "Epoch 64/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 0.6896\n",
      "Epoch 65/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6725\n",
      "Epoch 66/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6924\n",
      "Epoch 67/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 0.6916\n",
      "Epoch 68/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.7027\n",
      "Epoch 69/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 0.6995\n",
      "Epoch 70/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 0.7009\n",
      "Epoch 71/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.7153\n",
      "Epoch 72/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.7086\n",
      "Epoch 73/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.7005\n",
      "Epoch 74/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.7085\n",
      "Epoch 75/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.7042\n",
      "Epoch 76/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6089 - val_loss: 0.6841\n",
      "Epoch 77/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.7095\n",
      "Epoch 78/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.7056\n",
      "Epoch 79/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.7111\n",
      "Epoch 80/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.7102\n",
      "Epoch 81/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.6983\n",
      "Epoch 82/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.7104\n",
      "Epoch 83/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.7218\n",
      "Epoch 84/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.7089\n",
      "Epoch 85/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.7095\n",
      "Epoch 86/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.7168\n",
      "Epoch 87/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5997 - val_loss: 0.7065\n",
      "Epoch 88/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5990 - val_loss: 0.7102\n",
      "Epoch 89/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.7160\n",
      "Epoch 90/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5985 - val_loss: 0.7072\n",
      "Epoch 91/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6023 - val_loss: 0.7211\n",
      "Epoch 92/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5959 - val_loss: 0.7217\n",
      "Epoch 93/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.7194\n",
      "Epoch 94/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 0.7227\n",
      "Epoch 95/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.7168\n",
      "Epoch 96/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.7166\n",
      "Epoch 97/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7071\n",
      "Epoch 98/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 0.7210\n",
      "Epoch 99/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5950 - val_loss: 0.7254\n",
      "Epoch 100/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5938 - val_loss: 0.7295\n",
      "Epoch 101/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7232\n",
      "Epoch 102/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5919 - val_loss: 0.7227\n",
      "Epoch 103/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5908 - val_loss: 0.7246\n",
      "Epoch 104/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5957 - val_loss: 0.7173\n",
      "Epoch 105/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 0.7389\n",
      "Epoch 106/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5923 - val_loss: 0.7278\n",
      "Epoch 107/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7267\n",
      "Epoch 108/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5894 - val_loss: 0.7297\n",
      "Epoch 109/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 0.7429\n",
      "Epoch 110/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5925 - val_loss: 0.7086\n",
      "Epoch 111/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5870 - val_loss: 0.7221\n",
      "Epoch 112/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5908 - val_loss: 0.7403\n",
      "Epoch 113/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5903 - val_loss: 0.7282\n",
      "Epoch 114/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5900 - val_loss: 0.7279\n",
      "Epoch 115/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5865 - val_loss: 0.7345\n",
      "Epoch 116/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5887 - val_loss: 0.7357\n",
      "Epoch 117/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7272\n",
      "Epoch 118/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5859 - val_loss: 0.7212\n",
      "Epoch 119/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7414\n",
      "Epoch 120/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.7201\n",
      "Epoch 121/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5875 - val_loss: 0.7388\n",
      "Epoch 122/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5854 - val_loss: 0.7332\n",
      "Epoch 123/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.7336\n",
      "Epoch 124/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.7252\n",
      "Epoch 125/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5866 - val_loss: 0.7195\n",
      "Epoch 126/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5856 - val_loss: 0.7347\n",
      "Epoch 127/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5836 - val_loss: 0.7240\n",
      "Epoch 128/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.7328\n",
      "Epoch 129/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5812 - val_loss: 0.7336\n",
      "Epoch 130/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5835 - val_loss: 0.7286\n",
      "Epoch 131/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5842 - val_loss: 0.7289\n",
      "Epoch 132/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5818 - val_loss: 0.7175\n",
      "Epoch 133/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5864 - val_loss: 0.7269\n",
      "Epoch 134/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7338\n",
      "Epoch 135/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5809 - val_loss: 0.7235\n",
      "Epoch 136/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5785 - val_loss: 0.7284\n",
      "Epoch 137/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.7393\n",
      "Epoch 138/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.7362\n",
      "Epoch 139/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7290\n",
      "Epoch 140/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7428\n",
      "Epoch 141/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5771 - val_loss: 0.7437\n",
      "Epoch 142/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5778 - val_loss: 0.7536\n",
      "Epoch 143/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5806 - val_loss: 0.7343\n",
      "Epoch 144/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5781 - val_loss: 0.7425\n",
      "Epoch 145/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5757 - val_loss: 0.7394\n",
      "Epoch 146/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5753 - val_loss: 0.7411\n",
      "Epoch 147/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5749 - val_loss: 0.7373\n",
      "Epoch 148/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5779 - val_loss: 0.7423\n",
      "Epoch 149/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5775 - val_loss: 0.7284\n",
      "Epoch 150/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5762 - val_loss: 0.7351\n",
      "Epoch 151/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5762 - val_loss: 0.7324\n",
      "Epoch 152/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5747 - val_loss: 0.7405\n",
      "Epoch 153/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5752 - val_loss: 0.7378\n",
      "Epoch 154/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5773 - val_loss: 0.7480\n",
      "Epoch 155/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5720 - val_loss: 0.7366\n",
      "Epoch 156/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5767 - val_loss: 0.7371\n",
      "Epoch 157/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5750 - val_loss: 0.7468\n",
      "Epoch 158/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5698 - val_loss: 0.7387\n",
      "Epoch 159/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5724 - val_loss: 0.7527\n",
      "Epoch 160/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5733 - val_loss: 0.7545\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:27<02:13, 44.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9785 - val_loss: 0.7254\n",
      "Epoch 2/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8835 - val_loss: 0.6215\n",
      "Epoch 3/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7971 - val_loss: 0.5613\n",
      "Epoch 4/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.5341\n",
      "Epoch 5/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7379 - val_loss: 0.5211\n",
      "Epoch 6/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7267 - val_loss: 0.5161\n",
      "Epoch 7/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7206 - val_loss: 0.5103\n",
      "Epoch 8/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7129 - val_loss: 0.5137\n",
      "Epoch 9/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7081 - val_loss: 0.5145\n",
      "Epoch 10/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7015 - val_loss: 0.5145\n",
      "Epoch 11/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6979 - val_loss: 0.5183\n",
      "Epoch 12/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6940 - val_loss: 0.5199\n",
      "Epoch 13/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.5244\n",
      "Epoch 14/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6868 - val_loss: 0.5199\n",
      "Epoch 15/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6796 - val_loss: 0.5375\n",
      "Epoch 16/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6759 - val_loss: 0.5379\n",
      "Epoch 17/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6744 - val_loss: 0.5410\n",
      "Epoch 18/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6719 - val_loss: 0.5456\n",
      "Epoch 19/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6688 - val_loss: 0.5511\n",
      "Epoch 20/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6655 - val_loss: 0.5443\n",
      "Epoch 21/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.5595\n",
      "Epoch 22/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.5584\n",
      "Epoch 23/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.5618\n",
      "Epoch 24/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6554 - val_loss: 0.5727\n",
      "Epoch 25/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.5762\n",
      "Epoch 26/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6512 - val_loss: 0.5697\n",
      "Epoch 27/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.5973\n",
      "Epoch 28/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.5944\n",
      "Epoch 29/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6443 - val_loss: 0.5993\n",
      "Epoch 30/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6017\n",
      "Epoch 31/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6023\n",
      "Epoch 32/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6082\n",
      "Epoch 33/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.6093\n",
      "Epoch 34/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6391 - val_loss: 0.6085\n",
      "Epoch 35/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6367 - val_loss: 0.6179\n",
      "Epoch 36/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6257\n",
      "Epoch 37/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6215\n",
      "Epoch 38/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6312\n",
      "Epoch 39/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.6348\n",
      "Epoch 40/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6391\n",
      "Epoch 41/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6379\n",
      "Epoch 42/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.6431\n",
      "Epoch 43/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6341\n",
      "Epoch 44/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6290 - val_loss: 0.6394\n",
      "Epoch 45/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.6472\n",
      "Epoch 46/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.6536\n",
      "Epoch 47/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 0.6477\n",
      "Epoch 48/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6229 - val_loss: 0.6571\n",
      "Epoch 49/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.6640\n",
      "Epoch 50/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6528\n",
      "Epoch 51/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.6585\n",
      "Epoch 52/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.6509\n",
      "Epoch 53/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6208 - val_loss: 0.6760\n",
      "Epoch 54/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 0.6701\n",
      "Epoch 55/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 0.6817\n",
      "Epoch 56/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6184 - val_loss: 0.6763\n",
      "Epoch 57/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6178 - val_loss: 0.6836\n",
      "Epoch 58/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6198 - val_loss: 0.6818\n",
      "Epoch 59/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6174 - val_loss: 0.6878\n",
      "Epoch 60/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.6819\n",
      "Epoch 61/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6168 - val_loss: 0.6812\n",
      "Epoch 62/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6909\n",
      "Epoch 63/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6862\n",
      "Epoch 64/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6123 - val_loss: 0.6861\n",
      "Epoch 65/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6118 - val_loss: 0.6860\n",
      "Epoch 66/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6957\n",
      "Epoch 67/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6110 - val_loss: 0.7037\n",
      "Epoch 68/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6101 - val_loss: 0.6948\n",
      "Epoch 69/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6145 - val_loss: 0.6652\n",
      "Epoch 70/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.7126\n",
      "Epoch 71/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6903\n",
      "Epoch 72/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.7008\n",
      "Epoch 73/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6928\n",
      "Epoch 74/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6085 - val_loss: 0.7062\n",
      "Epoch 75/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.7017\n",
      "Epoch 76/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.7099\n",
      "Epoch 77/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6992\n",
      "Epoch 78/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6057 - val_loss: 0.7096\n",
      "Epoch 79/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6054 - val_loss: 0.7031\n",
      "Epoch 80/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6063 - val_loss: 0.6831\n",
      "Epoch 81/170\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6101 - val_loss: 0.7142\n",
      "Epoch 82/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6062 - val_loss: 0.7192\n",
      "Epoch 83/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6032 - val_loss: 0.7051\n",
      "Epoch 84/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6064 - val_loss: 0.7129\n",
      "Epoch 85/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.7105\n",
      "Epoch 86/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.7018\n",
      "Epoch 87/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.7142\n",
      "Epoch 88/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.7225\n",
      "Epoch 89/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6031 - val_loss: 0.7063\n",
      "Epoch 90/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.7251\n",
      "Epoch 91/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.7173\n",
      "Epoch 92/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.7178\n",
      "Epoch 93/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6015 - val_loss: 0.7041\n",
      "Epoch 94/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.7196\n",
      "Epoch 95/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5962 - val_loss: 0.7206\n",
      "Epoch 96/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.7318\n",
      "Epoch 97/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5951 - val_loss: 0.7199\n",
      "Epoch 98/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.7225\n",
      "Epoch 99/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5956 - val_loss: 0.7185\n",
      "Epoch 100/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5951 - val_loss: 0.7253\n",
      "Epoch 101/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5972 - val_loss: 0.7329\n",
      "Epoch 102/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5960 - val_loss: 0.7030\n",
      "Epoch 103/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.7296\n",
      "Epoch 104/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7166\n",
      "Epoch 105/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7094\n",
      "Epoch 106/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5907 - val_loss: 0.7128\n",
      "Epoch 107/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5890 - val_loss: 0.7204\n",
      "Epoch 108/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5931 - val_loss: 0.7264\n",
      "Epoch 109/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5911 - val_loss: 0.7285\n",
      "Epoch 110/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5921 - val_loss: 0.7386\n",
      "Epoch 111/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7335\n",
      "Epoch 112/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.7453\n",
      "Epoch 113/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.7253\n",
      "Epoch 114/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5871 - val_loss: 0.7323\n",
      "Epoch 115/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.7282\n",
      "Epoch 116/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5894 - val_loss: 0.7293\n",
      "Epoch 117/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5874 - val_loss: 0.7212\n",
      "Epoch 118/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5878 - val_loss: 0.7313\n",
      "Epoch 119/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.7071\n",
      "Epoch 120/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5810 - val_loss: 0.7262\n",
      "Epoch 121/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5834 - val_loss: 0.7260\n",
      "Epoch 122/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5846 - val_loss: 0.7427\n",
      "Epoch 123/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5828 - val_loss: 0.7281\n",
      "Epoch 124/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.7395\n",
      "Epoch 125/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5812 - val_loss: 0.7281\n",
      "Epoch 126/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7342\n",
      "Epoch 127/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5828 - val_loss: 0.7396\n",
      "Epoch 128/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5813 - val_loss: 0.7081\n",
      "Epoch 129/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5940 - val_loss: 0.7593\n",
      "Epoch 130/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5805 - val_loss: 0.7506\n",
      "Epoch 131/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5811 - val_loss: 0.7470\n",
      "Epoch 132/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5780 - val_loss: 0.7494\n",
      "Epoch 133/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5755 - val_loss: 0.7360\n",
      "Epoch 134/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5799 - val_loss: 0.7466\n",
      "Epoch 135/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.7388\n",
      "Epoch 136/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5790 - val_loss: 0.7400\n",
      "Epoch 137/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7400\n",
      "Epoch 138/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5788 - val_loss: 0.7377\n",
      "Epoch 139/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5766 - val_loss: 0.7394\n",
      "Epoch 140/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5751 - val_loss: 0.7450\n",
      "Epoch 141/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5720 - val_loss: 0.7470\n",
      "Epoch 142/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5753 - val_loss: 0.7547\n",
      "Epoch 143/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5748 - val_loss: 0.7419\n",
      "Epoch 144/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5759 - val_loss: 0.7297\n",
      "Epoch 145/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5731 - val_loss: 0.7569\n",
      "Epoch 146/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5711 - val_loss: 0.7328\n",
      "Epoch 147/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5766 - val_loss: 0.7437\n",
      "Epoch 148/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5720 - val_loss: 0.7234\n",
      "Epoch 149/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5721 - val_loss: 0.7644\n",
      "Epoch 150/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5712 - val_loss: 0.7533\n",
      "Epoch 151/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5697 - val_loss: 0.7437\n",
      "Epoch 152/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5714 - val_loss: 0.7439\n",
      "Epoch 153/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5716 - val_loss: 0.7602\n",
      "Epoch 154/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5718 - val_loss: 0.7518\n",
      "Epoch 155/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5663 - val_loss: 0.7527\n",
      "Epoch 156/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5661 - val_loss: 0.7397\n",
      "Epoch 157/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5725 - val_loss: 0.7523\n",
      "Epoch 158/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5697 - val_loss: 0.7265\n",
      "Epoch 159/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5662 - val_loss: 0.7576\n",
      "Epoch 160/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5669 - val_loss: 0.7555\n",
      "Epoch 161/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5677 - val_loss: 0.7611\n",
      "Epoch 162/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5652 - val_loss: 0.7472\n",
      "Epoch 163/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5653 - val_loss: 0.7512\n",
      "Epoch 164/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5658 - val_loss: 0.7553\n",
      "Epoch 165/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5676 - val_loss: 0.7418\n",
      "Epoch 166/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5640 - val_loss: 0.7682\n",
      "Epoch 167/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5645 - val_loss: 0.7512\n",
      "Epoch 168/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5669 - val_loss: 0.7531\n",
      "Epoch 169/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5657 - val_loss: 0.7496\n",
      "Epoch 170/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5689 - val_loss: 0.7605\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:26<01:42, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9952 - val_loss: 0.7502\n",
      "Epoch 2/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.9221 - val_loss: 0.6498\n",
      "Epoch 3/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8188 - val_loss: 0.5614\n",
      "Epoch 4/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7630 - val_loss: 0.5248\n",
      "Epoch 5/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7413 - val_loss: 0.5118\n",
      "Epoch 6/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7256 - val_loss: 0.5067\n",
      "Epoch 7/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7182 - val_loss: 0.5046\n",
      "Epoch 8/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7073 - val_loss: 0.5044\n",
      "Epoch 9/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7012 - val_loss: 0.5060\n",
      "Epoch 10/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6940 - val_loss: 0.5049\n",
      "Epoch 11/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6887 - val_loss: 0.5087\n",
      "Epoch 12/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6831 - val_loss: 0.5092\n",
      "Epoch 13/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6794 - val_loss: 0.5102\n",
      "Epoch 14/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6765 - val_loss: 0.5144\n",
      "Epoch 15/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6707 - val_loss: 0.5144\n",
      "Epoch 16/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6662 - val_loss: 0.5257\n",
      "Epoch 17/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6647 - val_loss: 0.5273\n",
      "Epoch 18/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6603 - val_loss: 0.5255\n",
      "Epoch 19/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.5326\n",
      "Epoch 20/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.5331\n",
      "Epoch 21/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.5341\n",
      "Epoch 22/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.5479\n",
      "Epoch 23/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.5488\n",
      "Epoch 24/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6466 - val_loss: 0.5591\n",
      "Epoch 25/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6462 - val_loss: 0.5567\n",
      "Epoch 26/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6443 - val_loss: 0.5669\n",
      "Epoch 27/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6422 - val_loss: 0.5631\n",
      "Epoch 28/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6416 - val_loss: 0.5726\n",
      "Epoch 29/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6384 - val_loss: 0.5764\n",
      "Epoch 30/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6375 - val_loss: 0.5837\n",
      "Epoch 31/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6371 - val_loss: 0.5864\n",
      "Epoch 32/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.5833\n",
      "Epoch 33/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6334 - val_loss: 0.5847\n",
      "Epoch 34/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.5950\n",
      "Epoch 35/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.5878\n",
      "Epoch 36/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6342 - val_loss: 0.5985\n",
      "Epoch 37/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6305 - val_loss: 0.6034\n",
      "Epoch 38/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.5998\n",
      "Epoch 39/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 0.6092\n",
      "Epoch 40/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6264 - val_loss: 0.6108\n",
      "Epoch 41/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6269 - val_loss: 0.6239\n",
      "Epoch 42/180\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6251 - val_loss: 0.6173\n",
      "Epoch 43/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6281 - val_loss: 0.6175\n",
      "Epoch 44/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.6268\n",
      "Epoch 45/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6237 - val_loss: 0.6210\n",
      "Epoch 46/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.6248\n",
      "Epoch 47/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.6384\n",
      "Epoch 48/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6205 - val_loss: 0.6305\n",
      "Epoch 49/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.6373\n",
      "Epoch 50/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6214 - val_loss: 0.6213\n",
      "Epoch 51/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6557\n",
      "Epoch 52/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.6497\n",
      "Epoch 53/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6616\n",
      "Epoch 54/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6545\n",
      "Epoch 55/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6188 - val_loss: 0.6552\n",
      "Epoch 56/180\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6196 - val_loss: 0.6460\n",
      "Epoch 57/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6701\n",
      "Epoch 58/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6741\n",
      "Epoch 59/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 0.6718\n",
      "Epoch 60/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6145 - val_loss: 0.6647\n",
      "Epoch 61/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6175 - val_loss: 0.6623\n",
      "Epoch 62/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6147 - val_loss: 0.6722\n",
      "Epoch 63/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6136 - val_loss: 0.6795\n",
      "Epoch 64/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6721\n",
      "Epoch 65/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6130 - val_loss: 0.6756\n",
      "Epoch 66/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.6638\n",
      "Epoch 67/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6845\n",
      "Epoch 68/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6092 - val_loss: 0.6794\n",
      "Epoch 69/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6108 - val_loss: 0.6913\n",
      "Epoch 70/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6110 - val_loss: 0.6886\n",
      "Epoch 71/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.6823\n",
      "Epoch 72/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.6876\n",
      "Epoch 73/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6968\n",
      "Epoch 74/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6891\n",
      "Epoch 75/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6685\n",
      "Epoch 76/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6071 - val_loss: 0.7051\n",
      "Epoch 77/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6827\n",
      "Epoch 78/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6028 - val_loss: 0.6856\n",
      "Epoch 79/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6956\n",
      "Epoch 80/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6919\n",
      "Epoch 81/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6989\n",
      "Epoch 82/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6898\n",
      "Epoch 83/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6892\n",
      "Epoch 84/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.7003\n",
      "Epoch 85/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.7025\n",
      "Epoch 86/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.7021\n",
      "Epoch 87/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5985 - val_loss: 0.7004\n",
      "Epoch 88/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.7036\n",
      "Epoch 89/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.7021\n",
      "Epoch 90/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5975 - val_loss: 0.6942\n",
      "Epoch 91/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.6975\n",
      "Epoch 92/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.7068\n",
      "Epoch 93/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.7141\n",
      "Epoch 94/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5955 - val_loss: 0.7030\n",
      "Epoch 95/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5934 - val_loss: 0.7073\n",
      "Epoch 96/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5954 - val_loss: 0.7040\n",
      "Epoch 97/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5964 - val_loss: 0.6993\n",
      "Epoch 98/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5960 - val_loss: 0.7129\n",
      "Epoch 99/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5909 - val_loss: 0.7196\n",
      "Epoch 100/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5942 - val_loss: 0.6962\n",
      "Epoch 101/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5897 - val_loss: 0.7224\n",
      "Epoch 102/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7313\n",
      "Epoch 103/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5936 - val_loss: 0.6897\n",
      "Epoch 104/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5915 - val_loss: 0.7280\n",
      "Epoch 105/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 0.7211\n",
      "Epoch 106/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5897 - val_loss: 0.7173\n",
      "Epoch 107/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5912 - val_loss: 0.7254\n",
      "Epoch 108/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5884 - val_loss: 0.7328\n",
      "Epoch 109/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5886 - val_loss: 0.7297\n",
      "Epoch 110/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7227\n",
      "Epoch 111/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5864 - val_loss: 0.7228\n",
      "Epoch 112/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7239\n",
      "Epoch 113/180\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5864 - val_loss: 0.7163\n",
      "Epoch 114/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.7296\n",
      "Epoch 115/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.7275\n",
      "Epoch 116/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5856 - val_loss: 0.7429\n",
      "Epoch 117/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5811 - val_loss: 0.7266\n",
      "Epoch 118/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5824 - val_loss: 0.7312\n",
      "Epoch 119/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7344\n",
      "Epoch 120/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5827 - val_loss: 0.7378\n",
      "Epoch 121/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5806 - val_loss: 0.7266\n",
      "Epoch 122/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7301\n",
      "Epoch 123/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7336\n",
      "Epoch 124/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5801 - val_loss: 0.7408\n",
      "Epoch 125/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.7247\n",
      "Epoch 126/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5824 - val_loss: 0.7388\n",
      "Epoch 127/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.7326\n",
      "Epoch 128/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5818 - val_loss: 0.7405\n",
      "Epoch 129/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7261\n",
      "Epoch 130/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5782 - val_loss: 0.7393\n",
      "Epoch 131/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5783 - val_loss: 0.7242\n",
      "Epoch 132/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5760 - val_loss: 0.7382\n",
      "Epoch 133/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5794 - val_loss: 0.7422\n",
      "Epoch 134/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5770 - val_loss: 0.7376\n",
      "Epoch 135/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.7445\n",
      "Epoch 136/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5752 - val_loss: 0.7427\n",
      "Epoch 137/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5801 - val_loss: 0.7518\n",
      "Epoch 138/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5752 - val_loss: 0.7395\n",
      "Epoch 139/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5750 - val_loss: 0.7376\n",
      "Epoch 140/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5770 - val_loss: 0.7423\n",
      "Epoch 141/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5721 - val_loss: 0.7462\n",
      "Epoch 142/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5761 - val_loss: 0.7463\n",
      "Epoch 143/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5746 - val_loss: 0.7394\n",
      "Epoch 144/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5750 - val_loss: 0.7474\n",
      "Epoch 145/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5716 - val_loss: 0.7292\n",
      "Epoch 146/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5701 - val_loss: 0.7460\n",
      "Epoch 147/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5776 - val_loss: 0.7567\n",
      "Epoch 148/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5767 - val_loss: 0.7579\n",
      "Epoch 149/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5706 - val_loss: 0.7595\n",
      "Epoch 150/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5709 - val_loss: 0.7620\n",
      "Epoch 151/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5712 - val_loss: 0.7425\n",
      "Epoch 152/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5702 - val_loss: 0.7502\n",
      "Epoch 153/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5660 - val_loss: 0.7500\n",
      "Epoch 154/180\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5707 - val_loss: 0.7479\n",
      "Epoch 155/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5685 - val_loss: 0.7518\n",
      "Epoch 156/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5659 - val_loss: 0.7462\n",
      "Epoch 157/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5663 - val_loss: 0.7530\n",
      "Epoch 158/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5702 - val_loss: 0.7383\n",
      "Epoch 159/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5688 - val_loss: 0.7216\n",
      "Epoch 160/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5653 - val_loss: 0.7616\n",
      "Epoch 161/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5673 - val_loss: 0.7704\n",
      "Epoch 162/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5614 - val_loss: 0.7741\n",
      "Epoch 163/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5638 - val_loss: 0.7370\n",
      "Epoch 164/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5608 - val_loss: 0.7582\n",
      "Epoch 165/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5624 - val_loss: 0.7718\n",
      "Epoch 166/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5578 - val_loss: 0.7474\n",
      "Epoch 167/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5628 - val_loss: 0.7479\n",
      "Epoch 168/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5624 - val_loss: 0.7588\n",
      "Epoch 169/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5613 - val_loss: 0.7426\n",
      "Epoch 170/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5551 - val_loss: 0.7599\n",
      "Epoch 171/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5622 - val_loss: 0.7676\n",
      "Epoch 172/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5596 - val_loss: 0.7716\n",
      "Epoch 173/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5559 - val_loss: 0.7623\n",
      "Epoch 174/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5517 - val_loss: 0.7682\n",
      "Epoch 175/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5550 - val_loss: 0.7593\n",
      "Epoch 176/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5573 - val_loss: 0.7738\n",
      "Epoch 177/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5538 - val_loss: 0.7735\n",
      "Epoch 178/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5506 - val_loss: 0.7680\n",
      "Epoch 179/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5563 - val_loss: 0.7616\n",
      "Epoch 180/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5540 - val_loss: 0.7625\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:29<00:55, 55.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/190\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9806 - val_loss: 0.7254\n",
      "Epoch 2/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8891 - val_loss: 0.6159\n",
      "Epoch 3/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7922 - val_loss: 0.5470\n",
      "Epoch 4/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7517 - val_loss: 0.5243\n",
      "Epoch 5/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7351 - val_loss: 0.5167\n",
      "Epoch 6/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7220 - val_loss: 0.5139\n",
      "Epoch 7/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7162 - val_loss: 0.5130\n",
      "Epoch 8/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7099 - val_loss: 0.5154\n",
      "Epoch 9/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7039 - val_loss: 0.5161\n",
      "Epoch 10/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6994 - val_loss: 0.5207\n",
      "Epoch 11/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6966 - val_loss: 0.5228\n",
      "Epoch 12/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6934 - val_loss: 0.5260\n",
      "Epoch 13/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.5272\n",
      "Epoch 14/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.5298\n",
      "Epoch 15/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6861 - val_loss: 0.5334\n",
      "Epoch 16/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6842 - val_loss: 0.5366\n",
      "Epoch 17/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.5390\n",
      "Epoch 18/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6784 - val_loss: 0.5438\n",
      "Epoch 19/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6780 - val_loss: 0.5465\n",
      "Epoch 20/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6751 - val_loss: 0.5457\n",
      "Epoch 21/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6738 - val_loss: 0.5532\n",
      "Epoch 22/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6717 - val_loss: 0.5550\n",
      "Epoch 23/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6724 - val_loss: 0.5499\n",
      "Epoch 24/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6678 - val_loss: 0.5630\n",
      "Epoch 25/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6656 - val_loss: 0.5655\n",
      "Epoch 26/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6664 - val_loss: 0.5701\n",
      "Epoch 27/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6666 - val_loss: 0.5752\n",
      "Epoch 28/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6633 - val_loss: 0.5808\n",
      "Epoch 29/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6626 - val_loss: 0.5777\n",
      "Epoch 30/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.5798\n",
      "Epoch 31/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6616 - val_loss: 0.5680\n",
      "Epoch 32/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6593 - val_loss: 0.5875\n",
      "Epoch 33/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6577 - val_loss: 0.5878\n",
      "Epoch 34/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6580 - val_loss: 0.5909\n",
      "Epoch 35/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6560 - val_loss: 0.5917\n",
      "Epoch 36/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.5968\n",
      "Epoch 37/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.5977\n",
      "Epoch 38/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.5984\n",
      "Epoch 39/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6041\n",
      "Epoch 40/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6085\n",
      "Epoch 41/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6050\n",
      "Epoch 42/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6069\n",
      "Epoch 43/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.6064\n",
      "Epoch 44/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6077\n",
      "Epoch 45/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.6063\n",
      "Epoch 46/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6454 - val_loss: 0.6152\n",
      "Epoch 47/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6177\n",
      "Epoch 48/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6423 - val_loss: 0.6011\n",
      "Epoch 49/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6403 - val_loss: 0.6332\n",
      "Epoch 50/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6422 - val_loss: 0.6349\n",
      "Epoch 51/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6392 - val_loss: 0.6328\n",
      "Epoch 52/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6389 - val_loss: 0.6381\n",
      "Epoch 53/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.6364\n",
      "Epoch 54/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 0.6341\n",
      "Epoch 55/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6354 - val_loss: 0.6398\n",
      "Epoch 56/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6341 - val_loss: 0.6377\n",
      "Epoch 57/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.6380\n",
      "Epoch 58/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6459\n",
      "Epoch 59/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6328 - val_loss: 0.6403\n",
      "Epoch 60/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6317 - val_loss: 0.6483\n",
      "Epoch 61/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6277 - val_loss: 0.6446\n",
      "Epoch 62/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6293 - val_loss: 0.6411\n",
      "Epoch 63/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6296 - val_loss: 0.6515\n",
      "Epoch 64/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6484\n",
      "Epoch 65/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6281 - val_loss: 0.6529\n",
      "Epoch 66/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6555\n",
      "Epoch 67/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.6533\n",
      "Epoch 68/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6509\n",
      "Epoch 69/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.6545\n",
      "Epoch 70/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.6531\n",
      "Epoch 71/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6256 - val_loss: 0.6514\n",
      "Epoch 72/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6227 - val_loss: 0.6562\n",
      "Epoch 73/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6234 - val_loss: 0.6552\n",
      "Epoch 74/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.6442\n",
      "Epoch 75/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6373\n",
      "Epoch 76/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.6568\n",
      "Epoch 77/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6196 - val_loss: 0.6479\n",
      "Epoch 78/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6437\n",
      "Epoch 79/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.6526\n",
      "Epoch 80/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6183 - val_loss: 0.6666\n",
      "Epoch 81/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6175 - val_loss: 0.6702\n",
      "Epoch 82/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6652\n",
      "Epoch 83/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.6633\n",
      "Epoch 84/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6638\n",
      "Epoch 85/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.6661\n",
      "Epoch 86/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.6667\n",
      "Epoch 87/190\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6145 - val_loss: 0.6706\n",
      "Epoch 88/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6736\n",
      "Epoch 89/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.6746\n",
      "Epoch 90/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6185 - val_loss: 0.6324\n",
      "Epoch 91/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.6750\n",
      "Epoch 92/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6150 - val_loss: 0.6727\n",
      "Epoch 93/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6669\n",
      "Epoch 94/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6121 - val_loss: 0.6654\n",
      "Epoch 95/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.6606\n",
      "Epoch 96/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6632\n",
      "Epoch 97/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6687\n",
      "Epoch 98/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6800\n",
      "Epoch 99/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6731\n",
      "Epoch 100/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6783\n",
      "Epoch 101/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6732\n",
      "Epoch 102/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6777\n",
      "Epoch 103/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6817\n",
      "Epoch 104/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.6752\n",
      "Epoch 105/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6103 - val_loss: 0.6814\n",
      "Epoch 106/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6758\n",
      "Epoch 107/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6797\n",
      "Epoch 108/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.6782\n",
      "Epoch 109/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6112 - val_loss: 0.6810\n",
      "Epoch 110/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6087 - val_loss: 0.6816\n",
      "Epoch 111/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6763\n",
      "Epoch 112/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6077 - val_loss: 0.6827\n",
      "Epoch 113/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6734\n",
      "Epoch 114/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.6840\n",
      "Epoch 115/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6849\n",
      "Epoch 116/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6815\n",
      "Epoch 117/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6067 - val_loss: 0.6945\n",
      "Epoch 118/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6070 - val_loss: 0.6982\n",
      "Epoch 119/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6051 - val_loss: 0.6884\n",
      "Epoch 120/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6868\n",
      "Epoch 121/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6922\n",
      "Epoch 122/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6052 - val_loss: 0.6777\n",
      "Epoch 123/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.6909\n",
      "Epoch 124/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7012\n",
      "Epoch 125/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6901\n",
      "Epoch 126/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.6818\n",
      "Epoch 127/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6979\n",
      "Epoch 128/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6031 - val_loss: 0.7063\n",
      "Epoch 129/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6956\n",
      "Epoch 130/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.7009\n",
      "Epoch 131/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6013 - val_loss: 0.6954\n",
      "Epoch 132/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.6901\n",
      "Epoch 133/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6918\n",
      "Epoch 134/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6025 - val_loss: 0.7041\n",
      "Epoch 135/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.7031\n",
      "Epoch 136/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6012 - val_loss: 0.6991\n",
      "Epoch 137/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6984\n",
      "Epoch 138/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.7033\n",
      "Epoch 139/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.7001\n",
      "Epoch 140/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.6935\n",
      "Epoch 141/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6002 - val_loss: 0.6817\n",
      "Epoch 142/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.7012\n",
      "Epoch 143/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.7030\n",
      "Epoch 144/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6008 - val_loss: 0.7015\n",
      "Epoch 145/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5990 - val_loss: 0.7160\n",
      "Epoch 146/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5924 - val_loss: 0.6865\n",
      "Epoch 147/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6021 - val_loss: 0.6940\n",
      "Epoch 148/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.6984\n",
      "Epoch 149/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6940\n",
      "Epoch 150/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.6932\n",
      "Epoch 151/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.6945\n",
      "Epoch 152/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5983 - val_loss: 0.7033\n",
      "Epoch 153/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5990 - val_loss: 0.7058\n",
      "Epoch 154/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5958 - val_loss: 0.6967\n",
      "Epoch 155/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5968 - val_loss: 0.7031\n",
      "Epoch 156/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.6834\n",
      "Epoch 157/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5969 - val_loss: 0.7148\n",
      "Epoch 158/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5941 - val_loss: 0.7064\n",
      "Epoch 159/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7046\n",
      "Epoch 160/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.7115\n",
      "Epoch 161/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7044\n",
      "Epoch 162/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.7018\n",
      "Epoch 163/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5963 - val_loss: 0.7046\n",
      "Epoch 164/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.6870\n",
      "Epoch 165/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5932 - val_loss: 0.7094\n",
      "Epoch 166/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7043\n",
      "Epoch 167/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5926 - val_loss: 0.7061\n",
      "Epoch 168/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.7085\n",
      "Epoch 169/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7099\n",
      "Epoch 170/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5940 - val_loss: 0.7181\n",
      "Epoch 171/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5926 - val_loss: 0.7066\n",
      "Epoch 172/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5934 - val_loss: 0.7046\n",
      "Epoch 173/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7094\n",
      "Epoch 174/190\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5935 - val_loss: 0.7127\n",
      "Epoch 175/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7130\n",
      "Epoch 176/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5943 - val_loss: 0.7099\n",
      "Epoch 177/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5916 - val_loss: 0.7169\n",
      "Epoch 178/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5934 - val_loss: 0.7143\n",
      "Epoch 179/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5902 - val_loss: 0.7124\n",
      "Epoch 180/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5910 - val_loss: 0.7165\n",
      "Epoch 181/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5948 - val_loss: 0.7060\n",
      "Epoch 182/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5891 - val_loss: 0.7088\n",
      "Epoch 183/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5935 - val_loss: 0.7229\n",
      "Epoch 184/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5893 - val_loss: 0.7131\n",
      "Epoch 185/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7143\n",
      "Epoch 186/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5888 - val_loss: 0.7146\n",
      "Epoch 187/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5884 - val_loss: 0.7033\n",
      "Epoch 188/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5909 - val_loss: 0.7007\n",
      "Epoch 189/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5889 - val_loss: 0.7064\n",
      "Epoch 190/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.6910\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:37<00:00, 55.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# r2_all=[]\n",
    "for item in tqdm(range(150,200,10)):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,item,8)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(r2_all)),r2_all)\n",
    "plt.xticks(range(len(r2_all)),range(10,200,10))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X_test[:100,:]\n",
    "y=y_test[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "76/76 [==============================] - 2s 10ms/step - loss: 0.9840 - val_loss: 0.2815\n",
      "Epoch 2/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.9100 - val_loss: 0.2042\n",
      "Epoch 3/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.8204 - val_loss: 0.1540\n",
      "Epoch 4/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7760 - val_loss: 0.1297\n",
      "Epoch 5/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7493 - val_loss: 0.1274\n",
      "Epoch 6/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7382 - val_loss: 0.1291\n",
      "Epoch 7/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7307 - val_loss: 0.1315\n",
      "Epoch 8/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7220 - val_loss: 0.1345\n",
      "Epoch 9/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7178 - val_loss: 0.1373\n",
      "Epoch 10/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7148 - val_loss: 0.1477\n",
      "Epoch 11/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7084 - val_loss: 0.1499\n",
      "Epoch 12/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7047 - val_loss: 0.1560\n",
      "Epoch 13/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7016 - val_loss: 0.1591\n",
      "Epoch 14/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6996 - val_loss: 0.1672\n",
      "Epoch 15/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6960 - val_loss: 0.1744\n",
      "Epoch 16/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6939 - val_loss: 0.1807\n",
      "Epoch 17/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6923 - val_loss: 0.1847\n",
      "Epoch 18/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6894 - val_loss: 0.1947\n",
      "Epoch 19/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6895 - val_loss: 0.1978\n",
      "Epoch 20/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6851 - val_loss: 0.2123\n",
      "Epoch 21/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6840 - val_loss: 0.2185\n",
      "Epoch 22/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6810 - val_loss: 0.2229\n",
      "Epoch 23/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6766 - val_loss: 0.2282\n",
      "Epoch 24/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6762 - val_loss: 0.2412\n",
      "Epoch 25/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6731 - val_loss: 0.2424\n",
      "Epoch 26/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6729 - val_loss: 0.2547\n",
      "Epoch 27/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6688 - val_loss: 0.2589\n",
      "Epoch 28/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6678 - val_loss: 0.2650\n",
      "Epoch 29/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6652 - val_loss: 0.2681\n",
      "Epoch 30/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6652 - val_loss: 0.2703\n",
      "Epoch 31/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6622 - val_loss: 0.2908\n",
      "Epoch 32/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6609 - val_loss: 0.2949\n",
      "Epoch 33/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6586 - val_loss: 0.3049\n",
      "Epoch 34/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6568 - val_loss: 0.2879\n",
      "Epoch 35/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6553 - val_loss: 0.3135\n",
      "Epoch 36/150\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6532 - val_loss: 0.3225\n",
      "Epoch 37/150\n",
      "76/76 [==============================] - 0s 7ms/step - loss: 0.6524 - val_loss: 0.3281\n",
      "Epoch 38/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6491 - val_loss: 0.3307\n",
      "Epoch 39/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6494 - val_loss: 0.3379\n",
      "Epoch 40/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6470 - val_loss: 0.3538\n",
      "Epoch 41/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6455 - val_loss: 0.3386\n",
      "Epoch 42/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6426 - val_loss: 0.3701\n",
      "Epoch 43/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6421 - val_loss: 0.3672\n",
      "Epoch 44/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6404 - val_loss: 0.3772\n",
      "Epoch 45/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6406 - val_loss: 0.3935\n",
      "Epoch 46/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6394 - val_loss: 0.3986\n",
      "Epoch 47/150\n",
      "76/76 [==============================] - 0s 7ms/step - loss: 0.6362 - val_loss: 0.4129\n",
      "Epoch 48/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6374 - val_loss: 0.4059\n",
      "Epoch 49/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6343 - val_loss: 0.4155\n",
      "Epoch 50/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6335 - val_loss: 0.4394\n",
      "Epoch 51/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6311 - val_loss: 0.4345\n",
      "Epoch 52/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6329 - val_loss: 0.4496\n",
      "Epoch 53/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6278 - val_loss: 0.4410\n",
      "Epoch 54/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6309 - val_loss: 0.4660\n",
      "Epoch 55/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6288 - val_loss: 0.4698\n",
      "Epoch 56/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6277 - val_loss: 0.4680\n",
      "Epoch 57/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6265 - val_loss: 0.4661\n",
      "Epoch 58/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6278 - val_loss: 0.4821\n",
      "Epoch 59/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6259 - val_loss: 0.4974\n",
      "Epoch 60/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6252 - val_loss: 0.4772\n",
      "Epoch 61/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6261 - val_loss: 0.5053\n",
      "Epoch 62/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.4988\n",
      "Epoch 63/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.4886\n",
      "Epoch 64/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.5104\n",
      "Epoch 65/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6228 - val_loss: 0.5101\n",
      "Epoch 66/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6215 - val_loss: 0.5246\n",
      "Epoch 67/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6226 - val_loss: 0.5358\n",
      "Epoch 68/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6185 - val_loss: 0.5030\n",
      "Epoch 69/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.5214\n",
      "Epoch 70/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.5358\n",
      "Epoch 71/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.5345\n",
      "Epoch 72/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6199 - val_loss: 0.5487\n",
      "Epoch 73/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.5572\n",
      "Epoch 74/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6178 - val_loss: 0.5418\n",
      "Epoch 75/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.5525\n",
      "Epoch 76/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6177 - val_loss: 0.5520\n",
      "Epoch 77/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6188 - val_loss: 0.5551\n",
      "Epoch 78/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6169 - val_loss: 0.5703\n",
      "Epoch 79/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6165 - val_loss: 0.5302\n",
      "Epoch 80/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6151 - val_loss: 0.5674\n",
      "Epoch 81/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6137 - val_loss: 0.5810\n",
      "Epoch 82/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6153 - val_loss: 0.5761\n",
      "Epoch 83/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6168 - val_loss: 0.5828\n",
      "Epoch 84/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6120 - val_loss: 0.5905\n",
      "Epoch 85/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6127 - val_loss: 0.5926\n",
      "Epoch 86/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6112 - val_loss: 0.5945\n",
      "Epoch 87/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.5947\n",
      "Epoch 88/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6089 - val_loss: 0.5988\n",
      "Epoch 89/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.5885\n",
      "Epoch 90/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6097 - val_loss: 0.6013\n",
      "Epoch 91/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.6086\n",
      "Epoch 92/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6093 - val_loss: 0.6048\n",
      "Epoch 93/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6080 - val_loss: 0.6118\n",
      "Epoch 94/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6081 - val_loss: 0.6144\n",
      "Epoch 95/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6062 - val_loss: 0.6047\n",
      "Epoch 96/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6085 - val_loss: 0.6159\n",
      "Epoch 97/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6063 - val_loss: 0.6150\n",
      "Epoch 98/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6057 - val_loss: 0.6304\n",
      "Epoch 99/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6050 - val_loss: 0.6155\n",
      "Epoch 100/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6060 - val_loss: 0.6312\n",
      "Epoch 101/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6059 - val_loss: 0.6027\n",
      "Epoch 102/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.6369\n",
      "Epoch 103/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6350\n",
      "Epoch 104/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6308\n",
      "Epoch 105/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6045 - val_loss: 0.6548\n",
      "Epoch 106/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6015 - val_loss: 0.6476\n",
      "Epoch 107/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.6403\n",
      "Epoch 108/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6012 - val_loss: 0.6465\n",
      "Epoch 109/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.6546\n",
      "Epoch 110/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.6418\n",
      "Epoch 111/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.6619\n",
      "Epoch 112/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.6700\n",
      "Epoch 113/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6568\n",
      "Epoch 114/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6014 - val_loss: 0.6536\n",
      "Epoch 115/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5996 - val_loss: 0.6769\n",
      "Epoch 116/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5971 - val_loss: 0.6589\n",
      "Epoch 117/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6378\n",
      "Epoch 118/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.6601\n",
      "Epoch 119/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5963 - val_loss: 0.6381\n",
      "Epoch 120/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6001 - val_loss: 0.6636\n",
      "Epoch 121/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5959 - val_loss: 0.6649\n",
      "Epoch 122/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5944 - val_loss: 0.6318\n",
      "Epoch 123/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.6634\n",
      "Epoch 124/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5951 - val_loss: 0.6247\n",
      "Epoch 125/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5953 - val_loss: 0.6685\n",
      "Epoch 126/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5977 - val_loss: 0.6432\n",
      "Epoch 127/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6702\n",
      "Epoch 128/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5941 - val_loss: 0.6767\n",
      "Epoch 129/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5940 - val_loss: 0.6447\n",
      "Epoch 130/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5942 - val_loss: 0.6835\n",
      "Epoch 131/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5932 - val_loss: 0.6779\n",
      "Epoch 132/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 0.6907\n",
      "Epoch 133/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5929 - val_loss: 0.6658\n",
      "Epoch 134/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5929 - val_loss: 0.6467\n",
      "Epoch 135/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5945 - val_loss: 0.6787\n",
      "Epoch 136/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5918 - val_loss: 0.6511\n",
      "Epoch 137/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5905 - val_loss: 0.6759\n",
      "Epoch 138/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5911 - val_loss: 0.6955\n",
      "Epoch 139/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5911 - val_loss: 0.6499\n",
      "Epoch 140/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5885 - val_loss: 0.6778\n",
      "Epoch 141/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5913 - val_loss: 0.6781\n",
      "Epoch 142/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.6776\n",
      "Epoch 143/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5903 - val_loss: 0.6722\n",
      "Epoch 144/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5891 - val_loss: 0.6808\n",
      "Epoch 145/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5880 - val_loss: 0.6763\n",
      "Epoch 146/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7134\n",
      "Epoch 147/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5893 - val_loss: 0.6673\n",
      "Epoch 148/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5871 - val_loss: 0.6798\n",
      "Epoch 149/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5888 - val_loss: 0.6497\n",
      "Epoch 150/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5903 - val_loss: 0.6587\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "history , r2=_compile_model(X_train,y_train,x,y,150,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.084627874795956"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
