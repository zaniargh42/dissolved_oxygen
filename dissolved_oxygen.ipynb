{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense  ,Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor ,ExtraTreesRegressor ,GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data():\n",
    "    train=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Training set 2011-2015')\n",
    "    train.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    test=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Testing set 2016-2019 ')\n",
    "    test.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    print(train.shape,test.shape)\n",
    "    return train , test\n",
    "\n",
    "def _prepare_data(data):\n",
    "    X_train=data.drop(['dissolved_oxygen'],axis=1)\n",
    "    y_train=data.dissolved_oxygen\n",
    "    return X_train , y_train\n",
    "\n",
    "\n",
    "def _calc_corr(y_test,y_pred,sqrt=False):\n",
    "    res=pd.DataFrame(y_pred,columns=['pred'])\n",
    "    res['real']=y_test\n",
    "    if sqrt:\n",
    "        return np.sqrt(res.corr())\n",
    "    else: return res.corr()\n",
    "\n",
    "def _zscore(df):\n",
    "    df_scaled=zscore(df,axis=1)\n",
    "    return df_scaled\n",
    "\n",
    "def _scale_data(X_train,y_train,X_test,y_test,same=False):\n",
    "    X_scaler=StandardScaler()\n",
    "    X_train_scaled=X_scaler.fit_transform(X_train)\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_scaled=y_scaler.fit_transform(np.array(y_train).reshape(-1,1))    \n",
    "    if same:\n",
    "        X_test_scaled=X_scaler.transform(X_test)\n",
    "        y_test_scaled=y_scaler.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "        return X_train_scaled,y_train_scaled,X_test_scaled,y_test_scaled\n",
    "    else:\n",
    "        X_test_scaler=StandardScaler()\n",
    "        y_test_scaler=StandardScaler()\n",
    "        X_test_scaled=X_test_scaler.fit_transform(X_test)\n",
    "        y_test_scaled=y_test_scaler.fit_transform(np.array(y_test).reshape(-1,1))  \n",
    "        return X_train_scaled,y_train_scaled,X_test_scaled,y_test_scaled    \n",
    "\n",
    "#create a function to find outliers using IQR\n",
    "def find_outliers_IQR(df):\n",
    "   q1=df.quantile(0.25)\n",
    "   q3=df.quantile(0.75)\n",
    "   IQR=q3-q1\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "   return outliers\n",
    "\n",
    "def _relative_error(y_test,y_pred):\n",
    "    re=[]\n",
    "    for item in range(len(y_test)):\n",
    "        re.append((abs(y_test[item]-y_pred[item])/y_test[item])*100)\n",
    "    return np.mean(re)\n",
    "\n",
    "def _errors(y_test, y_pred):\n",
    "    mse=mean_squared_error(y_test, y_pred)\n",
    "    rmse=np.sqrt(mse)\n",
    "    relative=_relative_error(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test, y_pred)\n",
    "    corr=_calc_corr(y_test,y_pred,sqrt=False)\n",
    "    sq_corr=r2_score(y_test,y_pred)\n",
    "    print(f\"mse: {mse}\\nrmse: {rmse}\\nrelative: {relative} %\\nmae: {mae}\\ncorr:{corr['real']['pred']}\\nsq_corr:{sq_corr}\\n\")\n",
    "    return [mse,rmse,relative,mae,corr['real']['pred'],sq_corr]\n",
    "\n",
    "def _drop_outliers(train,test,drop_test=False):\n",
    "    train=train[find_outliers_IQR(train).isna()].dropna()\n",
    "    if drop_test:\n",
    "        test=test[find_outliers_IQR(test).isna()].dropna()\n",
    "        print(train.shape,test.shape)\n",
    "        return train,test\n",
    "    else:\n",
    "        print(train.shape,test.shape)\n",
    "        return train,test\n",
    "\n",
    "def _augment_data(df,n=1000):\n",
    "    #creating fake data\n",
    "    fake=pd.DataFrame([list(range(1,len(df.columns)+1))],columns=df.columns,index=range(n))\n",
    "    fake.columns\n",
    "    for item in fake.columns:\n",
    "        fake[item]=np.random.random(n)\n",
    "    fake['fake']=np.ones(len(fake))\n",
    "    # concatenate fake and real data\n",
    "    df['fake']=np.zeros(len(df))\n",
    "    temp=pd.concat([fake,df],axis=0)\n",
    "    temp.reset_index(drop=True,inplace=True)\n",
    "    # Augment data\n",
    "    X=temp.drop(['fake'],axis=1)\n",
    "    y=temp.fake\n",
    "    # transform the dataset\n",
    "    oversample = SMOTE()\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    X['fake']=y\n",
    "    temp=X[X.fake==0]\n",
    "    temp.drop(['fake'],axis=1,inplace=True)\n",
    "    temp.reset_index(drop=True,inplace=True)\n",
    "    return temp\n",
    "\n",
    "def _dataset_type(train, test, type='ds1'):\n",
    "    if type=='ds1':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5'],axis=1,inplace=True)\n",
    "        return train , test\n",
    "    elif type=='ds2':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4'],axis=1,inplace=True)\n",
    "        return train , test\n",
    "    elif type=='ds3':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4','electrical'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4','electrical'],axis=1,inplace=True) \n",
    "        return train , test  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11) (461, 11)\n",
      "(510, 4) (383, 4)\n",
      "(510, 4)\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "train,test=_load_data()\n",
    "\n",
    "# dataset type\n",
    "train , test = _dataset_type(train, test,type='ds3')\n",
    "\n",
    "# drop outliers\n",
    "train,test=_drop_outliers(train , test,drop_test=True)\n",
    "\n",
    "# z score standard \n",
    "# train=_zscore(train)\n",
    "# test =_zscore(test)\n",
    "\n",
    "# Augment data\n",
    "\n",
    "# train=_augment_data(train,n=1000)\n",
    "print(train.shape)\n",
    "\n",
    "# train test and x y split\n",
    "X_train , y_train=_prepare_data(train)\n",
    "X_test , y_test =_prepare_data(test)\n",
    "\n",
    "# standard scale data\n",
    "X_train , y_train,X_test , y_test =_scale_data(X_train , y_train,X_test , y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "# - ExtraTreeRegressor\n",
    "# - this model has r2=0.741\n",
    "# joblib.dump(model, 'extratreereg.joblib.pkl', compress=9)\n",
    "model= joblib.load('extratreereg.joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.002447447566637241\n",
      "rmse: 0.0494716844936297\n",
      "relative: 1.676841881008486 %\n",
      "mae: 0.023822302036291453\n",
      "corr:0.9973934653539474\n",
      "sq_corr:0.9947925669095721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but KNeighborsRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=KNeighborsRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.00459907236742592\n",
      "rmse: 0.0678164608883855\n",
      "relative: 0.8996829151283612 %\n",
      "mae: 0.033423812676374724\n",
      "corr:0.9951064186236691\n",
      "sq_corr:0.990214555785433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=DecisionTreeRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.003105231622848229\n",
      "rmse: 0.055724605183421705\n",
      "relative: -0.9485603564551564 %\n",
      "mae: 0.021408496004849877\n",
      "corr:0.9966924502905953\n",
      "sq_corr:0.9933930000680339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.0016496695389432861\n",
      "rmse: 0.04061612412507237\n",
      "relative: 0.5696766849564529 %\n",
      "mae: 0.022662292896239455\n",
      "corr:0.998269393285694\n",
      "sq_corr:0.9964899988614803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.0035170242662577087\n",
      "rmse: 0.059304504603425436\n",
      "relative: 3.527304782627839 %\n",
      "mae: 0.05188801725564923\n",
      "corr:0.9988145051098656\n",
      "sq_corr:0.9925168290452439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=SVR()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.001303045773633415\n",
      "rmse: 0.036097725324920615\n",
      "relative: 0.3586902010020359 %\n",
      "mae: 0.02628127103373891\n",
      "corr:0.998629533232227\n",
      "sq_corr:0.9972275100915505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaniargh42/.local/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but MLPRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=MLPRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 2/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 3/150\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 4/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 5/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9999 - val_loss: 0.9998\n",
      "Epoch 6/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9998 - val_loss: 0.9997\n",
      "Epoch 7/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9997 - val_loss: 0.9996\n",
      "Epoch 8/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9996 - val_loss: 0.9995\n",
      "Epoch 9/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9993 - val_loss: 0.9992\n",
      "Epoch 10/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9991 - val_loss: 0.9989\n",
      "Epoch 11/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9987 - val_loss: 0.9985\n",
      "Epoch 12/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9982 - val_loss: 0.9979\n",
      "Epoch 13/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9976 - val_loss: 0.9971\n",
      "Epoch 14/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9966 - val_loss: 0.9960\n",
      "Epoch 15/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9954 - val_loss: 0.9946\n",
      "Epoch 16/150\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.9937 - val_loss: 0.9927\n",
      "Epoch 17/150\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.9915 - val_loss: 0.9902\n",
      "Epoch 18/150\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.9887 - val_loss: 0.9870\n",
      "Epoch 19/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9851 - val_loss: 0.9829\n",
      "Epoch 20/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9806 - val_loss: 0.9779\n",
      "Epoch 21/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9750 - val_loss: 0.9718\n",
      "Epoch 22/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9683 - val_loss: 0.9645\n",
      "Epoch 23/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9603 - val_loss: 0.9559\n",
      "Epoch 24/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9511 - val_loss: 0.9459\n",
      "Epoch 25/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9401 - val_loss: 0.9351\n",
      "Epoch 26/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9284 - val_loss: 0.9222\n",
      "Epoch 27/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9150 - val_loss: 0.9084\n",
      "Epoch 28/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9002 - val_loss: 0.8937\n",
      "Epoch 29/150\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.8847 - val_loss: 0.8773\n",
      "Epoch 30/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8679 - val_loss: 0.8596\n",
      "Epoch 31/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8493 - val_loss: 0.8422\n",
      "Epoch 32/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8321 - val_loss: 0.8225\n",
      "Epoch 33/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8124 - val_loss: 0.8039\n",
      "Epoch 34/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7928 - val_loss: 0.7861\n",
      "Epoch 35/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7753 - val_loss: 0.7667\n",
      "Epoch 36/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7562 - val_loss: 0.7495\n",
      "Epoch 37/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7390 - val_loss: 0.7320\n",
      "Epoch 38/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7222 - val_loss: 0.7161\n",
      "Epoch 39/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7069 - val_loss: 0.7013\n",
      "Epoch 40/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6933 - val_loss: 0.6874\n",
      "Epoch 41/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6808 - val_loss: 0.6752\n",
      "Epoch 42/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6694 - val_loss: 0.6648\n",
      "Epoch 43/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6597 - val_loss: 0.6551\n",
      "Epoch 44/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6511 - val_loss: 0.6462\n",
      "Epoch 45/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6435 - val_loss: 0.6380\n",
      "Epoch 46/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6363 - val_loss: 0.6304\n",
      "Epoch 47/150\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6299 - val_loss: 0.6235\n",
      "Epoch 48/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6240 - val_loss: 0.6170\n",
      "Epoch 49/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6184 - val_loss: 0.6109\n",
      "Epoch 50/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6043\n",
      "Epoch 51/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6083 - val_loss: 0.5993\n",
      "Epoch 52/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.5937\n",
      "Epoch 53/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5977 - val_loss: 0.5876\n",
      "Epoch 54/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5928 - val_loss: 0.5818\n",
      "Epoch 55/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5876 - val_loss: 0.5773\n",
      "Epoch 56/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.5717\n",
      "Epoch 57/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5773 - val_loss: 0.5663\n",
      "Epoch 58/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5722 - val_loss: 0.5609\n",
      "Epoch 59/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5671 - val_loss: 0.5558\n",
      "Epoch 60/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5618 - val_loss: 0.5499\n",
      "Epoch 61/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5565 - val_loss: 0.5442\n",
      "Epoch 62/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5512 - val_loss: 0.5385\n",
      "Epoch 63/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5457 - val_loss: 0.5330\n",
      "Epoch 64/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5404 - val_loss: 0.5273\n",
      "Epoch 65/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5348 - val_loss: 0.5220\n",
      "Epoch 66/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5291 - val_loss: 0.5162\n",
      "Epoch 67/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5236 - val_loss: 0.5103\n",
      "Epoch 68/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5177 - val_loss: 0.5046\n",
      "Epoch 69/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5123 - val_loss: 0.4987\n",
      "Epoch 70/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5064 - val_loss: 0.4931\n",
      "Epoch 71/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5004 - val_loss: 0.4871\n",
      "Epoch 72/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4948 - val_loss: 0.4809\n",
      "Epoch 73/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4887 - val_loss: 0.4759\n",
      "Epoch 74/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4828 - val_loss: 0.4698\n",
      "Epoch 75/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4771 - val_loss: 0.4639\n",
      "Epoch 76/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4711 - val_loss: 0.4585\n",
      "Epoch 77/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4654 - val_loss: 0.4522\n",
      "Epoch 78/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4592 - val_loss: 0.4472\n",
      "Epoch 79/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4535 - val_loss: 0.4418\n",
      "Epoch 80/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4480 - val_loss: 0.4364\n",
      "Epoch 81/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4428 - val_loss: 0.4314\n",
      "Epoch 82/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4366 - val_loss: 0.4263\n",
      "Epoch 83/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4314 - val_loss: 0.4210\n",
      "Epoch 84/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4263 - val_loss: 0.4171\n",
      "Epoch 85/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4208 - val_loss: 0.4122\n",
      "Epoch 86/150\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4158 - val_loss: 0.4077\n",
      "Epoch 87/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4107 - val_loss: 0.4033\n",
      "Epoch 88/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4058 - val_loss: 0.4003\n",
      "Epoch 89/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4012 - val_loss: 0.3966\n",
      "Epoch 90/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3972 - val_loss: 0.3924\n",
      "Epoch 91/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3923 - val_loss: 0.3897\n",
      "Epoch 92/150\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3882 - val_loss: 0.3869\n",
      "Epoch 93/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3842 - val_loss: 0.3844\n",
      "Epoch 94/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3804 - val_loss: 0.3813\n",
      "Epoch 95/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3767 - val_loss: 0.3787\n",
      "Epoch 96/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3730 - val_loss: 0.3773\n",
      "Epoch 97/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3699 - val_loss: 0.3748\n",
      "Epoch 98/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3664 - val_loss: 0.3729\n",
      "Epoch 99/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3636 - val_loss: 0.3717\n",
      "Epoch 100/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3603 - val_loss: 0.3699\n",
      "Epoch 101/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3578 - val_loss: 0.3690\n",
      "Epoch 102/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3549 - val_loss: 0.3674\n",
      "Epoch 103/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3522 - val_loss: 0.3664\n",
      "Epoch 104/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3497 - val_loss: 0.3649\n",
      "Epoch 105/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3474 - val_loss: 0.3639\n",
      "Epoch 106/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3453 - val_loss: 0.3629\n",
      "Epoch 107/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3433 - val_loss: 0.3623\n",
      "Epoch 108/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3412 - val_loss: 0.3613\n",
      "Epoch 109/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3393 - val_loss: 0.3603\n",
      "Epoch 110/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3378 - val_loss: 0.3594\n",
      "Epoch 111/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3362 - val_loss: 0.3587\n",
      "Epoch 112/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3345 - val_loss: 0.3582\n",
      "Epoch 113/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3333 - val_loss: 0.3573\n",
      "Epoch 114/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3318 - val_loss: 0.3568\n",
      "Epoch 115/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3306 - val_loss: 0.3564\n",
      "Epoch 116/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3292 - val_loss: 0.3557\n",
      "Epoch 117/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3281 - val_loss: 0.3554\n",
      "Epoch 118/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3272 - val_loss: 0.3550\n",
      "Epoch 119/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3263 - val_loss: 0.3545\n",
      "Epoch 120/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3253 - val_loss: 0.3543\n",
      "Epoch 121/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3247 - val_loss: 0.3540\n",
      "Epoch 122/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.3540\n",
      "Epoch 123/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3235 - val_loss: 0.3536\n",
      "Epoch 124/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3225 - val_loss: 0.3533\n",
      "Epoch 125/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3221 - val_loss: 0.3528\n",
      "Epoch 126/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3214 - val_loss: 0.3525\n",
      "Epoch 127/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3208 - val_loss: 0.3524\n",
      "Epoch 128/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3201 - val_loss: 0.3522\n",
      "Epoch 129/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3202 - val_loss: 0.3523\n",
      "Epoch 130/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3192 - val_loss: 0.3517\n",
      "Epoch 131/150\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3189 - val_loss: 0.3515\n",
      "Epoch 132/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3184 - val_loss: 0.3514\n",
      "Epoch 133/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3186 - val_loss: 0.3514\n",
      "Epoch 134/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3178 - val_loss: 0.3511\n",
      "Epoch 135/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3178 - val_loss: 0.3512\n",
      "Epoch 136/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3173 - val_loss: 0.3514\n",
      "Epoch 137/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3169 - val_loss: 0.3512\n",
      "Epoch 138/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3169 - val_loss: 0.3512\n",
      "Epoch 139/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3167 - val_loss: 0.3511\n",
      "Epoch 140/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3165 - val_loss: 0.3510\n",
      "Epoch 141/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.3512\n",
      "Epoch 142/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.3508\n",
      "Epoch 143/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3159 - val_loss: 0.3510\n",
      "Epoch 144/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3155 - val_loss: 0.3510\n",
      "Epoch 145/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3156 - val_loss: 0.3507\n",
      "Epoch 146/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3155 - val_loss: 0.3508\n",
      "Epoch 147/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3150 - val_loss: 0.3509\n",
      "Epoch 148/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3149 - val_loss: 0.3506\n",
      "Epoch 149/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3146 - val_loss: 0.3506\n",
      "Epoch 150/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3145 - val_loss: 0.3506\n",
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.350560715269495\n",
      "rmse: 0.5920816795590749\n",
      "relative: -70.09873347829124 %\n",
      "mae: 0.40487626455607495\n",
      "corr:0.8063570190719244\n",
      "sq_corr:0.649439284730505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.350560715269495,\n",
       " 0.5920816795590749,\n",
       " -70.09873347829124,\n",
       " 0.40487626455607495,\n",
       " 0.8063570190719244,\n",
       " 0.649439284730505]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(17,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(10,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(7,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='RandomNormal',activation='linear'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    \n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2 , y_pred,model\n",
    "history , r2 , y_pred,model=_compile_model(X_train,y_train,X_test,y_test,150,30)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()\n",
    "_errors(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.9994 - val_loss: 0.9971\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.9653 - val_loss: 0.9093\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 0.5804\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3854 - val_loss: 0.4047\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2792 - val_loss: 0.3753\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2482 - val_loss: 0.3644\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.3589\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2151 - val_loss: 0.3550\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.3540\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1964 - val_loss: 0.3518\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.3524\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.3495\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1777 - val_loss: 0.3487\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1729 - val_loss: 0.3525\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1690 - val_loss: 0.3508\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1655 - val_loss: 0.3487\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1626 - val_loss: 0.3494\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.3463\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.3461\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.3445\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.3422\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1520 - val_loss: 0.3395\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1505 - val_loss: 0.3376\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.3345\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1474 - val_loss: 0.3323\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.3277\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1445 - val_loss: 0.3270\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.3255\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.3231\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.3197\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.3172\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.1380 - val_loss: 0.3159\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.3110\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1347 - val_loss: 0.3123\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 0.3089\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.3056\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.3051\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 0.3037\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.3038\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 0.3004\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.3011\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.2996\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1254 - val_loss: 0.3009\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.3003\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.2990\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.2965\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 0.2975\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 0.2980\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.2973\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.2946\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1199 - val_loss: 0.2957\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1196 - val_loss: 0.2948\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.2951\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.2943\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.2929\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.2938\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.2919\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.2907\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.2912\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 0.2920\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.2882\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1154 - val_loss: 0.2894\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.2893\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.2882\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.2910\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.2883\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1137 - val_loss: 0.2884\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.2895\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.2909\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.2881\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1127 - val_loss: 0.2881\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.2846\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.2865\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.2869\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.2855\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1112 - val_loss: 0.2905\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.2909\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.2850\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1108 - val_loss: 0.2868\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.2838\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.2883\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.2884\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.2908\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.2863\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.2846\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1087 - val_loss: 0.2864\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.2836\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1083 - val_loss: 0.2865\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.2862\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1080 - val_loss: 0.2894\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.2842\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.2854\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.2893\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.2905\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.2871\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.2864\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.2868\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.2924\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1061 - val_loss: 0.2897\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.2919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6087733d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(17,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(20,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(30,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(40,kernel_initializer='RandomNormal',activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "model.fit(X_train, y_train,epochs=100,batch_size=30,validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 40)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnf_train=model.predict(X_train)\n",
    "nnf_test=model.predict(X_test)\n",
    "nnf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
