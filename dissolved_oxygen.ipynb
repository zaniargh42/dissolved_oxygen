{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense  ,Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor ,ExtraTreesRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor\n",
    "RandomForestRegressor \n",
    "ExtraTreesRegressor \n",
    "KNeighborsRegressor\n",
    "MLPRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data():\n",
    "    train=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Training set 2011-2015')\n",
    "    train.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    test=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Testing set 2016-2019 ')\n",
    "    test.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    print(train.shape,test.shape)\n",
    "    return train , test\n",
    "\n",
    "def _prepare_data(data):\n",
    "    X_train=data.drop(['dissolved_oxygen'],axis=1)\n",
    "    y_train=data.dissolved_oxygen\n",
    "    return X_train , y_train\n",
    "\n",
    "\n",
    "def _calc_corr(y_test,y_pred,sqrt=False):\n",
    "    res=pd.DataFrame(y_pred,columns=['pred'])\n",
    "    res['real']=y_test\n",
    "    if sqrt:\n",
    "        return np.sqrt(res.corr())\n",
    "    else: return res.corr()\n",
    "\n",
    "def _zscore(df):\n",
    "    df_scaled=zscore(df,axis=1)\n",
    "    return df_scaled\n",
    "\n",
    "def _scale_data(X_train,y_train,X_test,y_test,same=False):\n",
    "    X_scaler=StandardScaler()\n",
    "    X_train_scaled=X_scaler.fit_transform(X_train)\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_scaled=y_scaler.fit_transform(np.array(y_train).reshape(-1,1))    \n",
    "    if same:\n",
    "        X_test_scaled=X_scaler.transform(X_test)\n",
    "        y_test_scaled=y_scaler.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "        return X_train_scaled,y_train_scaled,X_test_scaled,y_test_scaled\n",
    "    else:\n",
    "        X_test_scaler=StandardScaler()\n",
    "        y_test_scaler=StandardScaler()\n",
    "        X_test_scaled=X_test_scaler.fit_transform(X_test)\n",
    "        y_test_scaled=y_test_scaler.fit_transform(np.array(y_test).reshape(-1,1))  \n",
    "        return X_train_scaled,y_train_scaled,X_test_scaled,y_test_scaled    \n",
    "\n",
    "#create a function to find outliers using IQR\n",
    "def find_outliers_IQR(df):\n",
    "   q1=df.quantile(0.25)\n",
    "   q3=df.quantile(0.75)\n",
    "   IQR=q3-q1\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "   return outliers\n",
    "\n",
    "def _relative_error(y_test,y_pred):\n",
    "    re=[]\n",
    "    for item in range(len(y_test)):\n",
    "        re.append((abs(y_test[item]-y_pred[item])/y_test[item])*100)\n",
    "    return np.mean(re)\n",
    "\n",
    "def _errors(y_test, y_pred):\n",
    "    mse=mean_squared_error(y_test, y_pred)\n",
    "    rmse=np.sqrt(mse)\n",
    "    relative=_relative_error(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test, y_pred)\n",
    "    corr=_calc_corr(y_test,y_pred,sqrt=False)\n",
    "    sq_corr=r2_score(y_test,y_pred)\n",
    "    print(f\"mse: {mse}\\nrmse: {rmse}\\nrelative: {relative} %\\nmae: {mae}\\ncorr:{corr['real']['pred']}\\nsq_corr:{sq_corr}\\n\")\n",
    "\n",
    "def _drop_outliers(train,test):\n",
    "    train=train[find_outliers_IQR(train).isna()].dropna()\n",
    "    test=test[find_outliers_IQR(test).isna()].dropna()\n",
    "    print(train.shape,test.shape)\n",
    "    return train,test\n",
    "\n",
    "def _augment_data(df,n=1000):\n",
    "    #creating fake data\n",
    "    fake=pd.DataFrame([list(range(1,len(df.columns)+1))],columns=df.columns,index=range(n))\n",
    "    fake.columns\n",
    "    for item in fake.columns:\n",
    "        fake[item]=np.random.random(n)\n",
    "    fake['fake']=np.ones(len(fake))\n",
    "    # concatenate fake and real data\n",
    "    df['fake']=np.zeros(len(df))\n",
    "    temp=pd.concat([fake,df],axis=0)\n",
    "    temp.reset_index(drop=True,inplace=True)\n",
    "    # Augment data\n",
    "    X=temp.drop(['fake'],axis=1)\n",
    "    y=temp.fake\n",
    "    # transform the dataset\n",
    "    oversample = SMOTE()\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    X['fake']=y\n",
    "    temp=X[X.fake==0]\n",
    "    temp.drop(['fake'],axis=1,inplace=True)\n",
    "    temp.reset_index(drop=True,inplace=True)\n",
    "    return temp\n",
    "\n",
    "def _dataset_type(train, test, type='ds1'):\n",
    "    if type=='ds1':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5'],axis=1,inplace=True)\n",
    "        return train , test\n",
    "    elif type=='ds2':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4'],axis=1,inplace=True)\n",
    "        return train , test\n",
    "    elif type=='ds3':\n",
    "        train.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4','electrical'],axis=1,inplace=True)\n",
    "        test.drop(['solids','NO2', 'NO3', 'TN','BOD5','NH4','electrical'],axis=1,inplace=True) \n",
    "        return train , test  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11) (461, 11)\n",
      "(466, 6) (339, 6)\n",
      "(466, 6)\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "train,test=_load_data()\n",
    "\n",
    "# dataset type\n",
    "train , test = _dataset_type(train, test,type='ds1')\n",
    "\n",
    "# drop outliers\n",
    "train,test=_drop_outliers(train , test)\n",
    "\n",
    "# z score standard \n",
    "train=_zscore(train)\n",
    "test =_zscore(test)\n",
    "\n",
    "# Augment data\n",
    "# train=_augment_data(train,n=1000)\n",
    "print(train.shape)\n",
    "\n",
    "# train test and x y split\n",
    "X_train , y_train=_prepare_data(train)\n",
    "X_test , y_test =_prepare_data(test)\n",
    "\n",
    "# standard scale data\n",
    "# X_train , y_train,X_test , y_test =_scale_data(X_train , y_train,X_test , y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "# - ExtraTreeRegressor\n",
    "# - this model has r2=0.741\n",
    "# joblib.dump(model, 'extratreereg.joblib.pkl', compress=9)\n",
    "model= joblib.load('extratreereg.joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor\n",
    "RandomForestRegressor \n",
    "ExtraTreesRegressor \n",
    "KNeighborsRegressor\n",
    "MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.0005276185966235143\n",
      "rmse: 0.022969949861144978\n",
      "relative: -4.212524123877741 %\n",
      "mae: 0.01768269128678556\n",
      "corr:-0.8722184192489691\n",
      "sq_corr:-0.42656794793379493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=MLPRegressor()\n",
    "model.fit(X_train.values,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "_errors(y_test.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0000 - val_loss: 1.0000\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9999 - val_loss: 0.9999\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9998 - val_loss: 0.9998\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.9998 - val_loss: 0.9997\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9997 - val_loss: 0.9997\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9996 - val_loss: 0.9996\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9995 - val_loss: 0.9994\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9993 - val_loss: 0.9992\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9991 - val_loss: 0.9990\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9988 - val_loss: 0.9987\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9985 - val_loss: 0.9984\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9981 - val_loss: 0.9980\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9976 - val_loss: 0.9974\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9970 - val_loss: 0.9968\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9962 - val_loss: 0.9960\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.9953 - val_loss: 0.9951\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9942 - val_loss: 0.9940\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9930 - val_loss: 0.9928\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9916 - val_loss: 0.9913\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9899 - val_loss: 0.9896\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9880 - val_loss: 0.9877\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9859 - val_loss: 0.9855\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9834 - val_loss: 0.9831\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9807 - val_loss: 0.9804\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9777 - val_loss: 0.9773\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9743 - val_loss: 0.9741\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9706 - val_loss: 0.9704\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9665 - val_loss: 0.9662\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9619 - val_loss: 0.9619\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9571 - val_loss: 0.9569\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9516 - val_loss: 0.9516\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9459 - val_loss: 0.9458\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9397 - val_loss: 0.9398\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9328 - val_loss: 0.9337\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9262 - val_loss: 0.9264\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9182 - val_loss: 0.9194\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9106 - val_loss: 0.9117\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9022 - val_loss: 0.9037\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8936 - val_loss: 0.8954\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8842 - val_loss: 0.8869\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8749 - val_loss: 0.8776\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8645 - val_loss: 0.8678\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8540 - val_loss: 0.8578\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8435 - val_loss: 0.8472\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8313 - val_loss: 0.8366\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8203 - val_loss: 0.8256\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8086 - val_loss: 0.8150\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7976 - val_loss: 0.8041\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7860 - val_loss: 0.7931\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7741 - val_loss: 0.7825\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7624 - val_loss: 0.7711\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7504 - val_loss: 0.7597\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7385 - val_loss: 0.7493\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7276 - val_loss: 0.7384\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7159 - val_loss: 0.7282\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7057 - val_loss: 0.7183\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6953 - val_loss: 0.7090\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6855 - val_loss: 0.7001\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6762 - val_loss: 0.6911\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6669 - val_loss: 0.6829\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6585 - val_loss: 0.6751\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6504 - val_loss: 0.6677\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6433 - val_loss: 0.6606\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6361 - val_loss: 0.6539\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6297 - val_loss: 0.6475\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6234 - val_loss: 0.6412\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6170 - val_loss: 0.6348\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6107 - val_loss: 0.6287\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6049 - val_loss: 0.6227\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5992 - val_loss: 0.6164\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5934 - val_loss: 0.6111\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5883 - val_loss: 0.6058\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5821 - val_loss: 0.6001\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5774 - val_loss: 0.5947\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5717 - val_loss: 0.5892\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5667 - val_loss: 0.5835\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5612 - val_loss: 0.5790\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5560 - val_loss: 0.5736\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5508 - val_loss: 0.5675\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5452 - val_loss: 0.5625\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5401 - val_loss: 0.5571\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5347 - val_loss: 0.5518\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5295 - val_loss: 0.5470\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5246 - val_loss: 0.5418\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5194 - val_loss: 0.5359\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5136 - val_loss: 0.5306\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5084 - val_loss: 0.5254\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5032 - val_loss: 0.5199\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4976 - val_loss: 0.5143\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4923 - val_loss: 0.5095\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - val_loss: 0.5045\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4812 - val_loss: 0.4990\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4756 - val_loss: 0.4935\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4700 - val_loss: 0.4881\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4648 - val_loss: 0.4832\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4593 - val_loss: 0.4783\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4540 - val_loss: 0.4729\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4485 - val_loss: 0.4679\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4429 - val_loss: 0.4631\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4377 - val_loss: 0.4577\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4321 - val_loss: 0.4527\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4265 - val_loss: 0.4474\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4213 - val_loss: 0.4421\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4157 - val_loss: 0.4378\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4106 - val_loss: 0.4337\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4052 - val_loss: 0.4288\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3999 - val_loss: 0.4244\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3953 - val_loss: 0.4204\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3904 - val_loss: 0.4160\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3854 - val_loss: 0.4122\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3809 - val_loss: 0.4083\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3763 - val_loss: 0.4046\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3715 - val_loss: 0.4009\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3671 - val_loss: 0.3972\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - val_loss: 0.3940\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3583 - val_loss: 0.3910\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3542 - val_loss: 0.3882\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3501 - val_loss: 0.3853\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3461 - val_loss: 0.3827\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3427 - val_loss: 0.3798\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3389 - val_loss: 0.3777\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3357 - val_loss: 0.3753\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3324 - val_loss: 0.3736\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3293 - val_loss: 0.3720\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3260 - val_loss: 0.3701\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3232 - val_loss: 0.3684\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3205 - val_loss: 0.3669\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3178 - val_loss: 0.3653\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3151 - val_loss: 0.3645\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3127 - val_loss: 0.3634\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3104 - val_loss: 0.3626\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3082 - val_loss: 0.3616\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3062 - val_loss: 0.3610\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3042 - val_loss: 0.3604\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3025 - val_loss: 0.3598\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3009 - val_loss: 0.3591\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2990 - val_loss: 0.3588\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2972 - val_loss: 0.3588\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2959 - val_loss: 0.3586\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2940 - val_loss: 0.3590\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2924 - val_loss: 0.3586\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2910 - val_loss: 0.3589\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2896 - val_loss: 0.3590\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2884 - val_loss: 0.3586\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2873 - val_loss: 0.3580\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2865 - val_loss: 0.3576\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2855 - val_loss: 0.3577\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2848 - val_loss: 0.3576\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2842 - val_loss: 0.3576\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2835 - val_loss: 0.3579\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2828 - val_loss: 0.3577\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2821 - val_loss: 0.3576\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2814 - val_loss: 0.3580\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2812 - val_loss: 0.3587\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2805 - val_loss: 0.3585\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2801 - val_loss: 0.3585\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2795 - val_loss: 0.3585\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2792 - val_loss: 0.3584\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2787 - val_loss: 0.3584\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2784 - val_loss: 0.3583\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2779 - val_loss: 0.3584\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2780 - val_loss: 0.3581\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2772 - val_loss: 0.3584\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2768 - val_loss: 0.3580\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2763 - val_loss: 0.3580\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2760 - val_loss: 0.3582\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2755 - val_loss: 0.3581\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2752 - val_loss: 0.3575\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2746 - val_loss: 0.3576\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2743 - val_loss: 0.3576\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2740 - val_loss: 0.3575\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2735 - val_loss: 0.3574\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2731 - val_loss: 0.3572\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2727 - val_loss: 0.3571\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2724 - val_loss: 0.3571\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2721 - val_loss: 0.3571\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2717 - val_loss: 0.3572\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2715 - val_loss: 0.3573\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2711 - val_loss: 0.3571\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2712 - val_loss: 0.3570\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2705 - val_loss: 0.3575\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2704 - val_loss: 0.3574\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2700 - val_loss: 0.3573\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2699 - val_loss: 0.3577\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2696 - val_loss: 0.3576\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2694 - val_loss: 0.3576\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2692 - val_loss: 0.3575\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2690 - val_loss: 0.3575\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2689 - val_loss: 0.3579\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2689 - val_loss: 0.3576\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2686 - val_loss: 0.3579\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2683 - val_loss: 0.3578\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2681 - val_loss: 0.3577\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2680 - val_loss: 0.3578\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2679 - val_loss: 0.3579\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2678 - val_loss: 0.3579\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2677 - val_loss: 0.3577\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2676 - val_loss: 0.3579\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2674 - val_loss: 0.3581\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2674 - val_loss: 0.3583\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2673 - val_loss: 0.3587\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2672 - val_loss: 0.3589\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2669 - val_loss: 0.3588\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2668 - val_loss: 0.3587\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2669 - val_loss: 0.3588\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2667 - val_loss: 0.3587\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2665 - val_loss: 0.3589\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2663 - val_loss: 0.3590\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2664 - val_loss: 0.3590\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2661 - val_loss: 0.3590\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2660 - val_loss: 0.3591\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2660 - val_loss: 0.3591\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2660 - val_loss: 0.3592\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2658 - val_loss: 0.3591\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2658 - val_loss: 0.3593\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2657 - val_loss: 0.3594\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2655 - val_loss: 0.3594\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2654 - val_loss: 0.3594\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2654 - val_loss: 0.3593\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2654 - val_loss: 0.3596\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2653 - val_loss: 0.3598\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2651 - val_loss: 0.3598\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2651 - val_loss: 0.3598\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2650 - val_loss: 0.3600\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2650 - val_loss: 0.3598\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2649 - val_loss: 0.3598\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2649 - val_loss: 0.3597\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2650 - val_loss: 0.3601\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2647 - val_loss: 0.3599\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2646 - val_loss: 0.3601\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2645 - val_loss: 0.3601\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2646 - val_loss: 0.3604\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2645 - val_loss: 0.3602\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2642 - val_loss: 0.3604\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2643 - val_loss: 0.3603\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2641 - val_loss: 0.3603\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2641 - val_loss: 0.3603\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2639 - val_loss: 0.3606\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.3607\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.3610\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2638 - val_loss: 0.3611\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2638 - val_loss: 0.3611\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388594421964744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred  real\n",
       "pred  1.00  0.80\n",
       "real  0.80  1.00"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(17,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(10,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(7,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='RandomNormal',activation='linear'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    \n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2 , y_pred,model\n",
    "history , r2 , y_pred,model=_compile_model(X_train,y_train,X_test,y_test,250,30)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()\n",
    "print(r2)\n",
    "_calc_corr(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.9994 - val_loss: 0.9971\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.9653 - val_loss: 0.9093\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 0.5804\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3854 - val_loss: 0.4047\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2792 - val_loss: 0.3753\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2482 - val_loss: 0.3644\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.3589\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2151 - val_loss: 0.3550\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.3540\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1964 - val_loss: 0.3518\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.3524\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.3495\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1777 - val_loss: 0.3487\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1729 - val_loss: 0.3525\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1690 - val_loss: 0.3508\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1655 - val_loss: 0.3487\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1626 - val_loss: 0.3494\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.3463\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.3461\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.3445\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.3422\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1520 - val_loss: 0.3395\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1505 - val_loss: 0.3376\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.3345\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1474 - val_loss: 0.3323\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.3277\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1445 - val_loss: 0.3270\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.3255\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.3231\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.3197\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.3172\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.1380 - val_loss: 0.3159\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.3110\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1347 - val_loss: 0.3123\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 0.3089\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.3056\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.3051\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 0.3037\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.3038\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 0.3004\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.3011\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.2996\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1254 - val_loss: 0.3009\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.3003\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.2990\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.2965\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 0.2975\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 0.2980\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.2973\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.2946\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1199 - val_loss: 0.2957\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1196 - val_loss: 0.2948\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.2951\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.2943\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.2929\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.2938\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.2919\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.2907\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.2912\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 0.2920\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.2882\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1154 - val_loss: 0.2894\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.2893\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.2882\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.2910\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.2883\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1137 - val_loss: 0.2884\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.2895\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.2909\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.2881\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1127 - val_loss: 0.2881\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.2846\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.2865\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.2869\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.2855\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1112 - val_loss: 0.2905\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.2909\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.2850\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1108 - val_loss: 0.2868\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.2838\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.2883\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.2884\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.2908\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.2863\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.2846\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1087 - val_loss: 0.2864\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.2836\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1083 - val_loss: 0.2865\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.2862\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1080 - val_loss: 0.2894\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.2842\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.2854\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.2893\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.2905\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.2871\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.2864\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.2868\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.2924\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1061 - val_loss: 0.2897\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.2919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6087733d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(17,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(20,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(30,kernel_initializer='RandomNormal', activation='relu'))\n",
    "model.add(Dense(40,kernel_initializer='RandomNormal',activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "model.fit(X_train, y_train,epochs=100,batch_size=30,validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 40)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnf_train=model.predict(X_train)\n",
    "nnf_test=model.predict(X_test)\n",
    "nnf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
