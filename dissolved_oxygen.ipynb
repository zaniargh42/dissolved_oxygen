{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense  ,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from lazypredict.Supervised import LazyRegressor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data():\n",
    "    train=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Training set 2011-2015')\n",
    "    train.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    test=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Testing set 2016-2019 ')\n",
    "    test.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "    test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "\n",
    "    print(train.shape,test.shape)\n",
    "    return train , test\n",
    "\n",
    "def _prepare_data(data):\n",
    "    X_train=data.drop(['dissolved_oxygen'],axis=1)\n",
    "    y_train=data.dissolved_oxygen\n",
    "    return X_train , y_train\n",
    "\n",
    "def _scale_data(X_train,y_train):\n",
    "    X_scaler=StandardScaler()\n",
    "    X_train_scaled=X_scaler.fit_transform(X_train)\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_scaled=y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "    print(X_train_scaled.shape, y_train_scaled.shape)\n",
    "    return X_train_scaled,y_train_scaled , X_scaler , y_scaler\n",
    "\n",
    "def r_squared(y, y_hat):\n",
    "    y_bar = y.mean()\n",
    "    ss_tot = ((y-y_bar)**2).sum()\n",
    "    ss_res = ((y-y_hat)**2).sum()\n",
    "    return 1 - (ss_res/ss_tot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(X_train, y_train,epochs=10,batch_size=8)\n",
    "\n",
    "KerasRegressor(model=model, epochs=100, batch_size=5, verbose=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have some missing values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonul_train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "X_train,y_train=_prepare_data(nonul_train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonul_test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "X_test,y_test=_prepare_data(nonul_test)\n",
    "\n",
    "X_test=X_scaler.transform(X_test)\n",
    "y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create the model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train[0].shape[0], input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history , r2=_compile_model(X_train,y_train,X_test,y_test,80,32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size itrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_all=[]\n",
    "for item in tqdm([8,16,32,64,128,256,512]):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,80,item)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(7),r2_all)\n",
    "plt.xticks(range(7),[8,16,32,64,128,256,512])\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_all=[]\n",
    "for item in tqdm(range(150,200,10)):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,item,8)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(r2_all)),r2_all)\n",
    "plt.xticks(range(len(r2_all)),range(10,200,10))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X_test[:100,:]\n",
    "y=y_test[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history , r2=_compile_model(X_train,y_train,x,y,100,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model\n",
    "it gives us r2=0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11) (461, 11)\n"
     ]
    }
   ],
   "source": [
    "train , test =_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 10) (605, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=_prepare_data(train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n",
    "X_test,y_test=_prepare_data(test)\n",
    "# to set a new scaler\n",
    "# X_test_scaler=StandardScaler()\n",
    "# y_test_scaler=StandardScaler()\n",
    "# X_test=X_test_scaler.fit_transform(X_test)\n",
    "# y_test=y_test_scaler.fit_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "#to scale by the train scaler\n",
    "X_test=X_scaler.transform(X_test)\n",
    "y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "76/76 [==============================] - 2s 13ms/step - loss: 1.0000 - val_loss: 0.7754\n",
      "Epoch 2/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 1.0000 - val_loss: 0.7754\n",
      "Epoch 3/70\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 1.0000 - val_loss: 0.7753\n",
      "Epoch 4/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9996 - val_loss: 0.7747\n",
      "Epoch 5/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9984 - val_loss: 0.7725\n",
      "Epoch 6/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9946 - val_loss: 0.7670\n",
      "Epoch 7/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.9857 - val_loss: 0.7537\n",
      "Epoch 8/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9677 - val_loss: 0.7302\n",
      "Epoch 9/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9396 - val_loss: 0.6989\n",
      "Epoch 10/70\n",
      "76/76 [==============================] - 0s 7ms/step - loss: 0.9089 - val_loss: 0.6662\n",
      "Epoch 11/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.8797 - val_loss: 0.6377\n",
      "Epoch 12/70\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.8505 - val_loss: 0.6093\n",
      "Epoch 13/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.8203 - val_loss: 0.5833\n",
      "Epoch 14/70\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7919 - val_loss: 0.5574\n",
      "Epoch 15/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7663 - val_loss: 0.5402\n",
      "Epoch 16/70\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7497 - val_loss: 0.5290\n",
      "Epoch 17/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7393 - val_loss: 0.5231\n",
      "Epoch 18/70\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7341 - val_loss: 0.5208\n",
      "Epoch 19/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7305 - val_loss: 0.5184\n",
      "Epoch 20/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7275 - val_loss: 0.5174\n",
      "Epoch 21/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7258 - val_loss: 0.5168\n",
      "Epoch 22/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7235 - val_loss: 0.5160\n",
      "Epoch 23/70\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7220 - val_loss: 0.5156\n",
      "Epoch 24/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7206 - val_loss: 0.5152\n",
      "Epoch 25/70\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7195 - val_loss: 0.5149\n",
      "Epoch 26/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7185 - val_loss: 0.5148\n",
      "Epoch 27/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7169 - val_loss: 0.5148\n",
      "Epoch 28/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7156 - val_loss: 0.5147\n",
      "Epoch 29/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7148 - val_loss: 0.5147\n",
      "Epoch 30/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7132 - val_loss: 0.5148\n",
      "Epoch 31/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7127 - val_loss: 0.5147\n",
      "Epoch 32/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7113 - val_loss: 0.5150\n",
      "Epoch 33/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 0.5151\n",
      "Epoch 34/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7098 - val_loss: 0.5152\n",
      "Epoch 35/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 0.5156\n",
      "Epoch 36/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 0.5155\n",
      "Epoch 37/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7072 - val_loss: 0.5157\n",
      "Epoch 38/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7058 - val_loss: 0.5155\n",
      "Epoch 39/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7055 - val_loss: 0.5165\n",
      "Epoch 40/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.5167\n",
      "Epoch 41/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7031 - val_loss: 0.5167\n",
      "Epoch 42/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7030 - val_loss: 0.5167\n",
      "Epoch 43/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7017 - val_loss: 0.5172\n",
      "Epoch 44/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7010 - val_loss: 0.5175\n",
      "Epoch 45/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7000 - val_loss: 0.5177\n",
      "Epoch 46/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7002 - val_loss: 0.5180\n",
      "Epoch 47/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6987 - val_loss: 0.5185\n",
      "Epoch 48/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.5180\n",
      "Epoch 49/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6975 - val_loss: 0.5189\n",
      "Epoch 50/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 0.5189\n",
      "Epoch 51/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6956 - val_loss: 0.5195\n",
      "Epoch 52/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6945 - val_loss: 0.5198\n",
      "Epoch 53/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6949 - val_loss: 0.5205\n",
      "Epoch 54/70\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6928 - val_loss: 0.5203\n",
      "Epoch 55/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6926 - val_loss: 0.5219\n",
      "Epoch 56/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 0.5217\n",
      "Epoch 57/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6916 - val_loss: 0.5222\n",
      "Epoch 58/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.5227\n",
      "Epoch 59/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6894 - val_loss: 0.5232\n",
      "Epoch 60/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6885 - val_loss: 0.5234\n",
      "Epoch 61/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6878 - val_loss: 0.5248\n",
      "Epoch 62/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 0.5249\n",
      "Epoch 63/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6865 - val_loss: 0.5253\n",
      "Epoch 64/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.5245\n",
      "Epoch 65/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6850 - val_loss: 0.5268\n",
      "Epoch 66/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6839 - val_loss: 0.5268\n",
      "Epoch 67/70\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6837 - val_loss: 0.5278\n",
      "Epoch 68/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6830 - val_loss: 0.5271\n",
      "Epoch 69/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6822 - val_loss: 0.5294\n",
      "Epoch 70/70\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.5298\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.31630193003044427"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(35, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomUniform', activation='relu'))\n",
    "    model.add(Dense(25,kernel_initializer='RandomUniform', activation='relu'))\n",
    "    model.add(Dense(12,kernel_initializer='RandomUniform', activation='relu'))\n",
    "    model.add(Dense(6,kernel_initializer='RandomUniform', activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='RandomUniform',activation='linear'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    \n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2 , y_pred\n",
    "history , r2 , y_pred=_compile_model(X_train,y_train,X_test,y_test,70,8)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()\n",
    "r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11) (461, 11)\n"
     ]
    }
   ],
   "source": [
    "train , test =_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 11) (258, 11)\n"
     ]
    }
   ],
   "source": [
    "#create a function to find outliers using IQR\n",
    "def find_outliers_IQR(df):\n",
    "   q1=df.quantile(0.25)\n",
    "   q3=df.quantile(0.75)\n",
    "   IQR=q3-q1\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "   return outliers\n",
    "\n",
    "train=train[find_outliers_IQR(train).isna()].dropna()\n",
    "test=test[find_outliers_IQR(test).isna()].dropna()\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solids</th>\n",
       "      <th>dissolved_oxygen</th>\n",
       "      <th>pH</th>\n",
       "      <th>electrical</th>\n",
       "      <th>NH4</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>TN</th>\n",
       "      <th>PO4P</th>\n",
       "      <th>BOD5</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  solids  dissolved_oxygen   pH  electrical  NH4  NO2  NO3  \\\n",
       "0            0.64    0.41              0.17 0.14        0.80 0.60 0.74 0.03   \n",
       "1            0.62    0.32              0.89 0.77        0.19 0.19 0.27 0.72   \n",
       "2            0.21    0.29              0.52 0.39        0.95 0.67 0.43 0.41   \n",
       "3            0.44    0.18              0.37 0.95        0.78 0.30 0.11 0.63   \n",
       "4            0.82    0.73              0.85 0.56        0.41 0.93 0.25 0.58   \n",
       "...           ...     ...               ...  ...         ...  ...  ...  ...   \n",
       "4995         0.19    0.04              0.97 0.25        0.63 0.30 0.10 0.17   \n",
       "4996         0.51    0.64              0.06 0.56        0.77 0.33 0.51 0.34   \n",
       "4997         0.35    0.94              0.20 0.27        0.36 0.90 0.35 0.19   \n",
       "4998         0.41    0.03              0.73 0.06        0.15 0.57 0.63 0.27   \n",
       "4999         0.87    0.25              0.27 0.14        0.15 0.63 0.04 0.11   \n",
       "\n",
       "       TN  PO4P  BOD5  fake  \n",
       "0    0.84  0.31  0.86  1.00  \n",
       "1    0.18  0.70  0.95  1.00  \n",
       "2    0.65  0.87  0.65  1.00  \n",
       "3    0.13  0.69  0.03  1.00  \n",
       "4    0.11  0.17  0.62  1.00  \n",
       "...   ...   ...   ...   ...  \n",
       "4995 0.93  0.58  0.73  1.00  \n",
       "4996 1.00  0.71  0.33  1.00  \n",
       "4997 0.11  0.53  0.87  1.00  \n",
       "4998 0.12  0.92  0.88  1.00  \n",
       "4999 0.11  0.01  0.31  1.00  \n",
       "\n",
       "[5000 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake=pd.DataFrame([[1,2,3,4,5,6,7,8,9,10,11]],columns=train.columns,index=range(5000))\n",
    "fake.columns\n",
    "for item in fake.columns:\n",
    "    fake[item]=np.random.random(5000)\n",
    "fake['fake']=np.ones(len(fake))\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solids</th>\n",
       "      <th>dissolved_oxygen</th>\n",
       "      <th>pH</th>\n",
       "      <th>electrical</th>\n",
       "      <th>NH4</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>TN</th>\n",
       "      <th>PO4P</th>\n",
       "      <th>BOD5</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>10.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>8.04</td>\n",
       "      <td>662.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>7.70</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.20</td>\n",
       "      <td>8.40</td>\n",
       "      <td>423.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>10.40</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.70</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1407.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>10.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.35</td>\n",
       "      <td>1274.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1230.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  solids  dissolved_oxygen   pH  electrical  NH4  NO2  NO3  \\\n",
       "0            0.64    0.41              0.17 0.14        0.80 0.60 0.74 0.03   \n",
       "1            0.62    0.32              0.89 0.77        0.19 0.19 0.27 0.72   \n",
       "2            0.21    0.29              0.52 0.39        0.95 0.67 0.43 0.41   \n",
       "3            0.44    0.18              0.37 0.95        0.78 0.30 0.11 0.63   \n",
       "4            0.82    0.73              0.85 0.56        0.41 0.93 0.25 0.58   \n",
       "...           ...     ...               ...  ...         ...  ...  ...  ...   \n",
       "5365        10.30   10.00              9.30 8.04      662.00 0.03 0.00 0.08   \n",
       "5366         7.70    4.00             11.20 8.40      423.00 0.02 0.00 0.07   \n",
       "5367        10.40   10.00              9.70 8.50     1407.00 0.03 0.02 2.33   \n",
       "5368        10.80    3.00              8.60 8.35     1274.00 0.02 0.03 1.88   \n",
       "5369         7.40    5.00             10.70 8.30     1230.00 0.12 0.02 1.52   \n",
       "\n",
       "       TN  PO4P  BOD5  fake  \n",
       "0    0.84  0.31  0.86  1.00  \n",
       "1    0.18  0.70  0.95  1.00  \n",
       "2    0.65  0.87  0.65  1.00  \n",
       "3    0.13  0.69  0.03  1.00  \n",
       "4    0.11  0.17  0.62  1.00  \n",
       "...   ...   ...   ...   ...  \n",
       "5365 0.08  0.01  2.30  0.00  \n",
       "5366 0.07  0.01  1.20  0.00  \n",
       "5367 2.35  0.13  3.50  0.00  \n",
       "5368 1.91  0.32  1.50  0.00  \n",
       "5369 1.54  0.27  1.40  0.00  \n",
       "\n",
       "[5370 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fake']=np.zeros(len(train))\n",
    "df=pd.concat([fake,train],axis=0)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solids</th>\n",
       "      <th>dissolved_oxygen</th>\n",
       "      <th>pH</th>\n",
       "      <th>electrical</th>\n",
       "      <th>NH4</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>TN</th>\n",
       "      <th>PO4P</th>\n",
       "      <th>BOD5</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>22.59</td>\n",
       "      <td>15.24</td>\n",
       "      <td>7.60</td>\n",
       "      <td>8.08</td>\n",
       "      <td>369.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15.08</td>\n",
       "      <td>23.58</td>\n",
       "      <td>10.15</td>\n",
       "      <td>8.26</td>\n",
       "      <td>515.84</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5.64</td>\n",
       "      <td>27.44</td>\n",
       "      <td>11.82</td>\n",
       "      <td>7.94</td>\n",
       "      <td>384.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>11.97</td>\n",
       "      <td>22.33</td>\n",
       "      <td>10.35</td>\n",
       "      <td>7.98</td>\n",
       "      <td>261.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8.98</td>\n",
       "      <td>10.48</td>\n",
       "      <td>9.34</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1192.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  solids  dissolved_oxygen   pH  electrical  NH4  NO2  NO3  \\\n",
       "0            0.64    0.41              0.17 0.14        0.80 0.60 0.74 0.03   \n",
       "1            0.62    0.32              0.89 0.77        0.19 0.19 0.27 0.72   \n",
       "2            0.21    0.29              0.52 0.39        0.95 0.67 0.43 0.41   \n",
       "3            0.44    0.18              0.37 0.95        0.78 0.30 0.11 0.63   \n",
       "4            0.82    0.73              0.85 0.56        0.41 0.93 0.25 0.58   \n",
       "...           ...     ...               ...  ...         ...  ...  ...  ...   \n",
       "9995        22.59   15.24              7.60 8.08      369.72 0.07 0.02 1.03   \n",
       "9996        15.08   23.58             10.15 8.26      515.84 0.14 0.03 0.88   \n",
       "9997         5.64   27.44             11.82 7.94      384.63 0.12 0.02 1.38   \n",
       "9998        11.97   22.33             10.35 7.98      261.67 0.03 0.01 0.87   \n",
       "9999         8.98   10.48              9.34 8.12     1192.29 0.04 0.02 1.70   \n",
       "\n",
       "       TN  PO4P  BOD5  fake  \n",
       "0    0.84  0.31  0.86  1.00  \n",
       "1    0.18  0.70  0.95  1.00  \n",
       "2    0.65  0.87  0.65  1.00  \n",
       "3    0.13  0.69  0.03  1.00  \n",
       "4    0.11  0.17  0.62  1.00  \n",
       "...   ...   ...   ...   ...  \n",
       "9995 1.05  0.08  1.23  0.00  \n",
       "9996 0.91  0.08  3.94  0.00  \n",
       "9997 1.40  0.05  1.26  0.00  \n",
       "9998 0.88  0.06  2.10  0.00  \n",
       "9999 1.71  0.10  1.81  0.00  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X=df.drop(['fake'],axis=1)\n",
    "y=df.fake\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "X['fake']=y\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(1,len(df[df.fake==1]))\n",
    "plt.bar(0,len(df[df.fake==0]))\n",
    "plt.show()\n",
    "plt.bar(1,len(X[X.fake==1]))\n",
    "plt.bar(0,len(X[X.fake==0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solids</th>\n",
       "      <th>dissolved_oxygen</th>\n",
       "      <th>pH</th>\n",
       "      <th>electrical</th>\n",
       "      <th>NH4</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO3</th>\n",
       "      <th>TN</th>\n",
       "      <th>PO4P</th>\n",
       "      <th>BOD5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>3.20</td>\n",
       "      <td>26.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>7.90</td>\n",
       "      <td>465.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>2.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>12.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>656.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>6.60</td>\n",
       "      <td>41.00</td>\n",
       "      <td>11.80</td>\n",
       "      <td>8.10</td>\n",
       "      <td>746.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>17.80</td>\n",
       "      <td>35.00</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.40</td>\n",
       "      <td>492.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>25.30</td>\n",
       "      <td>20.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.10</td>\n",
       "      <td>519.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>22.59</td>\n",
       "      <td>15.24</td>\n",
       "      <td>7.60</td>\n",
       "      <td>8.08</td>\n",
       "      <td>369.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15.08</td>\n",
       "      <td>23.58</td>\n",
       "      <td>10.15</td>\n",
       "      <td>8.26</td>\n",
       "      <td>515.84</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5.64</td>\n",
       "      <td>27.44</td>\n",
       "      <td>11.82</td>\n",
       "      <td>7.94</td>\n",
       "      <td>384.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>11.97</td>\n",
       "      <td>22.33</td>\n",
       "      <td>10.35</td>\n",
       "      <td>7.98</td>\n",
       "      <td>261.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8.98</td>\n",
       "      <td>10.48</td>\n",
       "      <td>9.34</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1192.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  solids  dissolved_oxygen   pH  electrical  NH4  NO2  NO3  \\\n",
       "5000         3.20   26.00             10.80 7.90      465.00 0.07 0.02 1.12   \n",
       "5001         2.00   30.00             12.70 7.90      656.00 0.17 0.02 1.13   \n",
       "5002         6.60   41.00             11.80 8.10      746.00 0.10 0.02 1.54   \n",
       "5003        17.80   35.00             10.70 8.40      492.00 0.04 0.02 0.64   \n",
       "5004        25.30   20.00              7.50 8.10      519.00 0.02 0.02 0.37   \n",
       "...           ...     ...               ...  ...         ...  ...  ...  ...   \n",
       "9995        22.59   15.24              7.60 8.08      369.72 0.07 0.02 1.03   \n",
       "9996        15.08   23.58             10.15 8.26      515.84 0.14 0.03 0.88   \n",
       "9997         5.64   27.44             11.82 7.94      384.63 0.12 0.02 1.38   \n",
       "9998        11.97   22.33             10.35 7.98      261.67 0.03 0.01 0.87   \n",
       "9999         8.98   10.48              9.34 8.12     1192.29 0.04 0.02 1.70   \n",
       "\n",
       "       TN  PO4P  BOD5  \n",
       "5000 1.14  0.10  1.60  \n",
       "5001 1.15  0.06  1.40  \n",
       "5002 1.56  0.04  1.40  \n",
       "5003 0.66  0.02  1.90  \n",
       "5004 0.39  0.01  3.10  \n",
       "...   ...   ...   ...  \n",
       "9995 1.05  0.08  1.23  \n",
       "9996 0.91  0.08  3.94  \n",
       "9997 1.40  0.05  1.26  \n",
       "9998 0.88  0.06  2.10  \n",
       "9999 1.71  0.10  1.81  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=X[X.fake==0]\n",
    "train.drop(['fake'],axis=1,inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11) (461, 11)\n"
     ]
    }
   ],
   "source": [
    "train , test =_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 10) (605, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=_prepare_data(train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n",
    "X_test,y_test=_prepare_data(test)\n",
    "# to set a new scaler\n",
    "X_test_scaler=StandardScaler()\n",
    "y_test_scaler=StandardScaler()\n",
    "X_test=X_test_scaler.fit_transform(X_test)\n",
    "y_test=y_test_scaler.fit_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "#to scale by the train scaler\n",
    "# X_test=X_scaler.transform(X_test)\n",
    "# y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_NN_features():\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001))\n",
    "    model.fit(X_train, y_train,epochs=40,batch_size=8,validation_split=0.2)\n",
    "    nnfeatures=model.predict(X_train)\n",
    "    return nnfeatures , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "61/61 [==============================] - 1s 6ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 2/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 3/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 4/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 5/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 6/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 7/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 8/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 9/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 10/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 11/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 12/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 13/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 14/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 15/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 16/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 17/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 18/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 19/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 20/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 21/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 22/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 23/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 24/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 25/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 26/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 27/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 28/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 29/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 30/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 31/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 32/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 33/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 34/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 35/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 36/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 37/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 38/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 39/40\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "Epoch 40/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1556 - val_loss: 1.0866\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "df_train , model =_create_NN_features()\n",
    "df_test=model.predict(X_test)\n",
    "\n",
    "# df_train=X_scaler.transform(df_train)\n",
    "# df_test=X_scaler.transform(df_test)\n",
    "\n",
    "# reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "# models, predictions = reg.fit(df_train, df_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3065837041798538"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()  #using linear kernel for SVM regressor \n",
    "regressor.fit(df_train, y_train)  \n",
    "y_pred = regressor.predict(df_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 11) (197, 11)\n"
     ]
    }
   ],
   "source": [
    "#create a function to find outliers using IQR\n",
    "def find_outliers_IQR(df):\n",
    "   q1=df.quantile(0.25)\n",
    "   q3=df.quantile(0.75)\n",
    "   IQR=q3-q1\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "   return outliers\n",
    "\n",
    "train=train[find_outliers_IQR(train).isna()].dropna()\n",
    "test=test[find_outliers_IQR(test).isna()].dropna()\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train , test=_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=_prepare_data(train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n",
    "X_test,y_test=_prepare_data(test)\n",
    "# to set a new scaler\n",
    "X_test_scaler=StandardScaler()\n",
    "y_test_scaler=StandardScaler()\n",
    "X_test=X_test_scaler.fit_transform(X_test)\n",
    "y_test=y_test_scaler.fit_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "#to scale by the train scaler\n",
    "# X_test=X_scaler.transform(X_test)\n",
    "# y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30/42 [00:36<00:14,  1.22s/it]"
     ]
    }
   ],
   "source": [
    "regressor=['MLPRegressor',\n",
    "'ExtraTreesRegressor',\n",
    "'RandomForestRegressor',\n",
    "'HistGradientBoostingRegressor',\n",
    "'GradientBoostingRegressor',\n",
    "'XGBRegressor',\n",
    "'LGBMRegressor',\n",
    "'NuSVR',\n",
    "'SVR',\n",
    "'BaggingRegressor',\n",
    "'OrthogonalMatchingPursuitCV',\n",
    "'LassoLarsCV',\n",
    "'LassoLarsIC',\n",
    "'LassoCV', \n",
    "'ElasticNetCV',\n",
    "'SGDRegressor', \n",
    "'BayesianRidge',\n",
    "'RidgeCV', \n",
    "'Ridge',\n",
    "'KernelRidge',\n",
    "'TransformedTargetRegressor',\n",
    "'LinearRegression',\n",
    "'LinearSVR',\n",
    "'HuberRegressor',\n",
    "'KNeighborsRegressor',\n",
    "'AdaBoostRegressor',\n",
    "'RANSACRegressor', \n",
    "'LarsCV']\n",
    "\n",
    "reg=LazyRegressor(verbose=0,ignore_warnings=True)\n",
    "models=reg.fit(X_train, X_test, y_train, y_test)\n",
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.9998 - val_loss: 0.9995\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9895\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 0.9289\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.8332 - val_loss: 0.7851\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.6962\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6319 - val_loss: 0.6623\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6403\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 0.6239\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.5698 - val_loss: 0.6092\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.5549 - val_loss: 0.5977\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.5857\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.5737\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.5625\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.5042 - val_loss: 0.5523\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4930 - val_loss: 0.5427\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4823 - val_loss: 0.5339\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4716 - val_loss: 0.5246\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4613 - val_loss: 0.5163\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4511 - val_loss: 0.5088\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4412 - val_loss: 0.5004\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4317 - val_loss: 0.4926\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4224 - val_loss: 0.4854\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.4135 - val_loss: 0.4787\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4721\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3965 - val_loss: 0.4649\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3884 - val_loss: 0.4594\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3806 - val_loss: 0.4545\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3730 - val_loss: 0.4474\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3657 - val_loss: 0.4431\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3586 - val_loss: 0.4372\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3519 - val_loss: 0.4322\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3452 - val_loss: 0.4281\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3388 - val_loss: 0.4226\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3326 - val_loss: 0.4175\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3265 - val_loss: 0.4141\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3206 - val_loss: 0.4105\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 0.4049\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.4012\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.3039 - val_loss: 0.3963\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2985 - val_loss: 0.3927\n",
      "Epoch 41/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2934 - val_loss: 0.3891\n",
      "Epoch 42/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2883 - val_loss: 0.3859\n",
      "Epoch 43/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2834 - val_loss: 0.3831\n",
      "Epoch 44/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2787 - val_loss: 0.3786\n",
      "Epoch 45/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2742 - val_loss: 0.3763\n",
      "Epoch 46/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2696 - val_loss: 0.3739\n",
      "Epoch 47/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2652 - val_loss: 0.3706\n",
      "Epoch 48/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2608 - val_loss: 0.3687\n",
      "Epoch 49/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2565 - val_loss: 0.3665\n",
      "Epoch 50/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2525 - val_loss: 0.3641\n",
      "Epoch 51/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2488 - val_loss: 0.3610\n",
      "Epoch 52/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2446 - val_loss: 0.3604\n",
      "Epoch 53/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2407 - val_loss: 0.3569\n",
      "Epoch 54/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2371 - val_loss: 0.3529\n",
      "Epoch 55/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2336 - val_loss: 0.3514\n",
      "Epoch 56/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2301 - val_loss: 0.3495\n",
      "Epoch 57/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2268 - val_loss: 0.3499\n",
      "Epoch 58/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2236 - val_loss: 0.3485\n",
      "Epoch 59/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2204 - val_loss: 0.3474\n",
      "Epoch 60/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2175 - val_loss: 0.3444\n",
      "Epoch 61/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2143 - val_loss: 0.3427\n",
      "Epoch 62/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2114 - val_loss: 0.3406\n",
      "Epoch 63/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2086 - val_loss: 0.3387\n",
      "Epoch 64/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2058 - val_loss: 0.3381\n",
      "Epoch 65/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2031 - val_loss: 0.3367\n",
      "Epoch 66/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.2006 - val_loss: 0.3357\n",
      "Epoch 67/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1980 - val_loss: 0.3335\n",
      "Epoch 68/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1954 - val_loss: 0.3322\n",
      "Epoch 69/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1928 - val_loss: 0.3317\n",
      "Epoch 70/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1905 - val_loss: 0.3305\n",
      "Epoch 71/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1880 - val_loss: 0.3273\n",
      "Epoch 72/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.3280\n",
      "Epoch 73/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1837 - val_loss: 0.3274\n",
      "Epoch 74/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1817 - val_loss: 0.3263\n",
      "Epoch 75/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.3235\n",
      "Epoch 76/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1777 - val_loss: 0.3218\n",
      "Epoch 77/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1757 - val_loss: 0.3208\n",
      "Epoch 78/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 0.3254\n",
      "Epoch 79/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.3193\n",
      "Epoch 80/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1701 - val_loss: 0.3202\n",
      "Epoch 81/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1683 - val_loss: 0.3174\n",
      "Epoch 82/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1669 - val_loss: 0.3174\n",
      "Epoch 83/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.3154\n",
      "Epoch 84/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1636 - val_loss: 0.3159\n",
      "Epoch 85/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1621 - val_loss: 0.3145\n",
      "Epoch 86/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1606 - val_loss: 0.3135\n",
      "Epoch 87/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1593 - val_loss: 0.3137\n",
      "Epoch 88/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.3130\n",
      "Epoch 89/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.3123\n",
      "Epoch 90/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1553 - val_loss: 0.3124\n",
      "Epoch 91/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.3089\n",
      "Epoch 92/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1528 - val_loss: 0.3098\n",
      "Epoch 93/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1518 - val_loss: 0.3095\n",
      "Epoch 94/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1505 - val_loss: 0.3089\n",
      "Epoch 95/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1493 - val_loss: 0.3067\n",
      "Epoch 96/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1485 - val_loss: 0.3061\n",
      "Epoch 97/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.3065\n",
      "Epoch 98/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.3042\n",
      "Epoch 99/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 0.3053\n",
      "Epoch 100/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1441 - val_loss: 0.3032\n",
      "Epoch 101/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1433 - val_loss: 0.3022\n",
      "Epoch 102/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1424 - val_loss: 0.3019\n",
      "Epoch 103/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.2999\n",
      "Epoch 104/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.3025\n",
      "Epoch 105/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.3011\n",
      "Epoch 106/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.2974\n",
      "Epoch 107/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1381 - val_loss: 0.2975\n",
      "Epoch 108/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.2978\n",
      "Epoch 109/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.2956\n",
      "Epoch 110/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1358 - val_loss: 0.2953\n",
      "Epoch 111/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1351 - val_loss: 0.2938\n",
      "Epoch 112/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1343 - val_loss: 0.2949\n",
      "Epoch 113/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1336 - val_loss: 0.2945\n",
      "Epoch 114/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.2929\n",
      "Epoch 115/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1323 - val_loss: 0.2911\n",
      "Epoch 116/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1316 - val_loss: 0.2904\n",
      "Epoch 117/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 0.2922\n",
      "Epoch 118/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1304 - val_loss: 0.2913\n",
      "Epoch 119/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1298 - val_loss: 0.2890\n",
      "Epoch 120/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.2911\n",
      "Epoch 121/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.2883\n",
      "Epoch 122/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.2886\n",
      "Epoch 123/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.2874\n",
      "Epoch 124/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1269 - val_loss: 0.2865\n",
      "Epoch 125/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.2869\n",
      "Epoch 126/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.2864\n",
      "Epoch 127/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1257 - val_loss: 0.2874\n",
      "Epoch 128/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1251 - val_loss: 0.2858\n",
      "Epoch 129/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1247 - val_loss: 0.2847\n",
      "Epoch 130/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1243 - val_loss: 0.2859\n",
      "Epoch 131/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.2834\n",
      "Epoch 132/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.2843\n",
      "Epoch 133/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1230 - val_loss: 0.2831\n",
      "Epoch 134/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1226 - val_loss: 0.2835\n",
      "Epoch 135/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 0.2830\n",
      "Epoch 136/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 0.2847\n",
      "Epoch 137/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.2815\n",
      "Epoch 138/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.2835\n",
      "Epoch 139/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.2818\n",
      "Epoch 140/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1203 - val_loss: 0.2818\n",
      "Epoch 141/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.2815\n",
      "Epoch 142/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1196 - val_loss: 0.2821\n",
      "Epoch 143/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1192 - val_loss: 0.2810\n",
      "Epoch 144/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.2827\n",
      "Epoch 145/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 0.2857\n",
      "Epoch 146/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1184 - val_loss: 0.2828\n",
      "Epoch 147/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1180 - val_loss: 0.2823\n",
      "Epoch 148/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.2827\n",
      "Epoch 149/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.2833\n",
      "Epoch 150/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.2846\n",
      "Epoch 151/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.2849\n",
      "Epoch 152/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.2813\n",
      "Epoch 153/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 0.2842\n",
      "Epoch 154/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.2847\n",
      "Epoch 155/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 0.2848\n",
      "Epoch 156/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1154 - val_loss: 0.2833\n",
      "Epoch 157/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.2825\n",
      "Epoch 158/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.2818\n",
      "Epoch 159/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.2823\n",
      "Epoch 160/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.2856\n",
      "Epoch 161/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.2855\n",
      "Epoch 162/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.2869\n",
      "Epoch 163/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1137 - val_loss: 0.2847\n",
      "Epoch 164/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.2851\n",
      "Epoch 165/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1133 - val_loss: 0.2869\n",
      "Epoch 166/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.2849\n",
      "Epoch 167/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.2864\n",
      "Epoch 168/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.2859\n",
      "Epoch 169/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.2857\n",
      "Epoch 170/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1121 - val_loss: 0.2898\n",
      "Epoch 171/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1120 - val_loss: 0.2893\n",
      "Epoch 172/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.2927\n",
      "Epoch 173/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.2928\n",
      "Epoch 174/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 0.2914\n",
      "Epoch 175/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 0.2940\n",
      "Epoch 176/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.2922\n",
      "Epoch 177/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.2925\n",
      "Epoch 178/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.2975\n",
      "Epoch 179/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1103 - val_loss: 0.2977\n",
      "Epoch 180/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.2999\n",
      "Epoch 181/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.2974\n",
      "Epoch 182/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.2982\n",
      "Epoch 183/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.3000\n",
      "Epoch 184/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.2994\n",
      "Epoch 185/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1088 - val_loss: 0.2995\n",
      "Epoch 186/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.2998\n",
      "Epoch 187/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.3022\n",
      "Epoch 188/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.3000\n",
      "Epoch 189/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1080 - val_loss: 0.3045\n",
      "Epoch 190/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1077 - val_loss: 0.3023\n",
      "Epoch 191/200\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.1076 - val_loss: 0.3040\n",
      "Epoch 192/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.3050\n",
      "Epoch 193/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.3050\n",
      "Epoch 194/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 0.3024\n",
      "Epoch 195/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.3044\n",
      "Epoch 196/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.3008\n",
      "Epoch 197/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1066 - val_loss: 0.3067\n",
      "Epoch 198/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.3010\n",
      "Epoch 199/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.3041\n",
      "Epoch 200/200\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.3053\n",
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.694686280717733"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_shape=(X_train[0].shape[0],),kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(17,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(10,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(7,kernel_initializer='RandomNormal', activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='RandomNormal',activation='linear'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.0001))\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    \n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2 , y_pred,model\n",
    "history , r2 , y_pred,model=_compile_model(X_train,y_train,X_test,y_test,200,30)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
