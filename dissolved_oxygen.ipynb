{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense  \n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 11) (492, 11)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Training set 2011-2015')\n",
    "train.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "test=pd.read_excel('Data set - Tisa.xlsx',sheet_name='Testing set 2016-2019 ')\n",
    "test.columns=['temperature', 'solids', 'dissolved_oxygen', 'pH','electrical', 'NH4', 'NO2', 'NO3', 'TN', 'PO4P', 'BOD5']\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data(data):\n",
    "    X_train=data.drop(['dissolved_oxygen'],axis=1)\n",
    "    y_train=data.dissolved_oxygen\n",
    "    return X_train , y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_data(X_train,y_train):\n",
    "    X_scaler=StandardScaler()\n",
    "    X_train_scaled=X_scaler.fit_transform(X_train)\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_scaled=y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "    print(X_train_scaled.shape, y_train_scaled.shape)\n",
    "    return X_train_scaled,y_train_scaled , X_scaler , y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 10) (626, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train=_prepare_data(train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(X_train, y_train,epochs=10,batch_size=8)\n",
    "\n",
    "KerasRegressor(model=model, epochs=100, batch_size=5, verbose=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have some missing values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 10) (605, 1)\n"
     ]
    }
   ],
   "source": [
    "nonul_train=train.drop(list(train[train.isna().any(axis=1)].index),axis=0)\n",
    "X_train,y_train=_prepare_data(nonul_train)\n",
    "X_train,y_train , X_scaler , y_scaler=_scale_data(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonul_test=test.drop(list(test[test.isna().any(axis=1)].index),axis=0)\n",
    "X_test,y_test=_prepare_data(nonul_test)\n",
    "\n",
    "X_test=X_scaler.transform(X_test)\n",
    "y_test=y_scaler.transform(np.array(y_test).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compile_model(X_train,y_train,X_test,y_test,epochs,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train[0].shape[0], input_shape=(X_train[0].shape[0],), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train,epochs=epochs,batch_size=batch_size,validation_data=(X_test,y_test))\n",
    "    history=model.history\n",
    "    y_pred=model.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    return history , r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history , r2=_compile_model(X_train,y_train,X_test,y_test,80,32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size itrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.9799 - val_loss: 0.7359\n",
      "Epoch 2/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.9088 - val_loss: 0.6404\n",
      "Epoch 3/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.8070 - val_loss: 0.5552\n",
      "Epoch 4/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7539 - val_loss: 0.5241\n",
      "Epoch 5/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.7305 - val_loss: 0.5132\n",
      "Epoch 6/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.5101\n",
      "Epoch 7/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7085 - val_loss: 0.5094\n",
      "Epoch 8/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7015 - val_loss: 0.5120\n",
      "Epoch 9/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6972 - val_loss: 0.5161\n",
      "Epoch 10/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6921 - val_loss: 0.5183\n",
      "Epoch 11/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6865 - val_loss: 0.5198\n",
      "Epoch 12/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.5228\n",
      "Epoch 13/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6811 - val_loss: 0.5293\n",
      "Epoch 14/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6774 - val_loss: 0.5236\n",
      "Epoch 15/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6711 - val_loss: 0.5423\n",
      "Epoch 16/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6710 - val_loss: 0.5474\n",
      "Epoch 17/80\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6664 - val_loss: 0.5505\n",
      "Epoch 18/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.5586\n",
      "Epoch 19/80\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6625 - val_loss: 0.5614\n",
      "Epoch 20/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6614 - val_loss: 0.5651\n",
      "Epoch 21/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6603 - val_loss: 0.5694\n",
      "Epoch 22/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6542 - val_loss: 0.5734\n",
      "Epoch 23/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.5748\n",
      "Epoch 24/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6532 - val_loss: 0.5776\n",
      "Epoch 25/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6485 - val_loss: 0.5882\n",
      "Epoch 26/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6496 - val_loss: 0.5938\n",
      "Epoch 27/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6466 - val_loss: 0.5967\n",
      "Epoch 28/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6045\n",
      "Epoch 29/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6415 - val_loss: 0.6026\n",
      "Epoch 30/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6414 - val_loss: 0.6111\n",
      "Epoch 31/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6379 - val_loss: 0.6140\n",
      "Epoch 32/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6383 - val_loss: 0.6207\n",
      "Epoch 33/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6362 - val_loss: 0.6262\n",
      "Epoch 34/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6365 - val_loss: 0.6216\n",
      "Epoch 35/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.6184\n",
      "Epoch 36/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6298 - val_loss: 0.6329\n",
      "Epoch 37/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 0.6263\n",
      "Epoch 38/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6286 - val_loss: 0.6348\n",
      "Epoch 39/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 0.6279\n",
      "Epoch 40/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 0.6415\n",
      "Epoch 41/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 0.6441\n",
      "Epoch 42/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 0.6487\n",
      "Epoch 43/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.6534\n",
      "Epoch 44/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 0.6487\n",
      "Epoch 45/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.6561\n",
      "Epoch 46/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.6626\n",
      "Epoch 47/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6479\n",
      "Epoch 48/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 0.6680\n",
      "Epoch 49/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6758\n",
      "Epoch 50/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6759\n",
      "Epoch 51/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6100 - val_loss: 0.6767\n",
      "Epoch 52/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6789\n",
      "Epoch 53/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.6857\n",
      "Epoch 54/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 0.6832\n",
      "Epoch 55/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6081 - val_loss: 0.6872\n",
      "Epoch 56/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.7021\n",
      "Epoch 57/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6859\n",
      "Epoch 58/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6922\n",
      "Epoch 59/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6860\n",
      "Epoch 60/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6943\n",
      "Epoch 61/80\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5997 - val_loss: 0.6932\n",
      "Epoch 62/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6994\n",
      "Epoch 63/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.7113\n",
      "Epoch 64/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.7096\n",
      "Epoch 65/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 0.7101\n",
      "Epoch 66/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.7167\n",
      "Epoch 67/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 0.7133\n",
      "Epoch 68/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7084\n",
      "Epoch 69/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.7189\n",
      "Epoch 70/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5947 - val_loss: 0.7183\n",
      "Epoch 71/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5965 - val_loss: 0.6940\n",
      "Epoch 72/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5948 - val_loss: 0.7194\n",
      "Epoch 73/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.7219\n",
      "Epoch 74/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 0.7274\n",
      "Epoch 75/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5946 - val_loss: 0.7025\n",
      "Epoch 76/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5920 - val_loss: 0.7325\n",
      "Epoch 77/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5931 - val_loss: 0.7333\n",
      "Epoch 78/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7332\n",
      "Epoch 79/80\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5917 - val_loss: 0.7364\n",
      "Epoch 80/80\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 0.7460\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:25<02:33, 25.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.9808 - val_loss: 0.7415\n",
      "Epoch 2/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 0.6931\n",
      "Epoch 3/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8759 - val_loss: 0.6326\n",
      "Epoch 4/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8170 - val_loss: 0.5860\n",
      "Epoch 5/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7784 - val_loss: 0.5577\n",
      "Epoch 6/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7581 - val_loss: 0.5426\n",
      "Epoch 7/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7415 - val_loss: 0.5330\n",
      "Epoch 8/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7320 - val_loss: 0.5275\n",
      "Epoch 9/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7240 - val_loss: 0.5250\n",
      "Epoch 10/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7163 - val_loss: 0.5229\n",
      "Epoch 11/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7151 - val_loss: 0.5213\n",
      "Epoch 12/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7072 - val_loss: 0.5226\n",
      "Epoch 13/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7048 - val_loss: 0.5233\n",
      "Epoch 14/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7022 - val_loss: 0.5234\n",
      "Epoch 15/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6981 - val_loss: 0.5262\n",
      "Epoch 16/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6947 - val_loss: 0.5276\n",
      "Epoch 17/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6922 - val_loss: 0.5278\n",
      "Epoch 18/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6896 - val_loss: 0.5301\n",
      "Epoch 19/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6873 - val_loss: 0.5313\n",
      "Epoch 20/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6847 - val_loss: 0.5332\n",
      "Epoch 21/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6843 - val_loss: 0.5379\n",
      "Epoch 22/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6826 - val_loss: 0.5354\n",
      "Epoch 23/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6790 - val_loss: 0.5348\n",
      "Epoch 24/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6769 - val_loss: 0.5412\n",
      "Epoch 25/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6766 - val_loss: 0.5463\n",
      "Epoch 26/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6752 - val_loss: 0.5417\n",
      "Epoch 27/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6722 - val_loss: 0.5490\n",
      "Epoch 28/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6718 - val_loss: 0.5517\n",
      "Epoch 29/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6698 - val_loss: 0.5536\n",
      "Epoch 30/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6687 - val_loss: 0.5550\n",
      "Epoch 31/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6678 - val_loss: 0.5580\n",
      "Epoch 32/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6664 - val_loss: 0.5575\n",
      "Epoch 33/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6654 - val_loss: 0.5616\n",
      "Epoch 34/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6644 - val_loss: 0.5560\n",
      "Epoch 35/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.5646\n",
      "Epoch 36/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6601 - val_loss: 0.5640\n",
      "Epoch 37/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6578 - val_loss: 0.5692\n",
      "Epoch 38/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6570 - val_loss: 0.5688\n",
      "Epoch 39/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.5755\n",
      "Epoch 40/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6527 - val_loss: 0.5732\n",
      "Epoch 41/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6542 - val_loss: 0.5770\n",
      "Epoch 42/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6509 - val_loss: 0.5771\n",
      "Epoch 43/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6493 - val_loss: 0.5864\n",
      "Epoch 44/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.5880\n",
      "Epoch 45/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6481 - val_loss: 0.5871\n",
      "Epoch 46/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6464 - val_loss: 0.5888\n",
      "Epoch 47/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6430 - val_loss: 0.5926\n",
      "Epoch 48/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6426 - val_loss: 0.5951\n",
      "Epoch 49/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6406 - val_loss: 0.5990\n",
      "Epoch 50/80\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.5928\n",
      "Epoch 51/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6400 - val_loss: 0.6079\n",
      "Epoch 52/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6393 - val_loss: 0.6064\n",
      "Epoch 53/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.6070\n",
      "Epoch 54/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6358 - val_loss: 0.6103\n",
      "Epoch 55/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6340 - val_loss: 0.6139\n",
      "Epoch 56/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6363 - val_loss: 0.6106\n",
      "Epoch 57/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6354 - val_loss: 0.6225\n",
      "Epoch 58/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6318 - val_loss: 0.6203\n",
      "Epoch 59/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6330 - val_loss: 0.6258\n",
      "Epoch 60/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6298 - val_loss: 0.6278\n",
      "Epoch 61/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6299 - val_loss: 0.6240\n",
      "Epoch 62/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6290 - val_loss: 0.6303\n",
      "Epoch 63/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 0.6337\n",
      "Epoch 64/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 0.6316\n",
      "Epoch 65/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6266 - val_loss: 0.6348\n",
      "Epoch 66/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.6382\n",
      "Epoch 67/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6249 - val_loss: 0.6453\n",
      "Epoch 68/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 0.6260\n",
      "Epoch 69/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 0.6411\n",
      "Epoch 70/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6230 - val_loss: 0.6479\n",
      "Epoch 71/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6211 - val_loss: 0.6581\n",
      "Epoch 72/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6213 - val_loss: 0.6579\n",
      "Epoch 73/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6206 - val_loss: 0.6589\n",
      "Epoch 74/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6205 - val_loss: 0.6618\n",
      "Epoch 75/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6602\n",
      "Epoch 76/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6200 - val_loss: 0.6628\n",
      "Epoch 77/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6188 - val_loss: 0.6635\n",
      "Epoch 78/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6190 - val_loss: 0.6558\n",
      "Epoch 79/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.6669\n",
      "Epoch 80/80\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.6762\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:38<01:30, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 0.9905 - val_loss: 0.7545\n",
      "Epoch 2/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9711 - val_loss: 0.7318\n",
      "Epoch 3/80\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.9438 - val_loss: 0.7010\n",
      "Epoch 4/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9091 - val_loss: 0.6619\n",
      "Epoch 5/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8672 - val_loss: 0.6235\n",
      "Epoch 6/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8280 - val_loss: 0.5908\n",
      "Epoch 7/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7954 - val_loss: 0.5677\n",
      "Epoch 8/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7736 - val_loss: 0.5496\n",
      "Epoch 9/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7575 - val_loss: 0.5399\n",
      "Epoch 10/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7466 - val_loss: 0.5300\n",
      "Epoch 11/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7398 - val_loss: 0.5238\n",
      "Epoch 12/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7320 - val_loss: 0.5205\n",
      "Epoch 13/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7265 - val_loss: 0.5165\n",
      "Epoch 14/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7224 - val_loss: 0.5140\n",
      "Epoch 15/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.5125\n",
      "Epoch 16/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 0.5108\n",
      "Epoch 17/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7112 - val_loss: 0.5099\n",
      "Epoch 18/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7081 - val_loss: 0.5105\n",
      "Epoch 19/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7053 - val_loss: 0.5086\n",
      "Epoch 20/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 0.5089\n",
      "Epoch 21/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7003 - val_loss: 0.5105\n",
      "Epoch 22/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6979 - val_loss: 0.5112\n",
      "Epoch 23/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6956 - val_loss: 0.5124\n",
      "Epoch 24/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6940 - val_loss: 0.5111\n",
      "Epoch 25/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.5129\n",
      "Epoch 26/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6915 - val_loss: 0.5110\n",
      "Epoch 27/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6891 - val_loss: 0.5159\n",
      "Epoch 28/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 0.5157\n",
      "Epoch 29/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.5196\n",
      "Epoch 30/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.5202\n",
      "Epoch 31/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6814 - val_loss: 0.5215\n",
      "Epoch 32/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.5220\n",
      "Epoch 33/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6784 - val_loss: 0.5236\n",
      "Epoch 34/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.5245\n",
      "Epoch 35/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6763 - val_loss: 0.5276\n",
      "Epoch 36/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.5298\n",
      "Epoch 37/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.5303\n",
      "Epoch 38/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.5318\n",
      "Epoch 39/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.5307\n",
      "Epoch 40/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6696 - val_loss: 0.5341\n",
      "Epoch 41/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6682 - val_loss: 0.5367\n",
      "Epoch 42/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6675 - val_loss: 0.5401\n",
      "Epoch 43/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6674 - val_loss: 0.5400\n",
      "Epoch 44/80\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6666 - val_loss: 0.5437\n",
      "Epoch 45/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.5474\n",
      "Epoch 46/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.5465\n",
      "Epoch 47/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6625 - val_loss: 0.5489\n",
      "Epoch 48/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.5504\n",
      "Epoch 49/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.5535\n",
      "Epoch 50/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.5511\n",
      "Epoch 51/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.5531\n",
      "Epoch 52/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.5564\n",
      "Epoch 53/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.5603\n",
      "Epoch 54/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.5582\n",
      "Epoch 55/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.5626\n",
      "Epoch 56/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.5638\n",
      "Epoch 57/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.5650\n",
      "Epoch 58/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.5648\n",
      "Epoch 59/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.5642\n",
      "Epoch 60/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.5716\n",
      "Epoch 61/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6452 - val_loss: 0.5711\n",
      "Epoch 62/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6439 - val_loss: 0.5715\n",
      "Epoch 63/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6429 - val_loss: 0.5771\n",
      "Epoch 64/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6424 - val_loss: 0.5773\n",
      "Epoch 65/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6418 - val_loss: 0.5761\n",
      "Epoch 66/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6417 - val_loss: 0.5788\n",
      "Epoch 67/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.5830\n",
      "Epoch 68/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6394 - val_loss: 0.5819\n",
      "Epoch 69/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6383 - val_loss: 0.5817\n",
      "Epoch 70/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6376 - val_loss: 0.5887\n",
      "Epoch 71/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.5929\n",
      "Epoch 72/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6354 - val_loss: 0.5918\n",
      "Epoch 73/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.5947\n",
      "Epoch 74/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.5961\n",
      "Epoch 75/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.5990\n",
      "Epoch 76/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.6000\n",
      "Epoch 77/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.5965\n",
      "Epoch 78/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6026\n",
      "Epoch 79/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6323 - val_loss: 0.5991\n",
      "Epoch 80/80\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.6062\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:47<00:55, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 0.9821 - val_loss: 0.7479\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9699 - val_loss: 0.7359\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9566 - val_loss: 0.7218\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9412 - val_loss: 0.7055\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9231 - val_loss: 0.6877\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9031 - val_loss: 0.6685\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8835 - val_loss: 0.6474\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8618 - val_loss: 0.6267\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8406 - val_loss: 0.6080\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8212 - val_loss: 0.5910\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8044 - val_loss: 0.5739\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7850 - val_loss: 0.5614\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7713 - val_loss: 0.5499\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7583 - val_loss: 0.5401\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7461 - val_loss: 0.5328\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7374 - val_loss: 0.5270\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7299 - val_loss: 0.5231\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7257 - val_loss: 0.5206\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7192 - val_loss: 0.5185\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7174 - val_loss: 0.5185\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7120 - val_loss: 0.5181\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7091 - val_loss: 0.5182\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7057 - val_loss: 0.5174\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7031 - val_loss: 0.5177\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7007 - val_loss: 0.5180\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6988 - val_loss: 0.5195\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6958 - val_loss: 0.5196\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6941 - val_loss: 0.5208\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6919 - val_loss: 0.5219\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6902 - val_loss: 0.5245\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6888 - val_loss: 0.5269\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6865 - val_loss: 0.5266\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6847 - val_loss: 0.5282\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6834 - val_loss: 0.5302\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6821 - val_loss: 0.5316\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6802 - val_loss: 0.5328\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6799 - val_loss: 0.5401\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6767 - val_loss: 0.5428\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6748 - val_loss: 0.5429\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6730 - val_loss: 0.5436\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6721 - val_loss: 0.5459\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6704 - val_loss: 0.5466\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6693 - val_loss: 0.5482\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6682 - val_loss: 0.5485\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6675 - val_loss: 0.5491\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6664 - val_loss: 0.5506\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6655 - val_loss: 0.5524\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6638 - val_loss: 0.5612\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6626 - val_loss: 0.5653\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6633 - val_loss: 0.5696\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.5690\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6606 - val_loss: 0.5722\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6595 - val_loss: 0.5712\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6585 - val_loss: 0.5730\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6580 - val_loss: 0.5717\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6562 - val_loss: 0.5795\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6560 - val_loss: 0.5817\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6561 - val_loss: 0.5940\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6538 - val_loss: 0.5964\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6534 - val_loss: 0.5961\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6533 - val_loss: 0.5996\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6521 - val_loss: 0.5966\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6506 - val_loss: 0.5977\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6503 - val_loss: 0.5983\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6504 - val_loss: 0.6038\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6494 - val_loss: 0.6047\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6493 - val_loss: 0.5986\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6483 - val_loss: 0.6079\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6483 - val_loss: 0.6151\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6468 - val_loss: 0.6117\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6456 - val_loss: 0.6119\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6454 - val_loss: 0.6139\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6451 - val_loss: 0.6131\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6443 - val_loss: 0.6127\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6435 - val_loss: 0.6137\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6429 - val_loss: 0.6149\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6422 - val_loss: 0.6168\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6415 - val_loss: 0.6194\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6411 - val_loss: 0.6188\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6411 - val_loss: 0.6180\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:58<00:38, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 43ms/step - loss: 0.9982 - val_loss: 0.7683\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9938 - val_loss: 0.7645\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9896 - val_loss: 0.7601\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9847 - val_loss: 0.7551\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9794 - val_loss: 0.7492\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9729 - val_loss: 0.7424\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9653 - val_loss: 0.7346\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9561 - val_loss: 0.7258\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9464 - val_loss: 0.7157\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9351 - val_loss: 0.7046\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9231 - val_loss: 0.6926\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9097 - val_loss: 0.6799\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8961 - val_loss: 0.6665\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8806 - val_loss: 0.6532\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8667 - val_loss: 0.6395\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8505 - val_loss: 0.6267\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8372 - val_loss: 0.6140\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8235 - val_loss: 0.6022\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8092 - val_loss: 0.5918\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7988 - val_loss: 0.5820\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7867 - val_loss: 0.5736\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7784 - val_loss: 0.5658\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7706 - val_loss: 0.5592\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7622 - val_loss: 0.5534\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7564 - val_loss: 0.5486\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7499 - val_loss: 0.5442\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7448 - val_loss: 0.5404\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7399 - val_loss: 0.5368\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7363 - val_loss: 0.5335\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7322 - val_loss: 0.5305\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7286 - val_loss: 0.5282\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7255 - val_loss: 0.5262\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7226 - val_loss: 0.5243\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7192 - val_loss: 0.5226\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7166 - val_loss: 0.5214\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7147 - val_loss: 0.5200\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7119 - val_loss: 0.5187\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7102 - val_loss: 0.5181\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7076 - val_loss: 0.5177\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7054 - val_loss: 0.5172\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7033 - val_loss: 0.5166\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7019 - val_loss: 0.5163\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7009 - val_loss: 0.5164\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6988 - val_loss: 0.5164\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6969 - val_loss: 0.5165\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6961 - val_loss: 0.5169\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6945 - val_loss: 0.5167\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6936 - val_loss: 0.5172\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6925 - val_loss: 0.5174\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6913 - val_loss: 0.5180\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6905 - val_loss: 0.5183\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6890 - val_loss: 0.5185\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6881 - val_loss: 0.5186\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6872 - val_loss: 0.5194\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6870 - val_loss: 0.5205\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6855 - val_loss: 0.5208\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6848 - val_loss: 0.5221\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6839 - val_loss: 0.5229\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6832 - val_loss: 0.5240\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6821 - val_loss: 0.5242\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6811 - val_loss: 0.5255\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6805 - val_loss: 0.5270\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6795 - val_loss: 0.5278\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6793 - val_loss: 0.5299\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6780 - val_loss: 0.5309\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6773 - val_loss: 0.5315\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6765 - val_loss: 0.5323\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6763 - val_loss: 0.5332\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6758 - val_loss: 0.5350\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6747 - val_loss: 0.5356\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6741 - val_loss: 0.5369\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6734 - val_loss: 0.5379\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6725 - val_loss: 0.5378\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6724 - val_loss: 0.5398\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6715 - val_loss: 0.5411\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6705 - val_loss: 0.5417\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6699 - val_loss: 0.5418\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6690 - val_loss: 0.5428\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6681 - val_loss: 0.5434\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6680 - val_loss: 0.5454\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:03<00:20, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 0.9990 - val_loss: 0.7723\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9963 - val_loss: 0.7700\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9937 - val_loss: 0.7679\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9912 - val_loss: 0.7656\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9888 - val_loss: 0.7633\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9861 - val_loss: 0.7609\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9835 - val_loss: 0.7583\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9807 - val_loss: 0.7555\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9775 - val_loss: 0.7524\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9739 - val_loss: 0.7489\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9700 - val_loss: 0.7450\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9659 - val_loss: 0.7407\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9612 - val_loss: 0.7361\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9563 - val_loss: 0.7311\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9509 - val_loss: 0.7257\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9449 - val_loss: 0.7200\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.9388 - val_loss: 0.7139\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9319 - val_loss: 0.7075\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9251 - val_loss: 0.7007\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9175 - val_loss: 0.6935\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9096 - val_loss: 0.6862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9012 - val_loss: 0.6786\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8928 - val_loss: 0.6707\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8846 - val_loss: 0.6627\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8755 - val_loss: 0.6547\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8663 - val_loss: 0.6467\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8579 - val_loss: 0.6388\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8484 - val_loss: 0.6310\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8400 - val_loss: 0.6233\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8311 - val_loss: 0.6158\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8231 - val_loss: 0.6086\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8145 - val_loss: 0.6019\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8072 - val_loss: 0.5954\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7999 - val_loss: 0.5894\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7926 - val_loss: 0.5840\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7865 - val_loss: 0.5790\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7801 - val_loss: 0.5745\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7752 - val_loss: 0.5702\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7702 - val_loss: 0.5664\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7652 - val_loss: 0.5628\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7611 - val_loss: 0.5594\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7567 - val_loss: 0.5565\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7528 - val_loss: 0.5539\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7494 - val_loss: 0.5514\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7459 - val_loss: 0.5490\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7429 - val_loss: 0.5468\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7398 - val_loss: 0.5447\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7366 - val_loss: 0.5427\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7341 - val_loss: 0.5410\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7307 - val_loss: 0.5394\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7285 - val_loss: 0.5379\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7252 - val_loss: 0.5366\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7224 - val_loss: 0.5357\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7204 - val_loss: 0.5351\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7178 - val_loss: 0.5344\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7147 - val_loss: 0.5333\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7126 - val_loss: 0.5326\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7108 - val_loss: 0.5322\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7088 - val_loss: 0.5316\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7071 - val_loss: 0.5314\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7051 - val_loss: 0.5318\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7031 - val_loss: 0.5328\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7022 - val_loss: 0.5340\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6999 - val_loss: 0.5349\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6988 - val_loss: 0.5357\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6970 - val_loss: 0.5361\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6956 - val_loss: 0.5363\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6943 - val_loss: 0.5363\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6933 - val_loss: 0.5363\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6920 - val_loss: 0.5361\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6909 - val_loss: 0.5359\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6896 - val_loss: 0.5365\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6887 - val_loss: 0.5372\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6870 - val_loss: 0.5379\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6855 - val_loss: 0.5394\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6843 - val_loss: 0.5409\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6834 - val_loss: 0.5422\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6819 - val_loss: 0.5430\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6811 - val_loss: 0.5439\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6804 - val_loss: 0.5449\n",
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [01:10<00:09,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.9992 - val_loss: 0.7777\n",
      "Epoch 2/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9973 - val_loss: 0.7762\n",
      "Epoch 3/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9955 - val_loss: 0.7747\n",
      "Epoch 4/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9938 - val_loss: 0.7733\n",
      "Epoch 5/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9921 - val_loss: 0.7719\n",
      "Epoch 6/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9904 - val_loss: 0.7704\n",
      "Epoch 7/80\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.9886 - val_loss: 0.7689\n",
      "Epoch 8/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9868 - val_loss: 0.7674\n",
      "Epoch 9/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9849 - val_loss: 0.7658\n",
      "Epoch 10/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9829 - val_loss: 0.7641\n",
      "Epoch 11/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9807 - val_loss: 0.7623\n",
      "Epoch 12/80\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9784 - val_loss: 0.7603\n",
      "Epoch 13/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9760 - val_loss: 0.7581\n",
      "Epoch 14/80\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9734 - val_loss: 0.7558\n",
      "Epoch 15/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9706 - val_loss: 0.7533\n",
      "Epoch 16/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9678 - val_loss: 0.7506\n",
      "Epoch 17/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9646 - val_loss: 0.7478\n",
      "Epoch 18/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9614 - val_loss: 0.7448\n",
      "Epoch 19/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9580 - val_loss: 0.7416\n",
      "Epoch 20/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9543 - val_loss: 0.7382\n",
      "Epoch 21/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9505 - val_loss: 0.7347\n",
      "Epoch 22/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9465 - val_loss: 0.7309\n",
      "Epoch 23/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9424 - val_loss: 0.7270\n",
      "Epoch 24/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9380 - val_loss: 0.7229\n",
      "Epoch 25/80\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9335 - val_loss: 0.7188\n",
      "Epoch 26/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9288 - val_loss: 0.7144\n",
      "Epoch 27/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.9240 - val_loss: 0.7099\n",
      "Epoch 28/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9193 - val_loss: 0.7053\n",
      "Epoch 29/80\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9142 - val_loss: 0.7006\n",
      "Epoch 30/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9091 - val_loss: 0.6957\n",
      "Epoch 31/80\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.9038 - val_loss: 0.6908\n",
      "Epoch 32/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8987 - val_loss: 0.6858\n",
      "Epoch 33/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8933 - val_loss: 0.6808\n",
      "Epoch 34/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8880 - val_loss: 0.6757\n",
      "Epoch 35/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8828 - val_loss: 0.6707\n",
      "Epoch 36/80\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8774 - val_loss: 0.6657\n",
      "Epoch 37/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8723 - val_loss: 0.6606\n",
      "Epoch 38/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8672 - val_loss: 0.6556\n",
      "Epoch 39/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8620 - val_loss: 0.6506\n",
      "Epoch 40/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8571 - val_loss: 0.6456\n",
      "Epoch 41/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8521 - val_loss: 0.6407\n",
      "Epoch 42/80\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8474 - val_loss: 0.6359\n",
      "Epoch 43/80\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8426 - val_loss: 0.6312\n",
      "Epoch 44/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8381 - val_loss: 0.6266\n",
      "Epoch 45/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8337 - val_loss: 0.6219\n",
      "Epoch 46/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8297 - val_loss: 0.6174\n",
      "Epoch 47/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8254 - val_loss: 0.6131\n",
      "Epoch 48/80\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.8213 - val_loss: 0.6090\n",
      "Epoch 49/80\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.8176 - val_loss: 0.6048\n",
      "Epoch 50/80\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.8137 - val_loss: 0.6008\n",
      "Epoch 51/80\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.8099 - val_loss: 0.5968\n",
      "Epoch 52/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8065 - val_loss: 0.5928\n",
      "Epoch 53/80\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8027 - val_loss: 0.5890\n",
      "Epoch 54/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7995 - val_loss: 0.5853\n",
      "Epoch 55/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7963 - val_loss: 0.5818\n",
      "Epoch 56/80\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7932 - val_loss: 0.5785\n",
      "Epoch 57/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7903 - val_loss: 0.5752\n",
      "Epoch 58/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7875 - val_loss: 0.5721\n",
      "Epoch 59/80\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7848 - val_loss: 0.5690\n",
      "Epoch 60/80\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7822 - val_loss: 0.5659\n",
      "Epoch 61/80\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7797 - val_loss: 0.5629\n",
      "Epoch 62/80\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7773 - val_loss: 0.5601\n",
      "Epoch 63/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7750 - val_loss: 0.5576\n",
      "Epoch 64/80\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7728 - val_loss: 0.5552\n",
      "Epoch 65/80\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7706 - val_loss: 0.5530\n",
      "Epoch 66/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7688 - val_loss: 0.5508\n",
      "Epoch 67/80\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7669 - val_loss: 0.5486\n",
      "Epoch 68/80\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7651 - val_loss: 0.5467\n",
      "Epoch 69/80\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7633 - val_loss: 0.5448\n",
      "Epoch 70/80\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7617 - val_loss: 0.5430\n",
      "Epoch 71/80\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7599 - val_loss: 0.5412\n",
      "Epoch 72/80\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7583 - val_loss: 0.5395\n",
      "Epoch 73/80\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7568 - val_loss: 0.5378\n",
      "Epoch 74/80\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7552 - val_loss: 0.5361\n",
      "Epoch 75/80\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7538 - val_loss: 0.5345\n",
      "Epoch 76/80\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.7523 - val_loss: 0.5331\n",
      "Epoch 77/80\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7508 - val_loss: 0.5317\n",
      "Epoch 78/80\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7497 - val_loss: 0.5303\n",
      "Epoch 79/80\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.7482 - val_loss: 0.5290\n",
      "Epoch 80/80\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.7467 - val_loss: 0.5277\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:17<00:00, 11.02s/it]\n"
     ]
    }
   ],
   "source": [
    "r2_all=[]\n",
    "for item in tqdm([8,16,32,64,128,256,512]):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,80,item)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(7),r2_all)\n",
    "plt.xticks(range(7),[8,16,32,64,128,256,512])\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "76/76 [==============================] - 2s 10ms/step - loss: 0.9837 - val_loss: 0.7372\n",
      "Epoch 2/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.9113 - val_loss: 0.6397\n",
      "Epoch 3/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8040 - val_loss: 0.5580\n",
      "Epoch 4/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7648 - val_loss: 0.5265\n",
      "Epoch 5/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7454 - val_loss: 0.5178\n",
      "Epoch 6/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7327 - val_loss: 0.5125\n",
      "Epoch 7/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7259 - val_loss: 0.5091\n",
      "Epoch 8/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7218 - val_loss: 0.5103\n",
      "Epoch 9/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7142 - val_loss: 0.5089\n",
      "Epoch 10/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7095 - val_loss: 0.5105\n",
      "Epoch 11/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7060 - val_loss: 0.5116\n",
      "Epoch 12/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7024 - val_loss: 0.5125\n",
      "Epoch 13/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6997 - val_loss: 0.5144\n",
      "Epoch 14/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6959 - val_loss: 0.5179\n",
      "Epoch 15/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 0.5230\n",
      "Epoch 16/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6918 - val_loss: 0.5241\n",
      "Epoch 17/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6897 - val_loss: 0.5269\n",
      "Epoch 18/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.5244\n",
      "Epoch 19/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6843 - val_loss: 0.5326\n",
      "Epoch 20/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6852 - val_loss: 0.5356\n",
      "Epoch 21/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6815 - val_loss: 0.5336\n",
      "Epoch 22/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.5439\n",
      "Epoch 23/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6788 - val_loss: 0.5483\n",
      "Epoch 24/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6783 - val_loss: 0.5472\n",
      "Epoch 25/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6772 - val_loss: 0.5498\n",
      "Epoch 26/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6750 - val_loss: 0.5560\n",
      "Epoch 27/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6762 - val_loss: 0.5490\n",
      "Epoch 28/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 0.5596\n",
      "Epoch 29/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6687 - val_loss: 0.5676\n",
      "Epoch 30/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6677 - val_loss: 0.5717\n",
      "Epoch 31/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6644 - val_loss: 0.5713\n",
      "Epoch 32/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6633 - val_loss: 0.5744\n",
      "Epoch 33/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6626 - val_loss: 0.5778\n",
      "Epoch 34/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6589 - val_loss: 0.5786\n",
      "Epoch 35/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6575 - val_loss: 0.5842\n",
      "Epoch 36/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6559 - val_loss: 0.5880\n",
      "Epoch 37/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6544 - val_loss: 0.5909\n",
      "Epoch 38/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6516 - val_loss: 0.5922\n",
      "Epoch 39/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6519 - val_loss: 0.5981\n",
      "Epoch 40/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6524 - val_loss: 0.5970\n",
      "Epoch 41/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6481 - val_loss: 0.5931\n",
      "Epoch 42/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6452 - val_loss: 0.6046\n",
      "Epoch 43/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6442 - val_loss: 0.6003\n",
      "Epoch 44/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6414 - val_loss: 0.6100\n",
      "Epoch 45/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 0.6183\n",
      "Epoch 46/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6402 - val_loss: 0.6152\n",
      "Epoch 47/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6384 - val_loss: 0.6172\n",
      "Epoch 48/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6382 - val_loss: 0.6189\n",
      "Epoch 49/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6376 - val_loss: 0.6236\n",
      "Epoch 50/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6360 - val_loss: 0.6145\n",
      "Epoch 51/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6327 - val_loss: 0.6321\n",
      "Epoch 52/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 0.6302\n",
      "Epoch 53/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6310 - val_loss: 0.6400\n",
      "Epoch 54/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6317 - val_loss: 0.6447\n",
      "Epoch 55/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6302 - val_loss: 0.6480\n",
      "Epoch 56/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6299 - val_loss: 0.6424\n",
      "Epoch 57/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 0.6440\n",
      "Epoch 58/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6281 - val_loss: 0.6436\n",
      "Epoch 59/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6285 - val_loss: 0.6487\n",
      "Epoch 60/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 0.6587\n",
      "Epoch 61/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6227 - val_loss: 0.6545\n",
      "Epoch 62/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6236 - val_loss: 0.6543\n",
      "Epoch 63/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6256 - val_loss: 0.6553\n",
      "Epoch 64/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 0.6621\n",
      "Epoch 65/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 0.6466\n",
      "Epoch 66/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 0.6714\n",
      "Epoch 67/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 0.6660\n",
      "Epoch 68/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6234 - val_loss: 0.6713\n",
      "Epoch 69/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6205 - val_loss: 0.6803\n",
      "Epoch 70/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.6751\n",
      "Epoch 71/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6200 - val_loss: 0.6853\n",
      "Epoch 72/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.6844\n",
      "Epoch 73/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.6787\n",
      "Epoch 74/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.6757\n",
      "Epoch 75/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.6592\n",
      "Epoch 76/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.6922\n",
      "Epoch 77/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6139 - val_loss: 0.6876\n",
      "Epoch 78/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.6710\n",
      "Epoch 79/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.7002\n",
      "Epoch 80/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 0.6996\n",
      "Epoch 81/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.6971\n",
      "Epoch 82/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6785\n",
      "Epoch 83/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.7068\n",
      "Epoch 84/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.6971\n",
      "Epoch 85/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6125 - val_loss: 0.7070\n",
      "Epoch 86/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.7138\n",
      "Epoch 87/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 0.7112\n",
      "Epoch 88/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 0.7096\n",
      "Epoch 89/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 0.7136\n",
      "Epoch 90/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 0.7165\n",
      "Epoch 91/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 0.7156\n",
      "Epoch 92/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.7170\n",
      "Epoch 93/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.7075\n",
      "Epoch 94/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.7252\n",
      "Epoch 95/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.7163\n",
      "Epoch 96/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.7252\n",
      "Epoch 97/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.7115\n",
      "Epoch 98/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.7133\n",
      "Epoch 99/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.7180\n",
      "Epoch 100/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.7209\n",
      "Epoch 101/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.7158\n",
      "Epoch 102/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.7189\n",
      "Epoch 103/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.7196\n",
      "Epoch 104/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.7252\n",
      "Epoch 105/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7300\n",
      "Epoch 106/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.7263\n",
      "Epoch 107/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.7243\n",
      "Epoch 108/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.7301\n",
      "Epoch 109/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.7350\n",
      "Epoch 110/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.7358\n",
      "Epoch 111/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.7255\n",
      "Epoch 112/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7434\n",
      "Epoch 113/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.7344\n",
      "Epoch 114/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.7336\n",
      "Epoch 115/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.7272\n",
      "Epoch 116/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.7443\n",
      "Epoch 117/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6001 - val_loss: 0.7257\n",
      "Epoch 118/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.7300\n",
      "Epoch 119/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.7489\n",
      "Epoch 120/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5996 - val_loss: 0.7333\n",
      "Epoch 121/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.7404\n",
      "Epoch 122/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.7360\n",
      "Epoch 123/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.7243\n",
      "Epoch 124/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.7450\n",
      "Epoch 125/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5964 - val_loss: 0.7351\n",
      "Epoch 126/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.7407\n",
      "Epoch 127/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 0.7421\n",
      "Epoch 128/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5961 - val_loss: 0.7497\n",
      "Epoch 129/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.7388\n",
      "Epoch 130/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 0.7463\n",
      "Epoch 131/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5983 - val_loss: 0.7423\n",
      "Epoch 132/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 0.7514\n",
      "Epoch 133/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5956 - val_loss: 0.7476\n",
      "Epoch 134/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.7438\n",
      "Epoch 135/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.7347\n",
      "Epoch 136/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5980 - val_loss: 0.7511\n",
      "Epoch 137/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 0.7530\n",
      "Epoch 138/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.7514\n",
      "Epoch 139/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.7677\n",
      "Epoch 140/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5964 - val_loss: 0.7565\n",
      "Epoch 141/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7559\n",
      "Epoch 142/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.7590\n",
      "Epoch 143/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5916 - val_loss: 0.7478\n",
      "Epoch 144/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.7574\n",
      "Epoch 145/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5923 - val_loss: 0.7578\n",
      "Epoch 146/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5931 - val_loss: 0.7664\n",
      "Epoch 147/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 0.7511\n",
      "Epoch 148/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5950 - val_loss: 0.7717\n",
      "Epoch 149/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5912 - val_loss: 0.7517\n",
      "Epoch 150/150\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5939 - val_loss: 0.7650\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:39<02:39, 39.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "76/76 [==============================] - 1s 5ms/step - loss: 0.9687 - val_loss: 0.7145\n",
      "Epoch 2/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8932 - val_loss: 0.6228\n",
      "Epoch 3/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.8119 - val_loss: 0.5546\n",
      "Epoch 4/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7557 - val_loss: 0.5183\n",
      "Epoch 5/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7308 - val_loss: 0.5040\n",
      "Epoch 6/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7170 - val_loss: 0.5032\n",
      "Epoch 7/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.7091 - val_loss: 0.5033\n",
      "Epoch 8/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7029 - val_loss: 0.5075\n",
      "Epoch 9/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6974 - val_loss: 0.5114\n",
      "Epoch 10/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6938 - val_loss: 0.5145\n",
      "Epoch 11/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6887 - val_loss: 0.5167\n",
      "Epoch 12/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 0.5238\n",
      "Epoch 13/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6833 - val_loss: 0.5286\n",
      "Epoch 14/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6785 - val_loss: 0.5296\n",
      "Epoch 15/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6756 - val_loss: 0.5372\n",
      "Epoch 16/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6721 - val_loss: 0.5395\n",
      "Epoch 17/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6666 - val_loss: 0.5434\n",
      "Epoch 18/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6652 - val_loss: 0.5521\n",
      "Epoch 19/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.5475\n",
      "Epoch 20/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6582 - val_loss: 0.5555\n",
      "Epoch 21/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6580 - val_loss: 0.5645\n",
      "Epoch 22/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6541 - val_loss: 0.5640\n",
      "Epoch 23/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.5697\n",
      "Epoch 24/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6474 - val_loss: 0.5738\n",
      "Epoch 25/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6482 - val_loss: 0.5819\n",
      "Epoch 26/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6444 - val_loss: 0.5810\n",
      "Epoch 27/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 0.5894\n",
      "Epoch 28/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6394 - val_loss: 0.5849\n",
      "Epoch 29/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6394 - val_loss: 0.5978\n",
      "Epoch 30/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6379 - val_loss: 0.5971\n",
      "Epoch 31/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6361 - val_loss: 0.6079\n",
      "Epoch 32/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6350 - val_loss: 0.6089\n",
      "Epoch 33/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6340 - val_loss: 0.6186\n",
      "Epoch 34/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6349 - val_loss: 0.6010\n",
      "Epoch 35/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6326 - val_loss: 0.6362\n",
      "Epoch 36/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6337 - val_loss: 0.6265\n",
      "Epoch 37/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6314 - val_loss: 0.6254\n",
      "Epoch 38/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6298 - val_loss: 0.6231\n",
      "Epoch 39/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6281 - val_loss: 0.6412\n",
      "Epoch 40/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 0.6387\n",
      "Epoch 41/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6280 - val_loss: 0.6493\n",
      "Epoch 42/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6254 - val_loss: 0.6448\n",
      "Epoch 43/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 0.6471\n",
      "Epoch 44/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 0.6503\n",
      "Epoch 45/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.6491\n",
      "Epoch 46/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6229 - val_loss: 0.6582\n",
      "Epoch 47/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.6612\n",
      "Epoch 48/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6592\n",
      "Epoch 49/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 0.6570\n",
      "Epoch 50/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 0.6685\n",
      "Epoch 51/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 0.6667\n",
      "Epoch 52/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 0.6749\n",
      "Epoch 53/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6194 - val_loss: 0.6785\n",
      "Epoch 54/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 0.6801\n",
      "Epoch 55/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.6797\n",
      "Epoch 56/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6201 - val_loss: 0.6825\n",
      "Epoch 57/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 0.6746\n",
      "Epoch 58/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6165 - val_loss: 0.6778\n",
      "Epoch 59/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.6829\n",
      "Epoch 60/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 0.6629\n",
      "Epoch 61/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6150 - val_loss: 0.6851\n",
      "Epoch 62/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6796\n",
      "Epoch 63/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.6847\n",
      "Epoch 64/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 0.6896\n",
      "Epoch 65/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6725\n",
      "Epoch 66/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6924\n",
      "Epoch 67/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 0.6916\n",
      "Epoch 68/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.7027\n",
      "Epoch 69/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 0.6995\n",
      "Epoch 70/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 0.7009\n",
      "Epoch 71/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.7153\n",
      "Epoch 72/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.7086\n",
      "Epoch 73/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.7005\n",
      "Epoch 74/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.7085\n",
      "Epoch 75/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.7042\n",
      "Epoch 76/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6089 - val_loss: 0.6841\n",
      "Epoch 77/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.7095\n",
      "Epoch 78/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.7056\n",
      "Epoch 79/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.7111\n",
      "Epoch 80/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.7102\n",
      "Epoch 81/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.6983\n",
      "Epoch 82/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.7104\n",
      "Epoch 83/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.7218\n",
      "Epoch 84/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.7089\n",
      "Epoch 85/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.7095\n",
      "Epoch 86/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.7168\n",
      "Epoch 87/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5997 - val_loss: 0.7065\n",
      "Epoch 88/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5990 - val_loss: 0.7102\n",
      "Epoch 89/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.7160\n",
      "Epoch 90/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5985 - val_loss: 0.7072\n",
      "Epoch 91/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6023 - val_loss: 0.7211\n",
      "Epoch 92/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5959 - val_loss: 0.7217\n",
      "Epoch 93/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.7194\n",
      "Epoch 94/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 0.7227\n",
      "Epoch 95/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.7168\n",
      "Epoch 96/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.7166\n",
      "Epoch 97/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7071\n",
      "Epoch 98/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 0.7210\n",
      "Epoch 99/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5950 - val_loss: 0.7254\n",
      "Epoch 100/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5938 - val_loss: 0.7295\n",
      "Epoch 101/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.7232\n",
      "Epoch 102/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5919 - val_loss: 0.7227\n",
      "Epoch 103/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5908 - val_loss: 0.7246\n",
      "Epoch 104/160\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5957 - val_loss: 0.7173\n",
      "Epoch 105/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 0.7389\n",
      "Epoch 106/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5923 - val_loss: 0.7278\n",
      "Epoch 107/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7267\n",
      "Epoch 108/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5894 - val_loss: 0.7297\n",
      "Epoch 109/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 0.7429\n",
      "Epoch 110/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5925 - val_loss: 0.7086\n",
      "Epoch 111/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5870 - val_loss: 0.7221\n",
      "Epoch 112/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5908 - val_loss: 0.7403\n",
      "Epoch 113/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5903 - val_loss: 0.7282\n",
      "Epoch 114/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5900 - val_loss: 0.7279\n",
      "Epoch 115/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5865 - val_loss: 0.7345\n",
      "Epoch 116/160\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5887 - val_loss: 0.7357\n",
      "Epoch 117/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7272\n",
      "Epoch 118/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5859 - val_loss: 0.7212\n",
      "Epoch 119/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7414\n",
      "Epoch 120/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5847 - val_loss: 0.7201\n",
      "Epoch 121/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5875 - val_loss: 0.7388\n",
      "Epoch 122/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5854 - val_loss: 0.7332\n",
      "Epoch 123/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.7336\n",
      "Epoch 124/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.7252\n",
      "Epoch 125/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5866 - val_loss: 0.7195\n",
      "Epoch 126/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5856 - val_loss: 0.7347\n",
      "Epoch 127/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5836 - val_loss: 0.7240\n",
      "Epoch 128/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.7328\n",
      "Epoch 129/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5812 - val_loss: 0.7336\n",
      "Epoch 130/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5835 - val_loss: 0.7286\n",
      "Epoch 131/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5842 - val_loss: 0.7289\n",
      "Epoch 132/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5818 - val_loss: 0.7175\n",
      "Epoch 133/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5864 - val_loss: 0.7269\n",
      "Epoch 134/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7338\n",
      "Epoch 135/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5809 - val_loss: 0.7235\n",
      "Epoch 136/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5785 - val_loss: 0.7284\n",
      "Epoch 137/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.7393\n",
      "Epoch 138/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.7362\n",
      "Epoch 139/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7290\n",
      "Epoch 140/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7428\n",
      "Epoch 141/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5771 - val_loss: 0.7437\n",
      "Epoch 142/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5778 - val_loss: 0.7536\n",
      "Epoch 143/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5806 - val_loss: 0.7343\n",
      "Epoch 144/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5781 - val_loss: 0.7425\n",
      "Epoch 145/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5757 - val_loss: 0.7394\n",
      "Epoch 146/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5753 - val_loss: 0.7411\n",
      "Epoch 147/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5749 - val_loss: 0.7373\n",
      "Epoch 148/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5779 - val_loss: 0.7423\n",
      "Epoch 149/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5775 - val_loss: 0.7284\n",
      "Epoch 150/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5762 - val_loss: 0.7351\n",
      "Epoch 151/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5762 - val_loss: 0.7324\n",
      "Epoch 152/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5747 - val_loss: 0.7405\n",
      "Epoch 153/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5752 - val_loss: 0.7378\n",
      "Epoch 154/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5773 - val_loss: 0.7480\n",
      "Epoch 155/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5720 - val_loss: 0.7366\n",
      "Epoch 156/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5767 - val_loss: 0.7371\n",
      "Epoch 157/160\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5750 - val_loss: 0.7468\n",
      "Epoch 158/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5698 - val_loss: 0.7387\n",
      "Epoch 159/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5724 - val_loss: 0.7527\n",
      "Epoch 160/160\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5733 - val_loss: 0.7545\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:27<02:13, 44.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9785 - val_loss: 0.7254\n",
      "Epoch 2/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8835 - val_loss: 0.6215\n",
      "Epoch 3/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7971 - val_loss: 0.5613\n",
      "Epoch 4/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.5341\n",
      "Epoch 5/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7379 - val_loss: 0.5211\n",
      "Epoch 6/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7267 - val_loss: 0.5161\n",
      "Epoch 7/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7206 - val_loss: 0.5103\n",
      "Epoch 8/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7129 - val_loss: 0.5137\n",
      "Epoch 9/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7081 - val_loss: 0.5145\n",
      "Epoch 10/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7015 - val_loss: 0.5145\n",
      "Epoch 11/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6979 - val_loss: 0.5183\n",
      "Epoch 12/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6940 - val_loss: 0.5199\n",
      "Epoch 13/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.5244\n",
      "Epoch 14/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6868 - val_loss: 0.5199\n",
      "Epoch 15/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6796 - val_loss: 0.5375\n",
      "Epoch 16/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6759 - val_loss: 0.5379\n",
      "Epoch 17/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6744 - val_loss: 0.5410\n",
      "Epoch 18/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6719 - val_loss: 0.5456\n",
      "Epoch 19/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6688 - val_loss: 0.5511\n",
      "Epoch 20/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6655 - val_loss: 0.5443\n",
      "Epoch 21/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.5595\n",
      "Epoch 22/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.5584\n",
      "Epoch 23/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.5618\n",
      "Epoch 24/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6554 - val_loss: 0.5727\n",
      "Epoch 25/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6547 - val_loss: 0.5762\n",
      "Epoch 26/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6512 - val_loss: 0.5697\n",
      "Epoch 27/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.5973\n",
      "Epoch 28/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.5944\n",
      "Epoch 29/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6443 - val_loss: 0.5993\n",
      "Epoch 30/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6017\n",
      "Epoch 31/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6023\n",
      "Epoch 32/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6082\n",
      "Epoch 33/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.6093\n",
      "Epoch 34/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6391 - val_loss: 0.6085\n",
      "Epoch 35/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6367 - val_loss: 0.6179\n",
      "Epoch 36/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6257\n",
      "Epoch 37/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6215\n",
      "Epoch 38/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6312\n",
      "Epoch 39/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.6348\n",
      "Epoch 40/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6391\n",
      "Epoch 41/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6379\n",
      "Epoch 42/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.6431\n",
      "Epoch 43/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6341\n",
      "Epoch 44/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6290 - val_loss: 0.6394\n",
      "Epoch 45/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.6472\n",
      "Epoch 46/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.6536\n",
      "Epoch 47/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6270 - val_loss: 0.6477\n",
      "Epoch 48/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6229 - val_loss: 0.6571\n",
      "Epoch 49/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.6640\n",
      "Epoch 50/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6528\n",
      "Epoch 51/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.6585\n",
      "Epoch 52/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.6509\n",
      "Epoch 53/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6208 - val_loss: 0.6760\n",
      "Epoch 54/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 0.6701\n",
      "Epoch 55/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 0.6817\n",
      "Epoch 56/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6184 - val_loss: 0.6763\n",
      "Epoch 57/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6178 - val_loss: 0.6836\n",
      "Epoch 58/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6198 - val_loss: 0.6818\n",
      "Epoch 59/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6174 - val_loss: 0.6878\n",
      "Epoch 60/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.6819\n",
      "Epoch 61/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6168 - val_loss: 0.6812\n",
      "Epoch 62/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6909\n",
      "Epoch 63/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6862\n",
      "Epoch 64/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6123 - val_loss: 0.6861\n",
      "Epoch 65/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6118 - val_loss: 0.6860\n",
      "Epoch 66/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6957\n",
      "Epoch 67/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6110 - val_loss: 0.7037\n",
      "Epoch 68/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6101 - val_loss: 0.6948\n",
      "Epoch 69/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6145 - val_loss: 0.6652\n",
      "Epoch 70/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.7126\n",
      "Epoch 71/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6903\n",
      "Epoch 72/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.7008\n",
      "Epoch 73/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6928\n",
      "Epoch 74/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6085 - val_loss: 0.7062\n",
      "Epoch 75/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.7017\n",
      "Epoch 76/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.7099\n",
      "Epoch 77/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6992\n",
      "Epoch 78/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6057 - val_loss: 0.7096\n",
      "Epoch 79/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6054 - val_loss: 0.7031\n",
      "Epoch 80/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6063 - val_loss: 0.6831\n",
      "Epoch 81/170\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6101 - val_loss: 0.7142\n",
      "Epoch 82/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6062 - val_loss: 0.7192\n",
      "Epoch 83/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6032 - val_loss: 0.7051\n",
      "Epoch 84/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6064 - val_loss: 0.7129\n",
      "Epoch 85/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.7105\n",
      "Epoch 86/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.7018\n",
      "Epoch 87/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.7142\n",
      "Epoch 88/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.7225\n",
      "Epoch 89/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6031 - val_loss: 0.7063\n",
      "Epoch 90/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.7251\n",
      "Epoch 91/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.7173\n",
      "Epoch 92/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.7178\n",
      "Epoch 93/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6015 - val_loss: 0.7041\n",
      "Epoch 94/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.7196\n",
      "Epoch 95/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5962 - val_loss: 0.7206\n",
      "Epoch 96/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.7318\n",
      "Epoch 97/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5951 - val_loss: 0.7199\n",
      "Epoch 98/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.7225\n",
      "Epoch 99/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5956 - val_loss: 0.7185\n",
      "Epoch 100/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5951 - val_loss: 0.7253\n",
      "Epoch 101/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5972 - val_loss: 0.7329\n",
      "Epoch 102/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5960 - val_loss: 0.7030\n",
      "Epoch 103/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.7296\n",
      "Epoch 104/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7166\n",
      "Epoch 105/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7094\n",
      "Epoch 106/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5907 - val_loss: 0.7128\n",
      "Epoch 107/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5890 - val_loss: 0.7204\n",
      "Epoch 108/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5931 - val_loss: 0.7264\n",
      "Epoch 109/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5911 - val_loss: 0.7285\n",
      "Epoch 110/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5921 - val_loss: 0.7386\n",
      "Epoch 111/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7335\n",
      "Epoch 112/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.7453\n",
      "Epoch 113/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.7253\n",
      "Epoch 114/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5871 - val_loss: 0.7323\n",
      "Epoch 115/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5869 - val_loss: 0.7282\n",
      "Epoch 116/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5894 - val_loss: 0.7293\n",
      "Epoch 117/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5874 - val_loss: 0.7212\n",
      "Epoch 118/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5878 - val_loss: 0.7313\n",
      "Epoch 119/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.7071\n",
      "Epoch 120/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5810 - val_loss: 0.7262\n",
      "Epoch 121/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5834 - val_loss: 0.7260\n",
      "Epoch 122/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5846 - val_loss: 0.7427\n",
      "Epoch 123/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5828 - val_loss: 0.7281\n",
      "Epoch 124/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.7395\n",
      "Epoch 125/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5812 - val_loss: 0.7281\n",
      "Epoch 126/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7342\n",
      "Epoch 127/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5828 - val_loss: 0.7396\n",
      "Epoch 128/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5813 - val_loss: 0.7081\n",
      "Epoch 129/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5940 - val_loss: 0.7593\n",
      "Epoch 130/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5805 - val_loss: 0.7506\n",
      "Epoch 131/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5811 - val_loss: 0.7470\n",
      "Epoch 132/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5780 - val_loss: 0.7494\n",
      "Epoch 133/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5755 - val_loss: 0.7360\n",
      "Epoch 134/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5799 - val_loss: 0.7466\n",
      "Epoch 135/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.7388\n",
      "Epoch 136/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5790 - val_loss: 0.7400\n",
      "Epoch 137/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7400\n",
      "Epoch 138/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5788 - val_loss: 0.7377\n",
      "Epoch 139/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5766 - val_loss: 0.7394\n",
      "Epoch 140/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5751 - val_loss: 0.7450\n",
      "Epoch 141/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5720 - val_loss: 0.7470\n",
      "Epoch 142/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5753 - val_loss: 0.7547\n",
      "Epoch 143/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5748 - val_loss: 0.7419\n",
      "Epoch 144/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5759 - val_loss: 0.7297\n",
      "Epoch 145/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5731 - val_loss: 0.7569\n",
      "Epoch 146/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5711 - val_loss: 0.7328\n",
      "Epoch 147/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5766 - val_loss: 0.7437\n",
      "Epoch 148/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5720 - val_loss: 0.7234\n",
      "Epoch 149/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5721 - val_loss: 0.7644\n",
      "Epoch 150/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5712 - val_loss: 0.7533\n",
      "Epoch 151/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5697 - val_loss: 0.7437\n",
      "Epoch 152/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5714 - val_loss: 0.7439\n",
      "Epoch 153/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5716 - val_loss: 0.7602\n",
      "Epoch 154/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5718 - val_loss: 0.7518\n",
      "Epoch 155/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5663 - val_loss: 0.7527\n",
      "Epoch 156/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5661 - val_loss: 0.7397\n",
      "Epoch 157/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5725 - val_loss: 0.7523\n",
      "Epoch 158/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5697 - val_loss: 0.7265\n",
      "Epoch 159/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5662 - val_loss: 0.7576\n",
      "Epoch 160/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5669 - val_loss: 0.7555\n",
      "Epoch 161/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5677 - val_loss: 0.7611\n",
      "Epoch 162/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5652 - val_loss: 0.7472\n",
      "Epoch 163/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5653 - val_loss: 0.7512\n",
      "Epoch 164/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5658 - val_loss: 0.7553\n",
      "Epoch 165/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5676 - val_loss: 0.7418\n",
      "Epoch 166/170\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5640 - val_loss: 0.7682\n",
      "Epoch 167/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5645 - val_loss: 0.7512\n",
      "Epoch 168/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5669 - val_loss: 0.7531\n",
      "Epoch 169/170\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5657 - val_loss: 0.7496\n",
      "Epoch 170/170\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5689 - val_loss: 0.7605\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:26<01:42, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9952 - val_loss: 0.7502\n",
      "Epoch 2/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.9221 - val_loss: 0.6498\n",
      "Epoch 3/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8188 - val_loss: 0.5614\n",
      "Epoch 4/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7630 - val_loss: 0.5248\n",
      "Epoch 5/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7413 - val_loss: 0.5118\n",
      "Epoch 6/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7256 - val_loss: 0.5067\n",
      "Epoch 7/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7182 - val_loss: 0.5046\n",
      "Epoch 8/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7073 - val_loss: 0.5044\n",
      "Epoch 9/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7012 - val_loss: 0.5060\n",
      "Epoch 10/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6940 - val_loss: 0.5049\n",
      "Epoch 11/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6887 - val_loss: 0.5087\n",
      "Epoch 12/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6831 - val_loss: 0.5092\n",
      "Epoch 13/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6794 - val_loss: 0.5102\n",
      "Epoch 14/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6765 - val_loss: 0.5144\n",
      "Epoch 15/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6707 - val_loss: 0.5144\n",
      "Epoch 16/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6662 - val_loss: 0.5257\n",
      "Epoch 17/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6647 - val_loss: 0.5273\n",
      "Epoch 18/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6603 - val_loss: 0.5255\n",
      "Epoch 19/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.5326\n",
      "Epoch 20/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.5331\n",
      "Epoch 21/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.5341\n",
      "Epoch 22/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.5479\n",
      "Epoch 23/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.5488\n",
      "Epoch 24/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6466 - val_loss: 0.5591\n",
      "Epoch 25/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6462 - val_loss: 0.5567\n",
      "Epoch 26/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6443 - val_loss: 0.5669\n",
      "Epoch 27/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6422 - val_loss: 0.5631\n",
      "Epoch 28/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6416 - val_loss: 0.5726\n",
      "Epoch 29/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6384 - val_loss: 0.5764\n",
      "Epoch 30/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6375 - val_loss: 0.5837\n",
      "Epoch 31/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6371 - val_loss: 0.5864\n",
      "Epoch 32/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.5833\n",
      "Epoch 33/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6334 - val_loss: 0.5847\n",
      "Epoch 34/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.5950\n",
      "Epoch 35/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.5878\n",
      "Epoch 36/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6342 - val_loss: 0.5985\n",
      "Epoch 37/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6305 - val_loss: 0.6034\n",
      "Epoch 38/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.5998\n",
      "Epoch 39/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 0.6092\n",
      "Epoch 40/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6264 - val_loss: 0.6108\n",
      "Epoch 41/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6269 - val_loss: 0.6239\n",
      "Epoch 42/180\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6251 - val_loss: 0.6173\n",
      "Epoch 43/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6281 - val_loss: 0.6175\n",
      "Epoch 44/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.6268\n",
      "Epoch 45/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6237 - val_loss: 0.6210\n",
      "Epoch 46/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.6248\n",
      "Epoch 47/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.6384\n",
      "Epoch 48/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6205 - val_loss: 0.6305\n",
      "Epoch 49/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.6373\n",
      "Epoch 50/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6214 - val_loss: 0.6213\n",
      "Epoch 51/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6557\n",
      "Epoch 52/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.6497\n",
      "Epoch 53/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6616\n",
      "Epoch 54/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6545\n",
      "Epoch 55/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6188 - val_loss: 0.6552\n",
      "Epoch 56/180\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6196 - val_loss: 0.6460\n",
      "Epoch 57/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6701\n",
      "Epoch 58/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6741\n",
      "Epoch 59/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 0.6718\n",
      "Epoch 60/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6145 - val_loss: 0.6647\n",
      "Epoch 61/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6175 - val_loss: 0.6623\n",
      "Epoch 62/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6147 - val_loss: 0.6722\n",
      "Epoch 63/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6136 - val_loss: 0.6795\n",
      "Epoch 64/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6721\n",
      "Epoch 65/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6130 - val_loss: 0.6756\n",
      "Epoch 66/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.6638\n",
      "Epoch 67/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6845\n",
      "Epoch 68/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6092 - val_loss: 0.6794\n",
      "Epoch 69/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6108 - val_loss: 0.6913\n",
      "Epoch 70/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6110 - val_loss: 0.6886\n",
      "Epoch 71/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.6823\n",
      "Epoch 72/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.6876\n",
      "Epoch 73/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6968\n",
      "Epoch 74/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6891\n",
      "Epoch 75/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6685\n",
      "Epoch 76/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6071 - val_loss: 0.7051\n",
      "Epoch 77/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6827\n",
      "Epoch 78/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6028 - val_loss: 0.6856\n",
      "Epoch 79/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6956\n",
      "Epoch 80/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6919\n",
      "Epoch 81/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6989\n",
      "Epoch 82/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6898\n",
      "Epoch 83/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6892\n",
      "Epoch 84/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.7003\n",
      "Epoch 85/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.7025\n",
      "Epoch 86/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.7021\n",
      "Epoch 87/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5985 - val_loss: 0.7004\n",
      "Epoch 88/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.7036\n",
      "Epoch 89/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.7021\n",
      "Epoch 90/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5975 - val_loss: 0.6942\n",
      "Epoch 91/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.6975\n",
      "Epoch 92/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.7068\n",
      "Epoch 93/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.7141\n",
      "Epoch 94/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5955 - val_loss: 0.7030\n",
      "Epoch 95/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5934 - val_loss: 0.7073\n",
      "Epoch 96/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5954 - val_loss: 0.7040\n",
      "Epoch 97/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5964 - val_loss: 0.6993\n",
      "Epoch 98/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5960 - val_loss: 0.7129\n",
      "Epoch 99/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5909 - val_loss: 0.7196\n",
      "Epoch 100/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5942 - val_loss: 0.6962\n",
      "Epoch 101/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5897 - val_loss: 0.7224\n",
      "Epoch 102/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7313\n",
      "Epoch 103/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5936 - val_loss: 0.6897\n",
      "Epoch 104/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5915 - val_loss: 0.7280\n",
      "Epoch 105/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 0.7211\n",
      "Epoch 106/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5897 - val_loss: 0.7173\n",
      "Epoch 107/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5912 - val_loss: 0.7254\n",
      "Epoch 108/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5884 - val_loss: 0.7328\n",
      "Epoch 109/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5886 - val_loss: 0.7297\n",
      "Epoch 110/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7227\n",
      "Epoch 111/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5864 - val_loss: 0.7228\n",
      "Epoch 112/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7239\n",
      "Epoch 113/180\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5864 - val_loss: 0.7163\n",
      "Epoch 114/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.7296\n",
      "Epoch 115/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.7275\n",
      "Epoch 116/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5856 - val_loss: 0.7429\n",
      "Epoch 117/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5811 - val_loss: 0.7266\n",
      "Epoch 118/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5824 - val_loss: 0.7312\n",
      "Epoch 119/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7344\n",
      "Epoch 120/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5827 - val_loss: 0.7378\n",
      "Epoch 121/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5806 - val_loss: 0.7266\n",
      "Epoch 122/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7301\n",
      "Epoch 123/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7336\n",
      "Epoch 124/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5801 - val_loss: 0.7408\n",
      "Epoch 125/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.7247\n",
      "Epoch 126/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5824 - val_loss: 0.7388\n",
      "Epoch 127/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.7326\n",
      "Epoch 128/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5818 - val_loss: 0.7405\n",
      "Epoch 129/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7261\n",
      "Epoch 130/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5782 - val_loss: 0.7393\n",
      "Epoch 131/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5783 - val_loss: 0.7242\n",
      "Epoch 132/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5760 - val_loss: 0.7382\n",
      "Epoch 133/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5794 - val_loss: 0.7422\n",
      "Epoch 134/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5770 - val_loss: 0.7376\n",
      "Epoch 135/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5793 - val_loss: 0.7445\n",
      "Epoch 136/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5752 - val_loss: 0.7427\n",
      "Epoch 137/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5801 - val_loss: 0.7518\n",
      "Epoch 138/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5752 - val_loss: 0.7395\n",
      "Epoch 139/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5750 - val_loss: 0.7376\n",
      "Epoch 140/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5770 - val_loss: 0.7423\n",
      "Epoch 141/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5721 - val_loss: 0.7462\n",
      "Epoch 142/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5761 - val_loss: 0.7463\n",
      "Epoch 143/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5746 - val_loss: 0.7394\n",
      "Epoch 144/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5750 - val_loss: 0.7474\n",
      "Epoch 145/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5716 - val_loss: 0.7292\n",
      "Epoch 146/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5701 - val_loss: 0.7460\n",
      "Epoch 147/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5776 - val_loss: 0.7567\n",
      "Epoch 148/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5767 - val_loss: 0.7579\n",
      "Epoch 149/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5706 - val_loss: 0.7595\n",
      "Epoch 150/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5709 - val_loss: 0.7620\n",
      "Epoch 151/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5712 - val_loss: 0.7425\n",
      "Epoch 152/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5702 - val_loss: 0.7502\n",
      "Epoch 153/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5660 - val_loss: 0.7500\n",
      "Epoch 154/180\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5707 - val_loss: 0.7479\n",
      "Epoch 155/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5685 - val_loss: 0.7518\n",
      "Epoch 156/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5659 - val_loss: 0.7462\n",
      "Epoch 157/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5663 - val_loss: 0.7530\n",
      "Epoch 158/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5702 - val_loss: 0.7383\n",
      "Epoch 159/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5688 - val_loss: 0.7216\n",
      "Epoch 160/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5653 - val_loss: 0.7616\n",
      "Epoch 161/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5673 - val_loss: 0.7704\n",
      "Epoch 162/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5614 - val_loss: 0.7741\n",
      "Epoch 163/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5638 - val_loss: 0.7370\n",
      "Epoch 164/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5608 - val_loss: 0.7582\n",
      "Epoch 165/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5624 - val_loss: 0.7718\n",
      "Epoch 166/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5578 - val_loss: 0.7474\n",
      "Epoch 167/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5628 - val_loss: 0.7479\n",
      "Epoch 168/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5624 - val_loss: 0.7588\n",
      "Epoch 169/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5613 - val_loss: 0.7426\n",
      "Epoch 170/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5551 - val_loss: 0.7599\n",
      "Epoch 171/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5622 - val_loss: 0.7676\n",
      "Epoch 172/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5596 - val_loss: 0.7716\n",
      "Epoch 173/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5559 - val_loss: 0.7623\n",
      "Epoch 174/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5517 - val_loss: 0.7682\n",
      "Epoch 175/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5550 - val_loss: 0.7593\n",
      "Epoch 176/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5573 - val_loss: 0.7738\n",
      "Epoch 177/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5538 - val_loss: 0.7735\n",
      "Epoch 178/180\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5506 - val_loss: 0.7680\n",
      "Epoch 179/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5563 - val_loss: 0.7616\n",
      "Epoch 180/180\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5540 - val_loss: 0.7625\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:29<00:55, 55.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/190\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.9806 - val_loss: 0.7254\n",
      "Epoch 2/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8891 - val_loss: 0.6159\n",
      "Epoch 3/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7922 - val_loss: 0.5470\n",
      "Epoch 4/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7517 - val_loss: 0.5243\n",
      "Epoch 5/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7351 - val_loss: 0.5167\n",
      "Epoch 6/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7220 - val_loss: 0.5139\n",
      "Epoch 7/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7162 - val_loss: 0.5130\n",
      "Epoch 8/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7099 - val_loss: 0.5154\n",
      "Epoch 9/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7039 - val_loss: 0.5161\n",
      "Epoch 10/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6994 - val_loss: 0.5207\n",
      "Epoch 11/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6966 - val_loss: 0.5228\n",
      "Epoch 12/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6934 - val_loss: 0.5260\n",
      "Epoch 13/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.5272\n",
      "Epoch 14/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.5298\n",
      "Epoch 15/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6861 - val_loss: 0.5334\n",
      "Epoch 16/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6842 - val_loss: 0.5366\n",
      "Epoch 17/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.5390\n",
      "Epoch 18/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6784 - val_loss: 0.5438\n",
      "Epoch 19/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6780 - val_loss: 0.5465\n",
      "Epoch 20/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6751 - val_loss: 0.5457\n",
      "Epoch 21/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6738 - val_loss: 0.5532\n",
      "Epoch 22/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6717 - val_loss: 0.5550\n",
      "Epoch 23/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6724 - val_loss: 0.5499\n",
      "Epoch 24/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6678 - val_loss: 0.5630\n",
      "Epoch 25/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6656 - val_loss: 0.5655\n",
      "Epoch 26/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6664 - val_loss: 0.5701\n",
      "Epoch 27/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6666 - val_loss: 0.5752\n",
      "Epoch 28/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6633 - val_loss: 0.5808\n",
      "Epoch 29/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6626 - val_loss: 0.5777\n",
      "Epoch 30/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.5798\n",
      "Epoch 31/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6616 - val_loss: 0.5680\n",
      "Epoch 32/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6593 - val_loss: 0.5875\n",
      "Epoch 33/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6577 - val_loss: 0.5878\n",
      "Epoch 34/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6580 - val_loss: 0.5909\n",
      "Epoch 35/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6560 - val_loss: 0.5917\n",
      "Epoch 36/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.5968\n",
      "Epoch 37/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.5977\n",
      "Epoch 38/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.5984\n",
      "Epoch 39/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6544 - val_loss: 0.6041\n",
      "Epoch 40/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6085\n",
      "Epoch 41/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6050\n",
      "Epoch 42/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6069\n",
      "Epoch 43/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.6064\n",
      "Epoch 44/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6077\n",
      "Epoch 45/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.6063\n",
      "Epoch 46/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6454 - val_loss: 0.6152\n",
      "Epoch 47/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6177\n",
      "Epoch 48/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6423 - val_loss: 0.6011\n",
      "Epoch 49/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6403 - val_loss: 0.6332\n",
      "Epoch 50/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6422 - val_loss: 0.6349\n",
      "Epoch 51/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6392 - val_loss: 0.6328\n",
      "Epoch 52/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6389 - val_loss: 0.6381\n",
      "Epoch 53/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.6364\n",
      "Epoch 54/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 0.6341\n",
      "Epoch 55/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6354 - val_loss: 0.6398\n",
      "Epoch 56/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6341 - val_loss: 0.6377\n",
      "Epoch 57/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.6380\n",
      "Epoch 58/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6459\n",
      "Epoch 59/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6328 - val_loss: 0.6403\n",
      "Epoch 60/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6317 - val_loss: 0.6483\n",
      "Epoch 61/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6277 - val_loss: 0.6446\n",
      "Epoch 62/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6293 - val_loss: 0.6411\n",
      "Epoch 63/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6296 - val_loss: 0.6515\n",
      "Epoch 64/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6484\n",
      "Epoch 65/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6281 - val_loss: 0.6529\n",
      "Epoch 66/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6555\n",
      "Epoch 67/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.6533\n",
      "Epoch 68/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6509\n",
      "Epoch 69/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.6545\n",
      "Epoch 70/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.6531\n",
      "Epoch 71/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6256 - val_loss: 0.6514\n",
      "Epoch 72/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6227 - val_loss: 0.6562\n",
      "Epoch 73/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6234 - val_loss: 0.6552\n",
      "Epoch 74/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.6442\n",
      "Epoch 75/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6373\n",
      "Epoch 76/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.6568\n",
      "Epoch 77/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6196 - val_loss: 0.6479\n",
      "Epoch 78/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6437\n",
      "Epoch 79/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.6526\n",
      "Epoch 80/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6183 - val_loss: 0.6666\n",
      "Epoch 81/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6175 - val_loss: 0.6702\n",
      "Epoch 82/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6652\n",
      "Epoch 83/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.6633\n",
      "Epoch 84/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6155 - val_loss: 0.6638\n",
      "Epoch 85/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.6661\n",
      "Epoch 86/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.6667\n",
      "Epoch 87/190\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6145 - val_loss: 0.6706\n",
      "Epoch 88/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6736\n",
      "Epoch 89/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.6746\n",
      "Epoch 90/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6185 - val_loss: 0.6324\n",
      "Epoch 91/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.6750\n",
      "Epoch 92/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6150 - val_loss: 0.6727\n",
      "Epoch 93/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6669\n",
      "Epoch 94/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6121 - val_loss: 0.6654\n",
      "Epoch 95/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.6606\n",
      "Epoch 96/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6632\n",
      "Epoch 97/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6687\n",
      "Epoch 98/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6800\n",
      "Epoch 99/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6731\n",
      "Epoch 100/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6783\n",
      "Epoch 101/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6732\n",
      "Epoch 102/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6777\n",
      "Epoch 103/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6817\n",
      "Epoch 104/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.6752\n",
      "Epoch 105/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6103 - val_loss: 0.6814\n",
      "Epoch 106/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6758\n",
      "Epoch 107/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6797\n",
      "Epoch 108/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.6782\n",
      "Epoch 109/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6112 - val_loss: 0.6810\n",
      "Epoch 110/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6087 - val_loss: 0.6816\n",
      "Epoch 111/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6763\n",
      "Epoch 112/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6077 - val_loss: 0.6827\n",
      "Epoch 113/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.6734\n",
      "Epoch 114/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.6840\n",
      "Epoch 115/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6849\n",
      "Epoch 116/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6815\n",
      "Epoch 117/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6067 - val_loss: 0.6945\n",
      "Epoch 118/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6070 - val_loss: 0.6982\n",
      "Epoch 119/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6051 - val_loss: 0.6884\n",
      "Epoch 120/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6868\n",
      "Epoch 121/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6922\n",
      "Epoch 122/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6052 - val_loss: 0.6777\n",
      "Epoch 123/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.6909\n",
      "Epoch 124/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7012\n",
      "Epoch 125/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6901\n",
      "Epoch 126/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.6818\n",
      "Epoch 127/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6979\n",
      "Epoch 128/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6031 - val_loss: 0.7063\n",
      "Epoch 129/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6956\n",
      "Epoch 130/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.7009\n",
      "Epoch 131/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6013 - val_loss: 0.6954\n",
      "Epoch 132/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.6901\n",
      "Epoch 133/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6918\n",
      "Epoch 134/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6025 - val_loss: 0.7041\n",
      "Epoch 135/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.7031\n",
      "Epoch 136/190\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6012 - val_loss: 0.6991\n",
      "Epoch 137/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6984\n",
      "Epoch 138/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.7033\n",
      "Epoch 139/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.7001\n",
      "Epoch 140/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.6935\n",
      "Epoch 141/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6002 - val_loss: 0.6817\n",
      "Epoch 142/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.7012\n",
      "Epoch 143/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.7030\n",
      "Epoch 144/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6008 - val_loss: 0.7015\n",
      "Epoch 145/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5990 - val_loss: 0.7160\n",
      "Epoch 146/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5924 - val_loss: 0.6865\n",
      "Epoch 147/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6021 - val_loss: 0.6940\n",
      "Epoch 148/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.6984\n",
      "Epoch 149/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 0.6940\n",
      "Epoch 150/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.6932\n",
      "Epoch 151/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.6945\n",
      "Epoch 152/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5983 - val_loss: 0.7033\n",
      "Epoch 153/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5990 - val_loss: 0.7058\n",
      "Epoch 154/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5958 - val_loss: 0.6967\n",
      "Epoch 155/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5968 - val_loss: 0.7031\n",
      "Epoch 156/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.6834\n",
      "Epoch 157/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5969 - val_loss: 0.7148\n",
      "Epoch 158/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5941 - val_loss: 0.7064\n",
      "Epoch 159/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7046\n",
      "Epoch 160/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.7115\n",
      "Epoch 161/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7044\n",
      "Epoch 162/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.7018\n",
      "Epoch 163/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5963 - val_loss: 0.7046\n",
      "Epoch 164/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.6870\n",
      "Epoch 165/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5932 - val_loss: 0.7094\n",
      "Epoch 166/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7043\n",
      "Epoch 167/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5926 - val_loss: 0.7061\n",
      "Epoch 168/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.7085\n",
      "Epoch 169/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5914 - val_loss: 0.7099\n",
      "Epoch 170/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5940 - val_loss: 0.7181\n",
      "Epoch 171/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5926 - val_loss: 0.7066\n",
      "Epoch 172/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5934 - val_loss: 0.7046\n",
      "Epoch 173/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7094\n",
      "Epoch 174/190\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5935 - val_loss: 0.7127\n",
      "Epoch 175/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7130\n",
      "Epoch 176/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5943 - val_loss: 0.7099\n",
      "Epoch 177/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5916 - val_loss: 0.7169\n",
      "Epoch 178/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5934 - val_loss: 0.7143\n",
      "Epoch 179/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5902 - val_loss: 0.7124\n",
      "Epoch 180/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5910 - val_loss: 0.7165\n",
      "Epoch 181/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5948 - val_loss: 0.7060\n",
      "Epoch 182/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5891 - val_loss: 0.7088\n",
      "Epoch 183/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5935 - val_loss: 0.7229\n",
      "Epoch 184/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5893 - val_loss: 0.7131\n",
      "Epoch 185/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.7143\n",
      "Epoch 186/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5888 - val_loss: 0.7146\n",
      "Epoch 187/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5884 - val_loss: 0.7033\n",
      "Epoch 188/190\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5909 - val_loss: 0.7007\n",
      "Epoch 189/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5889 - val_loss: 0.7064\n",
      "Epoch 190/190\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.6910\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:37<00:00, 55.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# r2_all=[]\n",
    "for item in tqdm(range(150,200,10)):\n",
    "    history , r2=_compile_model(X_train,y_train,X_test,y_test,item,8)\n",
    "    r2_all.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(r2_all)),r2_all)\n",
    "plt.xticks(range(len(r2_all)),range(10,200,10))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('R_squared')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "76/76 [==============================] - 2s 9ms/step - loss: 0.9969 - val_loss: 0.7516\n",
      "Epoch 2/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.9424 - val_loss: 0.6667\n",
      "Epoch 3/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.8467 - val_loss: 0.5682\n",
      "Epoch 4/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7768 - val_loss: 0.5277\n",
      "Epoch 5/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7465 - val_loss: 0.5132\n",
      "Epoch 6/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7326 - val_loss: 0.5100\n",
      "Epoch 7/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.7281 - val_loss: 0.5076\n",
      "Epoch 8/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7144 - val_loss: 0.5075\n",
      "Epoch 9/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7079 - val_loss: 0.5112\n",
      "Epoch 10/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.7040 - val_loss: 0.5126\n",
      "Epoch 11/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6982 - val_loss: 0.5136\n",
      "Epoch 12/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6950 - val_loss: 0.5176\n",
      "Epoch 13/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6907 - val_loss: 0.5151\n",
      "Epoch 14/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6863 - val_loss: 0.5226\n",
      "Epoch 15/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6822 - val_loss: 0.5234\n",
      "Epoch 16/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6820 - val_loss: 0.5216\n",
      "Epoch 17/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6817 - val_loss: 0.5311\n",
      "Epoch 18/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6747 - val_loss: 0.5305\n",
      "Epoch 19/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6720 - val_loss: 0.5332\n",
      "Epoch 20/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6691 - val_loss: 0.5356\n",
      "Epoch 21/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6665 - val_loss: 0.5416\n",
      "Epoch 22/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6656 - val_loss: 0.5463\n",
      "Epoch 23/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6609 - val_loss: 0.5448\n",
      "Epoch 24/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6584 - val_loss: 0.5465\n",
      "Epoch 25/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.5512\n",
      "Epoch 26/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6558 - val_loss: 0.5539\n",
      "Epoch 27/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6522 - val_loss: 0.5611\n",
      "Epoch 28/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6495 - val_loss: 0.5614\n",
      "Epoch 29/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6515 - val_loss: 0.5685\n",
      "Epoch 30/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 0.5717\n",
      "Epoch 31/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6451 - val_loss: 0.5731\n",
      "Epoch 32/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6438 - val_loss: 0.5806\n",
      "Epoch 33/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6426 - val_loss: 0.5815\n",
      "Epoch 34/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6410 - val_loss: 0.5886\n",
      "Epoch 35/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6398 - val_loss: 0.5911\n",
      "Epoch 36/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6397 - val_loss: 0.5810\n",
      "Epoch 37/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6436 - val_loss: 0.5966\n",
      "Epoch 38/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6381 - val_loss: 0.6022\n",
      "Epoch 39/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6363 - val_loss: 0.5984\n",
      "Epoch 40/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 0.5984\n",
      "Epoch 41/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6357 - val_loss: 0.5998\n",
      "Epoch 42/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6319 - val_loss: 0.6090\n",
      "Epoch 43/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6324 - val_loss: 0.6141\n",
      "Epoch 44/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6316 - val_loss: 0.6108\n",
      "Epoch 45/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6315 - val_loss: 0.6170\n",
      "Epoch 46/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6275 - val_loss: 0.6212\n",
      "Epoch 47/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6261 - val_loss: 0.6255\n",
      "Epoch 48/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 0.6261\n",
      "Epoch 49/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6282 - val_loss: 0.6278\n",
      "Epoch 50/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 0.6269\n",
      "Epoch 51/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6272 - val_loss: 0.6339\n",
      "Epoch 52/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6238 - val_loss: 0.6301\n",
      "Epoch 53/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6251 - val_loss: 0.6213\n",
      "Epoch 54/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6228 - val_loss: 0.6443\n",
      "Epoch 55/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6207 - val_loss: 0.6421\n",
      "Epoch 56/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6216 - val_loss: 0.6480\n",
      "Epoch 57/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6228 - val_loss: 0.6501\n",
      "Epoch 58/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6203 - val_loss: 0.6419\n",
      "Epoch 59/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6199 - val_loss: 0.6495\n",
      "Epoch 60/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6201 - val_loss: 0.6621\n",
      "Epoch 61/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6181 - val_loss: 0.6675\n",
      "Epoch 62/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6558\n",
      "Epoch 63/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6179 - val_loss: 0.6658\n",
      "Epoch 64/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6652\n",
      "Epoch 65/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6161 - val_loss: 0.6455\n",
      "Epoch 66/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6482\n",
      "Epoch 67/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6142 - val_loss: 0.6645\n",
      "Epoch 68/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6122 - val_loss: 0.6820\n",
      "Epoch 69/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6140 - val_loss: 0.6774\n",
      "Epoch 70/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6129 - val_loss: 0.6763\n",
      "Epoch 71/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6146 - val_loss: 0.6845\n",
      "Epoch 72/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.6775\n",
      "Epoch 73/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6104 - val_loss: 0.6856\n",
      "Epoch 74/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.6835\n",
      "Epoch 75/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6806\n",
      "Epoch 76/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.6840\n",
      "Epoch 77/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6106 - val_loss: 0.6889\n",
      "Epoch 78/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6062 - val_loss: 0.6846\n",
      "Epoch 79/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6851\n",
      "Epoch 80/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6079 - val_loss: 0.6987\n",
      "Epoch 81/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6066 - val_loss: 0.6843\n",
      "Epoch 82/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6865\n",
      "Epoch 83/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6068 - val_loss: 0.6773\n",
      "Epoch 84/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6044 - val_loss: 0.6919\n",
      "Epoch 85/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6926\n",
      "Epoch 86/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6061 - val_loss: 0.6972\n",
      "Epoch 87/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.6032 - val_loss: 0.6965\n",
      "Epoch 88/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6065 - val_loss: 0.6978\n",
      "Epoch 89/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6033 - val_loss: 0.7043\n",
      "Epoch 90/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.7057\n",
      "Epoch 91/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6026 - val_loss: 0.6990\n",
      "Epoch 92/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.7084\n",
      "Epoch 93/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6023 - val_loss: 0.7043\n",
      "Epoch 94/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.6931\n",
      "Epoch 95/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.7024\n",
      "Epoch 96/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6021 - val_loss: 0.7133\n",
      "Epoch 97/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6016 - val_loss: 0.7028\n",
      "Epoch 98/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5990 - val_loss: 0.6987\n",
      "Epoch 99/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5973 - val_loss: 0.6981\n",
      "Epoch 100/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5989 - val_loss: 0.7055\n",
      "Epoch 101/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5994 - val_loss: 0.7015\n",
      "Epoch 102/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5995 - val_loss: 0.6981\n",
      "Epoch 103/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5961 - val_loss: 0.7130\n",
      "Epoch 104/150\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.5945 - val_loss: 0.7142\n",
      "Epoch 105/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7100\n",
      "Epoch 106/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7044\n",
      "Epoch 107/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.7058\n",
      "Epoch 108/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5981 - val_loss: 0.7225\n",
      "Epoch 109/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5933 - val_loss: 0.7134\n",
      "Epoch 110/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5939 - val_loss: 0.7212\n",
      "Epoch 111/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5914 - val_loss: 0.7108\n",
      "Epoch 112/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5965 - val_loss: 0.6892\n",
      "Epoch 113/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5899 - val_loss: 0.7067\n",
      "Epoch 114/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.7223\n",
      "Epoch 115/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5925 - val_loss: 0.7240\n",
      "Epoch 116/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5906 - val_loss: 0.7169\n",
      "Epoch 117/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5880 - val_loss: 0.7054\n",
      "Epoch 118/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5922 - val_loss: 0.7182\n",
      "Epoch 119/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5883 - val_loss: 0.7263\n",
      "Epoch 120/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5884 - val_loss: 0.7253\n",
      "Epoch 121/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5879 - val_loss: 0.7113\n",
      "Epoch 122/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.7172\n",
      "Epoch 123/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5867 - val_loss: 0.7204\n",
      "Epoch 124/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5849 - val_loss: 0.7388\n",
      "Epoch 125/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5861 - val_loss: 0.7253\n",
      "Epoch 126/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7263\n",
      "Epoch 127/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5875 - val_loss: 0.7004\n",
      "Epoch 128/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5871 - val_loss: 0.7207\n",
      "Epoch 129/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5871 - val_loss: 0.7114\n",
      "Epoch 130/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5835 - val_loss: 0.7255\n",
      "Epoch 131/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.7072\n",
      "Epoch 132/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7243\n",
      "Epoch 133/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5854 - val_loss: 0.7141\n",
      "Epoch 134/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.7324\n",
      "Epoch 135/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5794 - val_loss: 0.7158\n",
      "Epoch 136/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5792 - val_loss: 0.7199\n",
      "Epoch 137/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7170\n",
      "Epoch 138/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5760 - val_loss: 0.7338\n",
      "Epoch 139/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5777 - val_loss: 0.7128\n",
      "Epoch 140/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5758 - val_loss: 0.7396\n",
      "Epoch 141/150\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5767 - val_loss: 0.7190\n",
      "Epoch 142/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5783 - val_loss: 0.7308\n",
      "Epoch 143/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5757 - val_loss: 0.7161\n",
      "Epoch 144/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5777 - val_loss: 0.7144\n",
      "Epoch 145/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5764 - val_loss: 0.7168\n",
      "Epoch 146/150\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.5767 - val_loss: 0.7122\n",
      "Epoch 147/150\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.5724 - val_loss: 0.7240\n",
      "Epoch 148/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5728 - val_loss: 0.7132\n",
      "Epoch 149/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5735 - val_loss: 0.7139\n",
      "Epoch 150/150\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5748 - val_loss: 0.7291\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history , r2=_compile_model(X_train,y_train,X_test,y_test,150,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059121773442694425"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
